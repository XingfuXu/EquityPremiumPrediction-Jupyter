{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2df2b249",
   "metadata": {},
   "source": [
    "### Alternative forecasting window sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f822b3b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/xingfuxu/PycharmProjects/EquityPremiumPredictionML-Jupyter'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "# os.chdir(path)    # or you can set your working dir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3c1c50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your working dir should include \"NN_models.py\", Perform_CW_test.py\" and \"Perform_PT_test.py\" files.\n",
    "from Perform_CW_test import CW_test\n",
    "from Perform_PT_test import PT_test\n",
    "from NN_models import Net2, Net4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e772b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import torch\n",
    "from skorch import NeuralNetRegressor\n",
    "from tqdm import tqdm\n",
    "#\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50dbea16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>log_equity_premium</th>\n",
       "      <th>equity_premium</th>\n",
       "      <th>DP</th>\n",
       "      <th>DY</th>\n",
       "      <th>EP</th>\n",
       "      <th>SVAR</th>\n",
       "      <th>BM</th>\n",
       "      <th>NTIS</th>\n",
       "      <th>TBL</th>\n",
       "      <th>...</th>\n",
       "      <th>MA_2_9</th>\n",
       "      <th>MA_2_12</th>\n",
       "      <th>MA_3_9</th>\n",
       "      <th>MA_3_12</th>\n",
       "      <th>MOM_1</th>\n",
       "      <th>MOM_2</th>\n",
       "      <th>MOM_3</th>\n",
       "      <th>MOM_6</th>\n",
       "      <th>MOM_9</th>\n",
       "      <th>MOM_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>192701</td>\n",
       "      <td>-0.005710</td>\n",
       "      <td>-0.00571</td>\n",
       "      <td>-2.942374</td>\n",
       "      <td>-2.963349</td>\n",
       "      <td>-2.374773</td>\n",
       "      <td>0.00047</td>\n",
       "      <td>0.44371</td>\n",
       "      <td>0.05082</td>\n",
       "      <td>3.23</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>192702</td>\n",
       "      <td>0.042017</td>\n",
       "      <td>0.04302</td>\n",
       "      <td>-2.979535</td>\n",
       "      <td>-2.932946</td>\n",
       "      <td>-2.430353</td>\n",
       "      <td>0.00029</td>\n",
       "      <td>0.42850</td>\n",
       "      <td>0.05167</td>\n",
       "      <td>3.29</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>192703</td>\n",
       "      <td>0.004697</td>\n",
       "      <td>0.00472</td>\n",
       "      <td>-2.976535</td>\n",
       "      <td>-2.970053</td>\n",
       "      <td>-2.445079</td>\n",
       "      <td>0.00092</td>\n",
       "      <td>0.46977</td>\n",
       "      <td>0.04636</td>\n",
       "      <td>3.20</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>192704</td>\n",
       "      <td>0.009940</td>\n",
       "      <td>0.01002</td>\n",
       "      <td>-2.984225</td>\n",
       "      <td>-2.967143</td>\n",
       "      <td>-2.471309</td>\n",
       "      <td>0.00060</td>\n",
       "      <td>0.45675</td>\n",
       "      <td>0.05051</td>\n",
       "      <td>3.39</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>192705</td>\n",
       "      <td>0.057987</td>\n",
       "      <td>0.05985</td>\n",
       "      <td>-3.025963</td>\n",
       "      <td>-2.975058</td>\n",
       "      <td>-2.531446</td>\n",
       "      <td>0.00039</td>\n",
       "      <td>0.43478</td>\n",
       "      <td>0.05528</td>\n",
       "      <td>3.33</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    month  log_equity_premium  equity_premium        DP        DY        EP  \\\n",
       "0  192701           -0.005710        -0.00571 -2.942374 -2.963349 -2.374773   \n",
       "1  192702            0.042017         0.04302 -2.979535 -2.932946 -2.430353   \n",
       "2  192703            0.004697         0.00472 -2.976535 -2.970053 -2.445079   \n",
       "3  192704            0.009940         0.01002 -2.984225 -2.967143 -2.471309   \n",
       "4  192705            0.057987         0.05985 -3.025963 -2.975058 -2.531446   \n",
       "\n",
       "      SVAR       BM     NTIS   TBL  ...  MA_2_9  MA_2_12  MA_3_9  MA_3_12  \\\n",
       "0  0.00047  0.44371  0.05082  3.23  ...       1        1       1        1   \n",
       "1  0.00029  0.42850  0.05167  3.29  ...       1        1       1        1   \n",
       "2  0.00092  0.46977  0.04636  3.20  ...       1        1       1        1   \n",
       "3  0.00060  0.45675  0.05051  3.39  ...       1        1       1        1   \n",
       "4  0.00039  0.43478  0.05528  3.33  ...       1        1       1        1   \n",
       "\n",
       "   MOM_1  MOM_2  MOM_3  MOM_6  MOM_9  MOM_12  \n",
       "0      0      0      1      1      1       1  \n",
       "1      1      1      1      1      1       1  \n",
       "2      1      1      1      1      1       1  \n",
       "3      1      1      1      1      1       1  \n",
       "4      1      1      1      1      1       1  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set seed\n",
    "torch.manual_seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "# read data\n",
    "predictor_df = pd.read_excel(open('ml_equity_premium_data.xlsx', 'rb'), sheet_name='result_predictor')\n",
    "predictor_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5218722b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove irrelavent columns\n",
    "predictor0 = predictor_df.drop(['month', 'equity_premium'], axis=1)\n",
    "# get all the predictors and set the log equity premium 1-month ahead\n",
    "predictor = np.concatenate([predictor0['log_equity_premium'][1:].values.reshape(-1, 1),\n",
    "                            predictor0.iloc[0:(predictor0.shape[0] - 1), 1:]], axis=1)\n",
    "\n",
    "# number of rows\n",
    "N = predictor.shape[0]\n",
    "\n",
    "# number of all columns, including the log equity premium\n",
    "n_cols = predictor.shape[1]\n",
    "\n",
    "# Actual one-month ahead log equity premium\n",
    "actual = predictor[:, [0]]\n",
    "\n",
    "# Historical average forecasting as benchmark\n",
    "y_pred_HA = predictor0['log_equity_premium'].values[0:(predictor0.shape[0] - 1), ].cumsum() / np.arange(1, N + 1)\n",
    "y_pred_HA = y_pred_HA.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f59806b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Out-of-sample: 1990:01-2020:12\n",
    "in_out_1990 = predictor_df.index[predictor_df['month'] == 199001][0]\n",
    "actual_1990 = actual[in_out_1990:, ]\n",
    "y_pred_HA_1990 = y_pred_HA[in_out_1990:, ]\n",
    "MSFE_HA_1990 = mean_squared_error(y_pred_HA_1990, actual_1990)\n",
    "\n",
    "# Machine Learning methods used in GKX (2020)\n",
    "y_pred_PLS_1990, y_pred_PCR_1990,  y_pred_LASSO_1990 = [], [], []\n",
    "y_pred_ENet_1990, y_pred_RF_1990 = [], []\n",
    "y_pred_NN2_1990, y_pred_NN4_1990 = [], []\n",
    "\n",
    "## Other commonly used machine learning method\n",
    "y_pred_Ridge_1990 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b69658e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# control the update month of models during out-of-sample period. \n",
    "month_index = 1  # We update our models annually, meaning we refresh them in months 1, 13, 25, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5dcc763",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 371/371 [1:07:38<00:00, 10.94s/it]\n"
     ]
    }
   ],
   "source": [
    "for t in tqdm(range(in_out_1990, N)):\n",
    "    #\n",
    "    X_train_all = predictor[:t, 1:n_cols]\n",
    "    y_train_all = predictor[:t, 0]\n",
    "    # set 15% of all the train data as validation set\n",
    "    X_train = X_train_all[0:int(len(X_train_all) * 0.85), :]\n",
    "    X_validation = X_train_all[int(len(X_train_all) * 0.85):t, :]\n",
    "    y_train = y_train_all[0:int(len(X_train_all) * 0.85)]\n",
    "    y_validation = y_train_all[int(len(X_train_all) * 0.85):t]\n",
    "    #\n",
    "    if month_index % 12 == 1:\n",
    "        month_index += 1\n",
    "\n",
    "        # PLS\n",
    "        PLS_param = {'n_components': [1, 2, 3, 4, 5, 6, 7, 8]}\n",
    "        PLS_result = {}\n",
    "        for param in ParameterGrid(PLS_param):\n",
    "            PLS = PLSRegression(**param)\n",
    "            PLS.fit(X_train, y_train)\n",
    "            mse = mean_squared_error(PLS.predict(X_validation), y_validation)\n",
    "            PLS_result[str(param)] = mse\n",
    "\n",
    "        PLS_best_param = eval(min(PLS_result, key=PLS_result.get))\n",
    "        PLS_model = PLSRegression(**PLS_best_param)\n",
    "        PLS_model.fit(X_train_all, y_train_all)\n",
    "        y_pred_PLS_1990.append(PLS_model.predict(predictor[[t], 1:n_cols])[0][0])\n",
    "\n",
    "        # PCR\n",
    "        PCR_param = {'n_components': [1, 2, 3, 4, 5, 6, 7, 8]}\n",
    "        PCR_result = {}\n",
    "        for param in ParameterGrid(PCR_param):\n",
    "            pca = PCA(**param)\n",
    "            pca.fit(X_train)\n",
    "            comps = pca.transform(X_train)\n",
    "            forecast = LinearRegression()\n",
    "            forecast.fit(comps, y_train)\n",
    "            mse = mean_squared_error(forecast.predict(pca.transform(X_validation)), y_validation)\n",
    "            PCR_result[str(param)] = mse\n",
    "        #\n",
    "        PCR_best_param = eval(min(PCR_result, key=PCR_result.get))\n",
    "        #\n",
    "        PCR_model = PCA(**PCR_best_param)\n",
    "        PCR_model.fit(X_train_all)\n",
    "        PCR_comps = PCR_model.transform(X_train_all)\n",
    "        PCR_forecast = LinearRegression()\n",
    "        PCR_forecast.fit(PCR_comps, y_train_all)\n",
    "        y_pred_PCR_1990.append(PCR_forecast.predict(PCR_model.transform(predictor[[t], 1:n_cols]))[0])\n",
    "\n",
    "        # LASSO\n",
    "        LASSO_param = {'alpha': list(10 ** np.arange(-4, 1 + 0.001, 0.2))}\n",
    "        LASSO_result = {}\n",
    "        for param in ParameterGrid(LASSO_param):\n",
    "            LASSO = Lasso(**param)\n",
    "            LASSO.fit(X_train, y_train)\n",
    "            mse = mean_squared_error(LASSO.predict(X_validation), y_validation)\n",
    "            LASSO_result[str(param)] = mse\n",
    "        #\n",
    "        LASSO_best_param = eval(min(LASSO_result, key=LASSO_result.get))\n",
    "        #\n",
    "        LASSO_model = Lasso(**LASSO_best_param)\n",
    "        LASSO_model.fit(X_train_all, y_train_all)\n",
    "        y_pred_LASSO_1990.append(LASSO_model.predict(predictor[[t], 1:n_cols])[0])\n",
    "\n",
    "        # ENet\n",
    "        ENet_param = {'alpha': list(10 ** np.arange(-4, 1 + 0.001, 0.2)),\n",
    "                      'l1_ratio': list(np.arange(0.2, 1, 0.3))}\n",
    "        ENet_result = {}\n",
    "        for param in ParameterGrid(ENet_param):\n",
    "            ENet = ElasticNet(**param)\n",
    "            ENet.fit(X_train, y_train)\n",
    "            mse = mean_squared_error(ENet.predict(X_validation), y_validation)\n",
    "            ENet_result[str(param)] = mse\n",
    "\n",
    "        ENet_best_param = eval(min(ENet_result, key=ENet_result.get))\n",
    "        ENet_model = ElasticNet(**ENet_best_param)\n",
    "        ENet_model.fit(X_train_all, y_train_all)\n",
    "        y_pred_ENet_1990.append(ENet_model.predict(predictor[[t], 1:n_cols])[0])\n",
    "\n",
    "\n",
    "        # RF\n",
    "        RF_param = {'n_estimators': [10, 50, 100, 150, 200],\n",
    "                    'max_depth': [2, 3, 4],\n",
    "                    'min_samples_leaf': [1, 3, 5]}\n",
    "        RF_result = {}\n",
    "        for param in ParameterGrid(RF_param):\n",
    "            RF = RandomForestRegressor(**param)\n",
    "            RF.fit(X_train, y_train)\n",
    "            mse = mean_squared_error(RF.predict(X_validation), y_validation)\n",
    "            RF_result[str(param)] = mse\n",
    "\n",
    "        RF_best_param = eval(min(RF_result, key=RF_result.get))\n",
    "        RF_model = RandomForestRegressor(**RF_best_param)\n",
    "        RF_model.fit(X_train_all, y_train_all)\n",
    "        y_pred_RF_1990.append(RF_model.predict(predictor[[t], 1:n_cols])[0])\n",
    "\n",
    "        # Neural Network Models: NN2 & NN4\n",
    "        X_train_all_tensor = torch.tensor(X_train_all, dtype=torch.float)\n",
    "        y_train_all_tensor = torch.tensor(y_train_all.reshape(-1, 1), dtype=torch.float)\n",
    "        X_train_tensor = torch.tensor(X_train, dtype=torch.float)\n",
    "        y_train_tensor = torch.tensor(y_train.reshape(-1, 1), dtype=torch.float)\n",
    "        X_validation_tensor = torch.tensor(X_validation, dtype=torch.float)\n",
    "        y_validation_tensor = torch.tensor(y_validation.reshape(-1, 1), dtype=torch.float)\n",
    "\n",
    "        # NN2\n",
    "        NN2_result = {}\n",
    "        NN2_architecture = {\"module__n_feature\": X_train_tensor.shape[1],\n",
    "                            \"module__n_hidden1\": 32, \"module__n_hidden2\": 16,\n",
    "                            \"module__n_output\": 1}\n",
    "        NN2_param = {'module__dropout': [0.2, 0.4, 0.6, 0.8],\n",
    "                    'lr': [0.001, 0.01],\n",
    "                    'optimizer__weight_decay': [0.1, 0.01, 0.001]}\n",
    "        for param in ParameterGrid(NN2_param):\n",
    "            NN2 = NeuralNetRegressor(Net2, verbose=0, max_epochs=200,\n",
    "                                     optimizer=torch.optim.SGD,\n",
    "                                     **NN2_architecture, **param)\n",
    "            NN2.fit(X_train_tensor, y_train_tensor)\n",
    "            mse = mean_squared_error(NN2.predict(X_validation_tensor), y_validation)\n",
    "            NN2_result[str(param)] = mse\n",
    "        \n",
    "        #\n",
    "        NN2_best_param = eval(min(NN2_result, key=NN2_result.get))\n",
    "        NN2_model = NeuralNetRegressor(Net2, verbose=0, max_epochs=200, optimizer=torch.optim.SGD,\n",
    "                                       **NN2_architecture, **NN2_best_param)\n",
    "        NN2_model.fit(X_train_all_tensor, y_train_all_tensor)\n",
    "        y_pred_NN2_1990.append(NN2_model.predict(torch.tensor(predictor[[t], 1:n_cols], dtype=torch.float))[0][0])\n",
    "        #\n",
    "\n",
    "\n",
    "        # NN4\n",
    "        NN4_result = {}\n",
    "        NN4_architecture = {\"module__n_feature\": X_train_tensor.shape[1],\n",
    "                            \"module__n_hidden1\": 32, \"module__n_hidden2\": 16,\n",
    "                            \"module__n_hidden3\": 8,  \"module__n_hidden4\": 4,\n",
    "                            \"module__n_output\": 1}\n",
    "        NN4_param = {'module__dropout': [0.2, 0.4, 0.6, 0.8],\n",
    "                     'lr': [0.001, 0.01],\n",
    "                     'optimizer__weight_decay': [0.1, 0.01, 0.001]}\n",
    "        for param in ParameterGrid(NN4_param):\n",
    "            NN4 = NeuralNetRegressor(Net4, verbose=0, max_epochs=200,\n",
    "                                     optimizer=torch.optim.SGD,\n",
    "                                     **NN4_architecture, **param)\n",
    "            NN4.fit(X_train_tensor, y_train_tensor)\n",
    "            mse = mean_squared_error(NN4.predict(X_validation_tensor), y_validation)\n",
    "            NN4_result[str(param)] = mse\n",
    "\n",
    "        #\n",
    "        NN4_best_param = eval(min(NN4_result, key=NN4_result.get))\n",
    "        NN4_model = NeuralNetRegressor(Net4, verbose=0, max_epochs=200, optimizer=torch.optim.SGD,\n",
    "                                       **NN4_architecture, **NN4_best_param)\n",
    "        NN4_model.fit(X_train_all_tensor, y_train_all_tensor)\n",
    "        y_pred_NN4_1990.append(NN4_model.predict(torch.tensor(predictor[[t], 1:n_cols], dtype=torch.float))[0][0])\n",
    "\n",
    "\n",
    "        ## Other commmonly used ML methods\n",
    "        # Ridge\n",
    "        Ridge_param = {'alpha': list(10 ** np.arange(0, 20 + 0.001, 1))}\n",
    "        Ridge_result = {}\n",
    "        for param in ParameterGrid(Ridge_param):\n",
    "            RIDGE = Ridge(**param)\n",
    "            RIDGE.fit(X_train, y_train)\n",
    "            mse = mean_squared_error(RIDGE.predict(X_validation), y_validation)\n",
    "            Ridge_result[str(param)] = mse\n",
    "        #\n",
    "        Ridge_best_param = eval(min(Ridge_result, key=Ridge_result.get))\n",
    "        Ridge_model = Ridge(**Ridge_best_param)\n",
    "        Ridge_model.fit(X_train_all, y_train_all)\n",
    "        y_pred_Ridge_1990.append(Ridge_model.predict(predictor[[t], 1:n_cols])[0])\n",
    "\n",
    "    else:\n",
    "        month_index += 1\n",
    "        y_pred_PLS_1990.append(PLS_model.predict(predictor[[t], 1:n_cols])[0][0])\n",
    "        y_pred_PCR_1990.append(PCR_forecast.predict(PCR_model.transform(predictor[[t], 1:n_cols]))[0])\n",
    "        y_pred_LASSO_1990.append(LASSO_model.predict(predictor[[t], 1:n_cols])[0])\n",
    "        y_pred_ENet_1990.append(ENet_model.predict(predictor[[t], 1:n_cols])[0])\n",
    "        y_pred_RF_1990.append(RF_model.predict(predictor[[t], 1:n_cols])[0])\n",
    "        y_pred_NN2_1990.append(NN2_model.predict(torch.tensor(predictor[[t], 1:n_cols], dtype=torch.float))[0][0])\n",
    "        y_pred_NN4_1990.append(NN4_model.predict(torch.tensor(predictor[[t], 1:n_cols], dtype=torch.float))[0][0])\n",
    "        # Other commonly used ML methods\n",
    "        y_pred_Ridge_1990.append(Ridge_model.predict(predictor[[t], 1:n_cols])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6a1f3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ml_pred_1990 = pd.DataFrame(np.array([y_pred_PLS_1990, y_pred_PCR_1990, y_pred_LASSO_1990,\n",
    "                                   y_pred_ENet_1990, y_pred_RF_1990, y_pred_NN2_1990,  \n",
    "                                   y_pred_NN4_1990, y_pred_Ridge_1990]),\n",
    "                         index=['PLS', 'PCR', 'LASSO', 'ENet', \n",
    "                                'RF', 'NN2', 'NN4', 'Ridge'],\n",
    "                         columns=predictor_df.month[in_out_1990:N]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8378dc2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xingfuxu/PycharmProjects/EquityPremiumPredictionML-Jupyter/Perform_PT_test.py:38: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  stat = (p_hat - p_star) / np.sqrt(p_hat_var - p_star_var)\n"
     ]
    }
   ],
   "source": [
    "# Performance compared with HA benchmark\n",
    "\n",
    "def compute_oos_r_square(actual, y_benchmark, y_pred):\n",
    "    MSFE_benchmark = mean_squared_error(y_benchmark, actual)\n",
    "    MSFE_pred = mean_squared_error(y_pred, actual)\n",
    "    return 1 - MSFE_pred / MSFE_benchmark\n",
    "\n",
    "\n",
    "ml_oos_performance_1990 = []\n",
    "\n",
    "for col in y_ml_pred_1990.columns:\n",
    "    oos_r_square = compute_oos_r_square(actual_1990, y_pred_HA_1990, y_ml_pred_1990[[col]].to_numpy())\n",
    "    MSFE_adjusted, pvalue_MSFE = CW_test(actual_1990, y_pred_HA_1990, y_ml_pred_1990[[col]].to_numpy())\n",
    "    success_ratio, PT_stat, pvalue_PT = PT_test(actual_1990, y_ml_pred_1990[[col]].to_numpy())\n",
    "    ml_oos_performance_1990.append([oos_r_square * 100, MSFE_adjusted, pvalue_MSFE, success_ratio * 100, PT_stat, pvalue_PT])\n",
    "\n",
    "\n",
    "ml_oos_performance_df_1990 = pd.DataFrame(np.array(ml_oos_performance_1990),index=y_ml_pred_1990.columns,\n",
    "                                     columns=['oos_r_square', 'MSFE_adjusted', 'pvalue_MSFE',\n",
    "                                              'success_ratio', 'PT_stat', 'pvalue_PT'])\n",
    "# success ratio of HA\n",
    "success_ratio_HA_1990, PT_HA_1990, p2_HA_1990 = PT_test(actual_1990, y_pred_HA_1990)\n",
    "ml_oos_performance_df_1990.loc['HA'] = [0, np.nan, np.nan, success_ratio_HA_1990 * 100, PT_HA_1990, p2_HA_1990]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "778a98a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>oos_r_square</th>\n",
       "      <th>MSFE_adjusted</th>\n",
       "      <th>pvalue_MSFE</th>\n",
       "      <th>success_ratio</th>\n",
       "      <th>PT_stat</th>\n",
       "      <th>pvalue_PT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PLS</th>\n",
       "      <td>-8.452069</td>\n",
       "      <td>-0.151539</td>\n",
       "      <td>0.560225</td>\n",
       "      <td>54.447439</td>\n",
       "      <td>0.090032</td>\n",
       "      <td>0.464131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCR</th>\n",
       "      <td>0.285366</td>\n",
       "      <td>0.990723</td>\n",
       "      <td>0.160911</td>\n",
       "      <td>60.916442</td>\n",
       "      <td>1.703533</td>\n",
       "      <td>0.044234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LASSO</th>\n",
       "      <td>-4.158772</td>\n",
       "      <td>0.119523</td>\n",
       "      <td>0.452431</td>\n",
       "      <td>60.646900</td>\n",
       "      <td>-0.043857</td>\n",
       "      <td>0.517491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENet</th>\n",
       "      <td>-4.174305</td>\n",
       "      <td>0.064894</td>\n",
       "      <td>0.474129</td>\n",
       "      <td>60.107817</td>\n",
       "      <td>-0.276725</td>\n",
       "      <td>0.609004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>-15.348813</td>\n",
       "      <td>-2.453392</td>\n",
       "      <td>0.992924</td>\n",
       "      <td>57.412399</td>\n",
       "      <td>-1.332976</td>\n",
       "      <td>0.908730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN2</th>\n",
       "      <td>-0.219362</td>\n",
       "      <td>1.073776</td>\n",
       "      <td>0.141461</td>\n",
       "      <td>63.072776</td>\n",
       "      <td>0.398512</td>\n",
       "      <td>0.345127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN4</th>\n",
       "      <td>-3.560712</td>\n",
       "      <td>0.980573</td>\n",
       "      <td>0.163402</td>\n",
       "      <td>60.646900</td>\n",
       "      <td>1.110291</td>\n",
       "      <td>0.133437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>-4.704733</td>\n",
       "      <td>-0.034768</td>\n",
       "      <td>0.513868</td>\n",
       "      <td>60.646900</td>\n",
       "      <td>0.225725</td>\n",
       "      <td>0.410708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HA</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64.150943</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       oos_r_square  MSFE_adjusted  pvalue_MSFE  success_ratio   PT_stat  \\\n",
       "PLS       -8.452069      -0.151539     0.560225      54.447439  0.090032   \n",
       "PCR        0.285366       0.990723     0.160911      60.916442  1.703533   \n",
       "LASSO     -4.158772       0.119523     0.452431      60.646900 -0.043857   \n",
       "ENet      -4.174305       0.064894     0.474129      60.107817 -0.276725   \n",
       "RF       -15.348813      -2.453392     0.992924      57.412399 -1.332976   \n",
       "NN2       -0.219362       1.073776     0.141461      63.072776  0.398512   \n",
       "NN4       -3.560712       0.980573     0.163402      60.646900  1.110291   \n",
       "Ridge     -4.704733      -0.034768     0.513868      60.646900  0.225725   \n",
       "HA         0.000000            NaN          NaN      64.150943       NaN   \n",
       "\n",
       "       pvalue_PT  \n",
       "PLS     0.464131  \n",
       "PCR     0.044234  \n",
       "LASSO   0.517491  \n",
       "ENet    0.609004  \n",
       "RF      0.908730  \n",
       "NN2     0.345127  \n",
       "NN4     0.133437  \n",
       "Ridge   0.410708  \n",
       "HA           NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save\n",
    "import openpyxl\n",
    "with pd.ExcelWriter(\"ml_equity_premium_robust_checks.xlsx\", engine='openpyxl', mode='a') as writer:\n",
    "    ml_oos_performance_df_1990.to_excel(writer, sheet_name='Alternative_window_sizes')\n",
    "ml_oos_performance_df_1990"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ab039d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
