{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2df2b249",
   "metadata": {},
   "source": [
    "### Rolling window estimation schemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f822b3b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/xingfuxu/PycharmProjects/EquityPremiumPredictionML-Jupyter'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "# os.chdir(path)    # or you can set your working dir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3c1c50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your working dir should include \"NN_models.py\", Perform_CW_test.py\" and \"Perform_PT_test.py\" files.\n",
    "from Perform_CW_test import CW_test\n",
    "from Perform_PT_test import PT_test\n",
    "from NN_models import Net2, Net4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e772b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import torch\n",
    "from skorch import NeuralNetRegressor\n",
    "from tqdm import tqdm\n",
    "#\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "#\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50dbea16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>log_equity_premium</th>\n",
       "      <th>equity_premium</th>\n",
       "      <th>DP</th>\n",
       "      <th>DY</th>\n",
       "      <th>EP</th>\n",
       "      <th>SVAR</th>\n",
       "      <th>BM</th>\n",
       "      <th>NTIS</th>\n",
       "      <th>TBL</th>\n",
       "      <th>...</th>\n",
       "      <th>MA_2_9</th>\n",
       "      <th>MA_2_12</th>\n",
       "      <th>MA_3_9</th>\n",
       "      <th>MA_3_12</th>\n",
       "      <th>MOM_1</th>\n",
       "      <th>MOM_2</th>\n",
       "      <th>MOM_3</th>\n",
       "      <th>MOM_6</th>\n",
       "      <th>MOM_9</th>\n",
       "      <th>MOM_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>192701</td>\n",
       "      <td>-0.005710</td>\n",
       "      <td>-0.00571</td>\n",
       "      <td>-2.942374</td>\n",
       "      <td>-2.963349</td>\n",
       "      <td>-2.374773</td>\n",
       "      <td>0.00047</td>\n",
       "      <td>0.44371</td>\n",
       "      <td>0.05082</td>\n",
       "      <td>3.23</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>192702</td>\n",
       "      <td>0.042017</td>\n",
       "      <td>0.04302</td>\n",
       "      <td>-2.979535</td>\n",
       "      <td>-2.932946</td>\n",
       "      <td>-2.430353</td>\n",
       "      <td>0.00029</td>\n",
       "      <td>0.42850</td>\n",
       "      <td>0.05167</td>\n",
       "      <td>3.29</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>192703</td>\n",
       "      <td>0.004697</td>\n",
       "      <td>0.00472</td>\n",
       "      <td>-2.976535</td>\n",
       "      <td>-2.970053</td>\n",
       "      <td>-2.445079</td>\n",
       "      <td>0.00092</td>\n",
       "      <td>0.46977</td>\n",
       "      <td>0.04636</td>\n",
       "      <td>3.20</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>192704</td>\n",
       "      <td>0.009940</td>\n",
       "      <td>0.01002</td>\n",
       "      <td>-2.984225</td>\n",
       "      <td>-2.967143</td>\n",
       "      <td>-2.471309</td>\n",
       "      <td>0.00060</td>\n",
       "      <td>0.45675</td>\n",
       "      <td>0.05051</td>\n",
       "      <td>3.39</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>192705</td>\n",
       "      <td>0.057987</td>\n",
       "      <td>0.05985</td>\n",
       "      <td>-3.025963</td>\n",
       "      <td>-2.975058</td>\n",
       "      <td>-2.531446</td>\n",
       "      <td>0.00039</td>\n",
       "      <td>0.43478</td>\n",
       "      <td>0.05528</td>\n",
       "      <td>3.33</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    month  log_equity_premium  equity_premium        DP        DY        EP  \\\n",
       "0  192701           -0.005710        -0.00571 -2.942374 -2.963349 -2.374773   \n",
       "1  192702            0.042017         0.04302 -2.979535 -2.932946 -2.430353   \n",
       "2  192703            0.004697         0.00472 -2.976535 -2.970053 -2.445079   \n",
       "3  192704            0.009940         0.01002 -2.984225 -2.967143 -2.471309   \n",
       "4  192705            0.057987         0.05985 -3.025963 -2.975058 -2.531446   \n",
       "\n",
       "      SVAR       BM     NTIS   TBL  ...  MA_2_9  MA_2_12  MA_3_9  MA_3_12  \\\n",
       "0  0.00047  0.44371  0.05082  3.23  ...       1        1       1        1   \n",
       "1  0.00029  0.42850  0.05167  3.29  ...       1        1       1        1   \n",
       "2  0.00092  0.46977  0.04636  3.20  ...       1        1       1        1   \n",
       "3  0.00060  0.45675  0.05051  3.39  ...       1        1       1        1   \n",
       "4  0.00039  0.43478  0.05528  3.33  ...       1        1       1        1   \n",
       "\n",
       "   MOM_1  MOM_2  MOM_3  MOM_6  MOM_9  MOM_12  \n",
       "0      0      0      1      1      1       1  \n",
       "1      1      1      1      1      1       1  \n",
       "2      1      1      1      1      1       1  \n",
       "3      1      1      1      1      1       1  \n",
       "4      1      1      1      1      1       1  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set seed\n",
    "torch.manual_seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "# read data\n",
    "predictor_df = pd.read_excel(open('ml_equity_premium_data.xlsx', 'rb'), sheet_name='result_predictor')\n",
    "predictor_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5218722b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove irrelavent columns\n",
    "predictor0 = predictor_df.drop(['month', 'equity_premium'], axis=1)\n",
    "# get all the predictors and set the log equity premium 1-month ahead\n",
    "predictor = np.concatenate([predictor0['log_equity_premium'][1:].values.reshape(-1, 1),\n",
    "                            predictor0.iloc[0:(predictor0.shape[0] - 1), 1:]], axis=1)\n",
    "\n",
    "# number of rows\n",
    "N = predictor.shape[0]\n",
    "\n",
    "# number of all columns, including the log equity premium\n",
    "n_cols = predictor.shape[1]\n",
    "\n",
    "# Actual one-month ahead log equity premium\n",
    "actual = predictor[:, [0]]\n",
    "\n",
    "# Historical average forecasting as benchmark\n",
    "y_pred_HA = predictor0['log_equity_premium'].values[0:(predictor0.shape[0] - 1), ].cumsum() / np.arange(1, N + 1)\n",
    "y_pred_HA = y_pred_HA.reshape(-1, 1)\n",
    "\n",
    "# Compute out-of-sample R-squared\n",
    "def compute_oos_r_square(actual, y_benchmark, y_pred):\n",
    "    MSFE_benchmark = mean_squared_error(y_benchmark, actual)\n",
    "    MSFE_pred = mean_squared_error(y_pred, actual)\n",
    "    return 1 - MSFE_pred / MSFE_benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ba6df3",
   "metadata": {},
   "source": [
    "### Five years rolling estimation scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b69658e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 767/767 [25:36<00:00,  2.00s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>oos_r_square</th>\n",
       "      <th>MSFE_adjusted</th>\n",
       "      <th>pvalue_MSFE</th>\n",
       "      <th>success_ratio</th>\n",
       "      <th>PT_stat</th>\n",
       "      <th>pvalue_PT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PLS</th>\n",
       "      <td>-47.239596</td>\n",
       "      <td>1.083377</td>\n",
       "      <td>0.139321</td>\n",
       "      <td>52.411995</td>\n",
       "      <td>-0.164357</td>\n",
       "      <td>0.565275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCR</th>\n",
       "      <td>-11.831484</td>\n",
       "      <td>0.818648</td>\n",
       "      <td>0.206494</td>\n",
       "      <td>56.062581</td>\n",
       "      <td>1.013248</td>\n",
       "      <td>0.155471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LASSO</th>\n",
       "      <td>-82.461558</td>\n",
       "      <td>-0.003547</td>\n",
       "      <td>0.501415</td>\n",
       "      <td>57.105606</td>\n",
       "      <td>1.118965</td>\n",
       "      <td>0.131578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENet</th>\n",
       "      <td>-74.396652</td>\n",
       "      <td>0.606137</td>\n",
       "      <td>0.272212</td>\n",
       "      <td>55.410691</td>\n",
       "      <td>0.585414</td>\n",
       "      <td>0.279135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>-16.913349</td>\n",
       "      <td>0.194882</td>\n",
       "      <td>0.422743</td>\n",
       "      <td>52.542373</td>\n",
       "      <td>-0.226891</td>\n",
       "      <td>0.589746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN2</th>\n",
       "      <td>-102.982502</td>\n",
       "      <td>-0.304749</td>\n",
       "      <td>0.619721</td>\n",
       "      <td>46.675359</td>\n",
       "      <td>-2.474727</td>\n",
       "      <td>0.993333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN4</th>\n",
       "      <td>-358.211154</td>\n",
       "      <td>-0.810580</td>\n",
       "      <td>0.791197</td>\n",
       "      <td>51.499348</td>\n",
       "      <td>-1.006715</td>\n",
       "      <td>0.842964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>-26.633373</td>\n",
       "      <td>0.143339</td>\n",
       "      <td>0.443011</td>\n",
       "      <td>56.453716</td>\n",
       "      <td>0.790713</td>\n",
       "      <td>0.214556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HA</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.973924</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       oos_r_square  MSFE_adjusted  pvalue_MSFE  success_ratio   PT_stat  \\\n",
       "PLS      -47.239596       1.083377     0.139321      52.411995 -0.164357   \n",
       "PCR      -11.831484       0.818648     0.206494      56.062581  1.013248   \n",
       "LASSO    -82.461558      -0.003547     0.501415      57.105606  1.118965   \n",
       "ENet     -74.396652       0.606137     0.272212      55.410691  0.585414   \n",
       "RF       -16.913349       0.194882     0.422743      52.542373 -0.226891   \n",
       "NN2     -102.982502      -0.304749     0.619721      46.675359 -2.474727   \n",
       "NN4     -358.211154      -0.810580     0.791197      51.499348 -1.006715   \n",
       "Ridge    -26.633373       0.143339     0.443011      56.453716  0.790713   \n",
       "HA         0.000000            NaN          NaN      59.973924       NaN   \n",
       "\n",
       "       pvalue_PT  \n",
       "PLS     0.565275  \n",
       "PCR     0.155471  \n",
       "LASSO   0.131578  \n",
       "ENet    0.279135  \n",
       "RF      0.589746  \n",
       "NN2     0.993333  \n",
       "NN4     0.842964  \n",
       "Ridge   0.214556  \n",
       "HA           NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Out-of-sample: 1957:01-2020:12\n",
    "in_out_1957 = predictor_df.index[predictor_df['month'] == 195701][0]\n",
    "actual_1957 = actual[in_out_1957:, ]\n",
    "y_pred_HA_1957 = y_pred_HA[in_out_1957:, ]\n",
    "MSFE_HA_1957 = mean_squared_error(y_pred_HA_1957, actual_1957)\n",
    "\n",
    "# Machine Learning methods used in GKX (2020)\n",
    "y_pred_PLS_1957, y_pred_PCR_1957,  y_pred_LASSO_1957 = [], [], []\n",
    "y_pred_ENet_1957, y_pred_RF_1957 = [], []\n",
    "y_pred_NN2_1957, y_pred_NN4_1957 = [], []\n",
    "\n",
    "## Other commonly used machine learning method\n",
    "y_pred_Ridge_1957 = []\n",
    "\n",
    "# control the update month of models during out-of-sample period. \n",
    "month_index = 1  # We update our models annually, meaning we refresh them in months 1, 13, 25, ...\n",
    "\n",
    "\n",
    "for t in tqdm(range(in_out_1957, N)):\n",
    "    #\n",
    "    warnings.filterwarnings('ignore')\n",
    "    X_train_all = predictor[(t - 5 * 12):t, 1:n_cols]\n",
    "    y_train_all = predictor[(t - 5 * 12):t, 0]\n",
    "    # set 15% of all the train data as validation set\n",
    "    X_train = X_train_all[0:int(len(X_train_all) * 0.85), :]\n",
    "    X_validation = X_train_all[int(len(X_train_all) * 0.85):t, :]\n",
    "    y_train = y_train_all[0:int(len(X_train_all) * 0.85)]\n",
    "    y_validation = y_train_all[int(len(X_train_all) * 0.85):t]\n",
    "    #\n",
    "    if month_index % 12 == 1:\n",
    "        month_index += 1\n",
    "\n",
    "        # PLS\n",
    "        PLS_param = {'n_components': [1, 2, 3, 4, 5, 6, 7, 8]}\n",
    "        PLS_result = {}\n",
    "        for param in ParameterGrid(PLS_param):\n",
    "            PLS = PLSRegression(**param)\n",
    "            PLS.fit(X_train, y_train)\n",
    "            mse = mean_squared_error(PLS.predict(X_validation), y_validation)\n",
    "            PLS_result[str(param)] = mse\n",
    "\n",
    "        PLS_best_param = eval(min(PLS_result, key=PLS_result.get))\n",
    "        PLS_model = PLSRegression(**PLS_best_param)\n",
    "        PLS_model.fit(X_train_all, y_train_all)\n",
    "        y_pred_PLS_1957.append(PLS_model.predict(predictor[[t], 1:n_cols])[0][0])\n",
    "\n",
    "        # PCR\n",
    "        PCR_param = {'n_components': [1, 2, 3, 4, 5, 6, 7, 8]}\n",
    "        PCR_result = {}\n",
    "        for param in ParameterGrid(PCR_param):\n",
    "            pca = PCA(**param)\n",
    "            pca.fit(X_train)\n",
    "            comps = pca.transform(X_train)\n",
    "            forecast = LinearRegression()\n",
    "            forecast.fit(comps, y_train)\n",
    "            mse = mean_squared_error(forecast.predict(pca.transform(X_validation)), y_validation)\n",
    "            PCR_result[str(param)] = mse\n",
    "        #\n",
    "        PCR_best_param = eval(min(PCR_result, key=PCR_result.get))\n",
    "        #\n",
    "        PCR_model = PCA(**PCR_best_param)\n",
    "        PCR_model.fit(X_train_all)\n",
    "        PCR_comps = PCR_model.transform(X_train_all)\n",
    "        PCR_forecast = LinearRegression()\n",
    "        PCR_forecast.fit(PCR_comps, y_train_all)\n",
    "        y_pred_PCR_1957.append(PCR_forecast.predict(PCR_model.transform(predictor[[t], 1:n_cols]))[0])\n",
    "\n",
    "        # LASSO\n",
    "        LASSO_param = {'alpha': list(10 ** np.arange(-4, 1 + 0.001, 0.2))}\n",
    "        LASSO_result = {}\n",
    "        for param in ParameterGrid(LASSO_param):\n",
    "            LASSO = Lasso(**param)\n",
    "            LASSO.fit(X_train, y_train)\n",
    "            mse = mean_squared_error(LASSO.predict(X_validation), y_validation)\n",
    "            LASSO_result[str(param)] = mse\n",
    "        #\n",
    "        LASSO_best_param = eval(min(LASSO_result, key=LASSO_result.get))\n",
    "        #\n",
    "        LASSO_model = Lasso(**LASSO_best_param)\n",
    "        LASSO_model.fit(X_train_all, y_train_all)\n",
    "        y_pred_LASSO_1957.append(LASSO_model.predict(predictor[[t], 1:n_cols])[0])\n",
    "\n",
    "        # ENet\n",
    "        ENet_param = {'alpha': list(10 ** np.arange(-4, 1 + 0.001, 0.2)),\n",
    "                      'l1_ratio': list(np.arange(0.2, 1, 0.3))}\n",
    "        ENet_result = {}\n",
    "        for param in ParameterGrid(ENet_param):\n",
    "            ENet = ElasticNet(**param, tol=1e-2)\n",
    "            ENet.fit(X_train, y_train)\n",
    "            mse = mean_squared_error(ENet.predict(X_validation), y_validation)\n",
    "            ENet_result[str(param)] = mse\n",
    "\n",
    "        ENet_best_param = eval(min(ENet_result, key=ENet_result.get))\n",
    "        ENet_model = ElasticNet(**ENet_best_param, tol=1e-2)\n",
    "        ENet_model.fit(X_train_all, y_train_all)\n",
    "        y_pred_ENet_1957.append(ENet_model.predict(predictor[[t], 1:n_cols])[0])\n",
    "\n",
    "\n",
    "        # RF\n",
    "        RF_param = {'n_estimators': [10, 50, 100, 150, 200],\n",
    "                    'max_depth': [2, 3, 4],\n",
    "                    'min_samples_leaf': [1, 3, 5]}\n",
    "        RF_result = {}\n",
    "        for param in ParameterGrid(RF_param):\n",
    "            RF = RandomForestRegressor(**param)\n",
    "            RF.fit(X_train, y_train)\n",
    "            mse = mean_squared_error(RF.predict(X_validation), y_validation)\n",
    "            RF_result[str(param)] = mse\n",
    "\n",
    "        RF_best_param = eval(min(RF_result, key=RF_result.get))\n",
    "        RF_model = RandomForestRegressor(**RF_best_param)\n",
    "        RF_model.fit(X_train_all, y_train_all)\n",
    "        y_pred_RF_1957.append(RF_model.predict(predictor[[t], 1:n_cols])[0])\n",
    "\n",
    "        # Neural Network Models: NN2 & NN4\n",
    "        X_train_all_tensor = torch.tensor(X_train_all, dtype=torch.float)\n",
    "        y_train_all_tensor = torch.tensor(y_train_all.reshape(-1, 1), dtype=torch.float)\n",
    "        X_train_tensor = torch.tensor(X_train, dtype=torch.float)\n",
    "        y_train_tensor = torch.tensor(y_train.reshape(-1, 1), dtype=torch.float)\n",
    "        X_validation_tensor = torch.tensor(X_validation, dtype=torch.float)\n",
    "        y_validation_tensor = torch.tensor(y_validation.reshape(-1, 1), dtype=torch.float)\n",
    "\n",
    "        # NN2\n",
    "        NN2_result = {}\n",
    "        NN2_architecture = {\"module__n_feature\": X_train_tensor.shape[1],\n",
    "                            \"module__n_hidden1\": 32, \"module__n_hidden2\": 16,\n",
    "                            \"module__n_output\": 1}\n",
    "        NN2_param = {'module__dropout': [0.2, 0.4, 0.6, 0.8],\n",
    "                    'lr': [0.001, 0.01],\n",
    "                    'optimizer__weight_decay': [0.1, 0.01, 0.001]}\n",
    "        for param in ParameterGrid(NN2_param):\n",
    "            NN2 = NeuralNetRegressor(Net2, verbose=0, max_epochs=200,\n",
    "                                     optimizer=torch.optim.SGD,\n",
    "                                     **NN2_architecture, **param)\n",
    "            NN2.fit(X_train_tensor, y_train_tensor)\n",
    "            mse = mean_squared_error(NN2.predict(X_validation_tensor), y_validation)\n",
    "            NN2_result[str(param)] = mse\n",
    "        \n",
    "        #\n",
    "        NN2_best_param = eval(min(NN2_result, key=NN2_result.get))\n",
    "        NN2_model = NeuralNetRegressor(Net2, verbose=0, max_epochs=200, optimizer=torch.optim.SGD,\n",
    "                                       **NN2_architecture, **NN2_best_param)\n",
    "        NN2_model.fit(X_train_all_tensor, y_train_all_tensor)\n",
    "        y_pred_NN2_1957.append(NN2_model.predict(torch.tensor(predictor[[t], 1:n_cols], dtype=torch.float))[0][0])\n",
    "        #\n",
    "\n",
    "\n",
    "        # NN4\n",
    "        NN4_result = {}\n",
    "        NN4_architecture = {\"module__n_feature\": X_train_tensor.shape[1],\n",
    "                            \"module__n_hidden1\": 32, \"module__n_hidden2\": 16,\n",
    "                            \"module__n_hidden3\": 8,  \"module__n_hidden4\": 4,\n",
    "                            \"module__n_output\": 1}\n",
    "        NN4_param = {'module__dropout': [0.2, 0.4, 0.6, 0.8],\n",
    "                     'lr': [0.001, 0.01],\n",
    "                     'optimizer__weight_decay': [0.1, 0.01, 0.001]}\n",
    "        for param in ParameterGrid(NN4_param):\n",
    "            NN4 = NeuralNetRegressor(Net4, verbose=0, max_epochs=200,\n",
    "                                     optimizer=torch.optim.SGD,\n",
    "                                     **NN4_architecture, **param)\n",
    "            NN4.fit(X_train_tensor, y_train_tensor)\n",
    "            mse = mean_squared_error(NN4.predict(X_validation_tensor), y_validation)\n",
    "            NN4_result[str(param)] = mse\n",
    "\n",
    "        #\n",
    "        NN4_best_param = eval(min(NN4_result, key=NN4_result.get))\n",
    "        NN4_model = NeuralNetRegressor(Net4, verbose=0, max_epochs=200, optimizer=torch.optim.SGD,\n",
    "                                       **NN4_architecture, **NN4_best_param)\n",
    "        NN4_model.fit(X_train_all_tensor, y_train_all_tensor)\n",
    "        y_pred_NN4_1957.append(NN4_model.predict(torch.tensor(predictor[[t], 1:n_cols], dtype=torch.float))[0][0])\n",
    "\n",
    "\n",
    "        ## Other commmonly used ML methods\n",
    "        # Ridge\n",
    "        Ridge_param = {'alpha': list(10 ** np.arange(0, 20 + 0.001, 1))}\n",
    "        Ridge_result = {}\n",
    "        for param in ParameterGrid(Ridge_param):\n",
    "            RIDGE = Ridge(**param)\n",
    "            RIDGE.fit(X_train, y_train)\n",
    "            mse = mean_squared_error(RIDGE.predict(X_validation), y_validation)\n",
    "            Ridge_result[str(param)] = mse\n",
    "        #\n",
    "        Ridge_best_param = eval(min(Ridge_result, key=Ridge_result.get))\n",
    "        Ridge_model = Ridge(**Ridge_best_param)\n",
    "        Ridge_model.fit(X_train_all, y_train_all)\n",
    "        y_pred_Ridge_1957.append(Ridge_model.predict(predictor[[t], 1:n_cols])[0])\n",
    "\n",
    "    else:\n",
    "        month_index += 1\n",
    "        y_pred_PLS_1957.append(PLS_model.predict(predictor[[t], 1:n_cols])[0][0])\n",
    "        y_pred_PCR_1957.append(PCR_forecast.predict(PCR_model.transform(predictor[[t], 1:n_cols]))[0])\n",
    "        y_pred_LASSO_1957.append(LASSO_model.predict(predictor[[t], 1:n_cols])[0])\n",
    "        y_pred_ENet_1957.append(ENet_model.predict(predictor[[t], 1:n_cols])[0])\n",
    "        y_pred_RF_1957.append(RF_model.predict(predictor[[t], 1:n_cols])[0])\n",
    "        y_pred_NN2_1957.append(NN2_model.predict(torch.tensor(predictor[[t], 1:n_cols], dtype=torch.float))[0][0])\n",
    "        y_pred_NN4_1957.append(NN4_model.predict(torch.tensor(predictor[[t], 1:n_cols], dtype=torch.float))[0][0])\n",
    "        # Other commonly used ML methods\n",
    "        y_pred_Ridge_1957.append(Ridge_model.predict(predictor[[t], 1:n_cols])[0])\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "y_ml_pred_1957 = pd.DataFrame(np.array([y_pred_PLS_1957, y_pred_PCR_1957, y_pred_LASSO_1957,\n",
    "                           y_pred_ENet_1957, y_pred_RF_1957, y_pred_NN2_1957,  \n",
    "                           y_pred_NN4_1957, y_pred_Ridge_1957]),\n",
    "                 index=['PLS', 'PCR', 'LASSO', 'ENet', \n",
    "                        'RF', 'NN2', 'NN4', 'Ridge'],\n",
    "                 columns=predictor_df.month[in_out_1957:N]).T\n",
    "\n",
    "# Performance compared with HA benchmark\n",
    "\n",
    "ml_oos_performance_5years = []\n",
    "\n",
    "for col in y_ml_pred_1957.columns:\n",
    "    oos_r_square = compute_oos_r_square(actual_1957, y_pred_HA_1957, y_ml_pred_1957[[col]].to_numpy())\n",
    "    MSFE_adjusted, pvalue_MSFE = CW_test(actual_1957, y_pred_HA_1957, y_ml_pred_1957[[col]].to_numpy())\n",
    "    success_ratio, PT_stat, pvalue_PT = PT_test(actual_1957, y_ml_pred_1957[[col]].to_numpy())\n",
    "    ml_oos_performance_5years.append([oos_r_square * 100, MSFE_adjusted, pvalue_MSFE, success_ratio * 100, PT_stat, pvalue_PT])\n",
    "\n",
    "\n",
    "ml_oos_performance_df_5years = pd.DataFrame(np.array(ml_oos_performance_5years),\n",
    "                                          index=y_ml_pred_1957.columns,\n",
    "                                          columns=['oos_r_square', 'MSFE_adjusted', 'pvalue_MSFE',\n",
    "                                                   'success_ratio', 'PT_stat', 'pvalue_PT'])\n",
    "# success ratio of HA\n",
    "success_ratio_HA_1957, PT_HA_1957, p2_HA_1957 = PT_test(actual_1957, y_pred_HA_1957)\n",
    "ml_oos_performance_df_5years.loc['HA'] = [0, np.nan, np.nan, success_ratio_HA_1957 * 100, PT_HA_1957, p2_HA_1957]\n",
    "ml_oos_performance_df_5years"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e9cffd",
   "metadata": {},
   "source": [
    "### Ten years rolling window estimation scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5dcc763",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 767/767 [35:01<00:00,  2.74s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>oos_r_square</th>\n",
       "      <th>MSFE_adjusted</th>\n",
       "      <th>pvalue_MSFE</th>\n",
       "      <th>success_ratio</th>\n",
       "      <th>PT_stat</th>\n",
       "      <th>pvalue_PT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PLS</th>\n",
       "      <td>-15.893212</td>\n",
       "      <td>1.049371</td>\n",
       "      <td>0.147004</td>\n",
       "      <td>55.410691</td>\n",
       "      <td>1.356501</td>\n",
       "      <td>0.087470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCR</th>\n",
       "      <td>-6.902878</td>\n",
       "      <td>0.899997</td>\n",
       "      <td>0.184061</td>\n",
       "      <td>57.757497</td>\n",
       "      <td>1.715461</td>\n",
       "      <td>0.043130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LASSO</th>\n",
       "      <td>-4.771582</td>\n",
       "      <td>1.970124</td>\n",
       "      <td>0.024412</td>\n",
       "      <td>59.843546</td>\n",
       "      <td>2.558406</td>\n",
       "      <td>0.005258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENet</th>\n",
       "      <td>-5.346111</td>\n",
       "      <td>1.982762</td>\n",
       "      <td>0.023697</td>\n",
       "      <td>59.843546</td>\n",
       "      <td>2.747300</td>\n",
       "      <td>0.003004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>-14.836244</td>\n",
       "      <td>0.534075</td>\n",
       "      <td>0.296645</td>\n",
       "      <td>51.368970</td>\n",
       "      <td>-0.222107</td>\n",
       "      <td>0.587885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN2</th>\n",
       "      <td>-100.028150</td>\n",
       "      <td>0.707580</td>\n",
       "      <td>0.239603</td>\n",
       "      <td>52.542373</td>\n",
       "      <td>0.229788</td>\n",
       "      <td>0.409128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN4</th>\n",
       "      <td>-103.312912</td>\n",
       "      <td>-1.065146</td>\n",
       "      <td>0.856595</td>\n",
       "      <td>55.541069</td>\n",
       "      <td>1.161620</td>\n",
       "      <td>0.122695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>-5.562798</td>\n",
       "      <td>1.265462</td>\n",
       "      <td>0.102853</td>\n",
       "      <td>58.930900</td>\n",
       "      <td>2.325955</td>\n",
       "      <td>0.010010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HA</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.973924</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       oos_r_square  MSFE_adjusted  pvalue_MSFE  success_ratio   PT_stat  \\\n",
       "PLS      -15.893212       1.049371     0.147004      55.410691  1.356501   \n",
       "PCR       -6.902878       0.899997     0.184061      57.757497  1.715461   \n",
       "LASSO     -4.771582       1.970124     0.024412      59.843546  2.558406   \n",
       "ENet      -5.346111       1.982762     0.023697      59.843546  2.747300   \n",
       "RF       -14.836244       0.534075     0.296645      51.368970 -0.222107   \n",
       "NN2     -100.028150       0.707580     0.239603      52.542373  0.229788   \n",
       "NN4     -103.312912      -1.065146     0.856595      55.541069  1.161620   \n",
       "Ridge     -5.562798       1.265462     0.102853      58.930900  2.325955   \n",
       "HA         0.000000            NaN          NaN      59.973924       NaN   \n",
       "\n",
       "       pvalue_PT  \n",
       "PLS     0.087470  \n",
       "PCR     0.043130  \n",
       "LASSO   0.005258  \n",
       "ENet    0.003004  \n",
       "RF      0.587885  \n",
       "NN2     0.409128  \n",
       "NN4     0.122695  \n",
       "Ridge   0.010010  \n",
       "HA           NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Out-of-sample: 1957:01-2020:12\n",
    "in_out_1957 = predictor_df.index[predictor_df['month'] == 195701][0]\n",
    "actual_1957 = actual[in_out_1957:, ]\n",
    "y_pred_HA_1957 = y_pred_HA[in_out_1957:, ]\n",
    "MSFE_HA_1957 = mean_squared_error(y_pred_HA_1957, actual_1957)\n",
    "\n",
    "# Machine Learning methods used in GKX (2020)\n",
    "y_pred_PLS_1957, y_pred_PCR_1957,  y_pred_LASSO_1957 = [], [], []\n",
    "y_pred_ENet_1957, y_pred_RF_1957 = [], []\n",
    "y_pred_NN2_1957, y_pred_NN4_1957 = [], []\n",
    "\n",
    "## Other commonly used machine learning method\n",
    "y_pred_Ridge_1957 = []\n",
    "\n",
    "# control the update month of models during out-of-sample period. \n",
    "month_index = 1  # We update our models annually, meaning we refresh them in months 1, 13, 25, ...\n",
    "\n",
    "\n",
    "for t in tqdm(range(in_out_1957, N)):\n",
    "    #\n",
    "    X_train_all = predictor[(t - 10 * 12):t, 1:n_cols]\n",
    "    y_train_all = predictor[(t - 10 * 12):t, 0]\n",
    "    # set 15% of all the train data as validation set\n",
    "    X_train = X_train_all[0:int(len(X_train_all) * 0.85), :]\n",
    "    X_validation = X_train_all[int(len(X_train_all) * 0.85):t, :]\n",
    "    y_train = y_train_all[0:int(len(X_train_all) * 0.85)]\n",
    "    y_validation = y_train_all[int(len(X_train_all) * 0.85):t]\n",
    "    #\n",
    "    if month_index % 12 == 1:\n",
    "        month_index += 1\n",
    "\n",
    "        # PLS\n",
    "        PLS_param = {'n_components': [1, 2, 3, 4, 5, 6, 7, 8]}\n",
    "        PLS_result = {}\n",
    "        for param in ParameterGrid(PLS_param):\n",
    "            PLS = PLSRegression(**param)\n",
    "            PLS.fit(X_train, y_train)\n",
    "            mse = mean_squared_error(PLS.predict(X_validation), y_validation)\n",
    "            PLS_result[str(param)] = mse\n",
    "\n",
    "        PLS_best_param = eval(min(PLS_result, key=PLS_result.get))\n",
    "        PLS_model = PLSRegression(**PLS_best_param)\n",
    "        PLS_model.fit(X_train_all, y_train_all)\n",
    "        y_pred_PLS_1957.append(PLS_model.predict(predictor[[t], 1:n_cols])[0][0])\n",
    "\n",
    "        # PCR\n",
    "        PCR_param = {'n_components': [1, 2, 3, 4, 5, 6, 7, 8]}\n",
    "        PCR_result = {}\n",
    "        for param in ParameterGrid(PCR_param):\n",
    "            pca = PCA(**param)\n",
    "            pca.fit(X_train)\n",
    "            comps = pca.transform(X_train)\n",
    "            forecast = LinearRegression()\n",
    "            forecast.fit(comps, y_train)\n",
    "            mse = mean_squared_error(forecast.predict(pca.transform(X_validation)), y_validation)\n",
    "            PCR_result[str(param)] = mse\n",
    "        #\n",
    "        PCR_best_param = eval(min(PCR_result, key=PCR_result.get))\n",
    "        #\n",
    "        PCR_model = PCA(**PCR_best_param)\n",
    "        PCR_model.fit(X_train_all)\n",
    "        PCR_comps = PCR_model.transform(X_train_all)\n",
    "        PCR_forecast = LinearRegression()\n",
    "        PCR_forecast.fit(PCR_comps, y_train_all)\n",
    "        y_pred_PCR_1957.append(PCR_forecast.predict(PCR_model.transform(predictor[[t], 1:n_cols]))[0])\n",
    "\n",
    "        # LASSO\n",
    "        LASSO_param = {'alpha': list(10 ** np.arange(-4, 1 + 0.001, 0.2))}\n",
    "        LASSO_result = {}\n",
    "        for param in ParameterGrid(LASSO_param):\n",
    "            LASSO = Lasso(**param)\n",
    "            LASSO.fit(X_train, y_train)\n",
    "            mse = mean_squared_error(LASSO.predict(X_validation), y_validation)\n",
    "            LASSO_result[str(param)] = mse\n",
    "        #\n",
    "        LASSO_best_param = eval(min(LASSO_result, key=LASSO_result.get))\n",
    "        #\n",
    "        LASSO_model = Lasso(**LASSO_best_param)\n",
    "        LASSO_model.fit(X_train_all, y_train_all)\n",
    "        y_pred_LASSO_1957.append(LASSO_model.predict(predictor[[t], 1:n_cols])[0])\n",
    "\n",
    "        # ENet\n",
    "        ENet_param = {'alpha': list(10 ** np.arange(-4, 1 + 0.001, 0.2)),\n",
    "                      'l1_ratio': list(np.arange(0.2, 1, 0.3))}\n",
    "        ENet_result = {}\n",
    "        for param in ParameterGrid(ENet_param):\n",
    "            ENet = ElasticNet(**param)\n",
    "            ENet.fit(X_train, y_train)\n",
    "            mse = mean_squared_error(ENet.predict(X_validation), y_validation)\n",
    "            ENet_result[str(param)] = mse\n",
    "\n",
    "        ENet_best_param = eval(min(ENet_result, key=ENet_result.get))\n",
    "        ENet_model = ElasticNet(**ENet_best_param)\n",
    "        ENet_model.fit(X_train_all, y_train_all)\n",
    "        y_pred_ENet_1957.append(ENet_model.predict(predictor[[t], 1:n_cols])[0])\n",
    "\n",
    "\n",
    "        # RF\n",
    "        RF_param = {'n_estimators': [10, 50, 100, 150, 200],\n",
    "                    'max_depth': [2, 3, 4],\n",
    "                    'min_samples_leaf': [1, 3, 5]}\n",
    "        RF_result = {}\n",
    "        for param in ParameterGrid(RF_param):\n",
    "            RF = RandomForestRegressor(**param)\n",
    "            RF.fit(X_train, y_train)\n",
    "            mse = mean_squared_error(RF.predict(X_validation), y_validation)\n",
    "            RF_result[str(param)] = mse\n",
    "\n",
    "        RF_best_param = eval(min(RF_result, key=RF_result.get))\n",
    "        RF_model = RandomForestRegressor(**RF_best_param)\n",
    "        RF_model.fit(X_train_all, y_train_all)\n",
    "        y_pred_RF_1957.append(RF_model.predict(predictor[[t], 1:n_cols])[0])\n",
    "\n",
    "        # Neural Network Models: NN2 & NN4\n",
    "        X_train_all_tensor = torch.tensor(X_train_all, dtype=torch.float)\n",
    "        y_train_all_tensor = torch.tensor(y_train_all.reshape(-1, 1), dtype=torch.float)\n",
    "        X_train_tensor = torch.tensor(X_train, dtype=torch.float)\n",
    "        y_train_tensor = torch.tensor(y_train.reshape(-1, 1), dtype=torch.float)\n",
    "        X_validation_tensor = torch.tensor(X_validation, dtype=torch.float)\n",
    "        y_validation_tensor = torch.tensor(y_validation.reshape(-1, 1), dtype=torch.float)\n",
    "\n",
    "        # NN2\n",
    "        NN2_result = {}\n",
    "        NN2_architecture = {\"module__n_feature\": X_train_tensor.shape[1],\n",
    "                            \"module__n_hidden1\": 32, \"module__n_hidden2\": 16,\n",
    "                            \"module__n_output\": 1}\n",
    "        NN2_param = {'module__dropout': [0.2, 0.4, 0.6, 0.8],\n",
    "                    'lr': [0.001, 0.01],\n",
    "                    'optimizer__weight_decay': [0.1, 0.01, 0.001]}\n",
    "        for param in ParameterGrid(NN2_param):\n",
    "            NN2 = NeuralNetRegressor(Net2, verbose=0, max_epochs=200,\n",
    "                                     optimizer=torch.optim.SGD,\n",
    "                                     **NN2_architecture, **param)\n",
    "            NN2.fit(X_train_tensor, y_train_tensor)\n",
    "            mse = mean_squared_error(NN2.predict(X_validation_tensor), y_validation)\n",
    "            NN2_result[str(param)] = mse\n",
    "        \n",
    "        #\n",
    "        NN2_best_param = eval(min(NN2_result, key=NN2_result.get))\n",
    "        NN2_model = NeuralNetRegressor(Net2, verbose=0, max_epochs=200, optimizer=torch.optim.SGD,\n",
    "                                       **NN2_architecture, **NN2_best_param)\n",
    "        NN2_model.fit(X_train_all_tensor, y_train_all_tensor)\n",
    "        y_pred_NN2_1957.append(NN2_model.predict(torch.tensor(predictor[[t], 1:n_cols], dtype=torch.float))[0][0])\n",
    "        #\n",
    "\n",
    "\n",
    "        # NN4\n",
    "        NN4_result = {}\n",
    "        NN4_architecture = {\"module__n_feature\": X_train_tensor.shape[1],\n",
    "                            \"module__n_hidden1\": 32, \"module__n_hidden2\": 16,\n",
    "                            \"module__n_hidden3\": 8,  \"module__n_hidden4\": 4,\n",
    "                            \"module__n_output\": 1}\n",
    "        NN4_param = {'module__dropout': [0.2, 0.4, 0.6, 0.8],\n",
    "                     'lr': [0.001, 0.01],\n",
    "                     'optimizer__weight_decay': [0.1, 0.01, 0.001]}\n",
    "        for param in ParameterGrid(NN4_param):\n",
    "            NN4 = NeuralNetRegressor(Net4, verbose=0, max_epochs=200,\n",
    "                                     optimizer=torch.optim.SGD,\n",
    "                                     **NN4_architecture, **param)\n",
    "            NN4.fit(X_train_tensor, y_train_tensor)\n",
    "            mse = mean_squared_error(NN4.predict(X_validation_tensor), y_validation)\n",
    "            NN4_result[str(param)] = mse\n",
    "\n",
    "        #\n",
    "        NN4_best_param = eval(min(NN4_result, key=NN4_result.get))\n",
    "        NN4_model = NeuralNetRegressor(Net4, verbose=0, max_epochs=200, optimizer=torch.optim.SGD,\n",
    "                                       **NN4_architecture, **NN4_best_param)\n",
    "        NN4_model.fit(X_train_all_tensor, y_train_all_tensor)\n",
    "        y_pred_NN4_1957.append(NN4_model.predict(torch.tensor(predictor[[t], 1:n_cols], dtype=torch.float))[0][0])\n",
    "\n",
    "\n",
    "        ## Other commmonly used ML methods\n",
    "        # Ridge\n",
    "        Ridge_param = {'alpha': list(10 ** np.arange(0, 20 + 0.001, 1))}\n",
    "        Ridge_result = {}\n",
    "        for param in ParameterGrid(Ridge_param):\n",
    "            RIDGE = Ridge(**param)\n",
    "            RIDGE.fit(X_train, y_train)\n",
    "            mse = mean_squared_error(RIDGE.predict(X_validation), y_validation)\n",
    "            Ridge_result[str(param)] = mse\n",
    "        #\n",
    "        Ridge_best_param = eval(min(Ridge_result, key=Ridge_result.get))\n",
    "        Ridge_model = Ridge(**Ridge_best_param)\n",
    "        Ridge_model.fit(X_train_all, y_train_all)\n",
    "        y_pred_Ridge_1957.append(Ridge_model.predict(predictor[[t], 1:n_cols])[0])\n",
    "\n",
    "    else:\n",
    "        month_index += 1\n",
    "        y_pred_PLS_1957.append(PLS_model.predict(predictor[[t], 1:n_cols])[0][0])\n",
    "        y_pred_PCR_1957.append(PCR_forecast.predict(PCR_model.transform(predictor[[t], 1:n_cols]))[0])\n",
    "        y_pred_LASSO_1957.append(LASSO_model.predict(predictor[[t], 1:n_cols])[0])\n",
    "        y_pred_ENet_1957.append(ENet_model.predict(predictor[[t], 1:n_cols])[0])\n",
    "        y_pred_RF_1957.append(RF_model.predict(predictor[[t], 1:n_cols])[0])\n",
    "        y_pred_NN2_1957.append(NN2_model.predict(torch.tensor(predictor[[t], 1:n_cols], dtype=torch.float))[0][0])\n",
    "        y_pred_NN4_1957.append(NN4_model.predict(torch.tensor(predictor[[t], 1:n_cols], dtype=torch.float))[0][0])\n",
    "        # Other commonly used ML methods\n",
    "        y_pred_Ridge_1957.append(Ridge_model.predict(predictor[[t], 1:n_cols])[0])\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "y_ml_pred_1957 = pd.DataFrame(np.array([y_pred_PLS_1957, y_pred_PCR_1957, y_pred_LASSO_1957,\n",
    "                           y_pred_ENet_1957, y_pred_RF_1957, y_pred_NN2_1957,  \n",
    "                           y_pred_NN4_1957, y_pred_Ridge_1957]),\n",
    "                 index=['PLS', 'PCR', 'LASSO', 'ENet', \n",
    "                        'RF', 'NN2', 'NN4', 'Ridge'],\n",
    "                 columns=predictor_df.month[in_out_1957:N]).T\n",
    "\n",
    "# Performance compared with HA benchmark\n",
    "\n",
    "ml_oos_performance_10years = []\n",
    "\n",
    "for col in y_ml_pred_1957.columns:\n",
    "    oos_r_square = compute_oos_r_square(actual_1957, y_pred_HA_1957, y_ml_pred_1957[[col]].to_numpy())\n",
    "    MSFE_adjusted, pvalue_MSFE = CW_test(actual_1957, y_pred_HA_1957, y_ml_pred_1957[[col]].to_numpy())\n",
    "    success_ratio, PT_stat, pvalue_PT = PT_test(actual_1957, y_ml_pred_1957[[col]].to_numpy())\n",
    "    ml_oos_performance_10years.append([oos_r_square * 100, MSFE_adjusted, pvalue_MSFE, success_ratio * 100, PT_stat, pvalue_PT])\n",
    "\n",
    "\n",
    "ml_oos_performance_df_10years = pd.DataFrame(np.array(ml_oos_performance_10years),\n",
    "                                          index=y_ml_pred_1957.columns,\n",
    "                                          columns=['oos_r_square', 'MSFE_adjusted', 'pvalue_MSFE',\n",
    "                                                   'success_ratio', 'PT_stat', 'pvalue_PT'])\n",
    "ml_oos_performance_df_10years.loc['HA'] = [0, np.nan, np.nan, success_ratio_HA_1957 * 100, PT_HA_1957, p2_HA_1957]\n",
    "ml_oos_performance_df_10years"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4355e0",
   "metadata": {},
   "source": [
    "### Twenty years rolling window estimation scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6a1f3d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 767/767 [59:03<00:00,  4.62s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>oos_r_square</th>\n",
       "      <th>MSFE_adjusted</th>\n",
       "      <th>pvalue_MSFE</th>\n",
       "      <th>success_ratio</th>\n",
       "      <th>PT_stat</th>\n",
       "      <th>pvalue_PT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PLS</th>\n",
       "      <td>-9.845205</td>\n",
       "      <td>0.158533</td>\n",
       "      <td>0.437018</td>\n",
       "      <td>54.498044</td>\n",
       "      <td>1.519034</td>\n",
       "      <td>0.064377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCR</th>\n",
       "      <td>-4.371883</td>\n",
       "      <td>0.794236</td>\n",
       "      <td>0.213529</td>\n",
       "      <td>58.539765</td>\n",
       "      <td>2.490715</td>\n",
       "      <td>0.006374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LASSO</th>\n",
       "      <td>-3.552983</td>\n",
       "      <td>0.877620</td>\n",
       "      <td>0.190075</td>\n",
       "      <td>56.453716</td>\n",
       "      <td>1.127861</td>\n",
       "      <td>0.129689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENet</th>\n",
       "      <td>-4.274418</td>\n",
       "      <td>0.664717</td>\n",
       "      <td>0.253116</td>\n",
       "      <td>57.887875</td>\n",
       "      <td>2.087509</td>\n",
       "      <td>0.018421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>-16.130001</td>\n",
       "      <td>-0.308727</td>\n",
       "      <td>0.621235</td>\n",
       "      <td>54.367666</td>\n",
       "      <td>0.120474</td>\n",
       "      <td>0.452054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN2</th>\n",
       "      <td>-30.501839</td>\n",
       "      <td>0.497311</td>\n",
       "      <td>0.309485</td>\n",
       "      <td>56.062581</td>\n",
       "      <td>1.102496</td>\n",
       "      <td>0.135123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN4</th>\n",
       "      <td>-76.556965</td>\n",
       "      <td>-1.000122</td>\n",
       "      <td>0.841374</td>\n",
       "      <td>54.889179</td>\n",
       "      <td>-0.584516</td>\n",
       "      <td>0.720563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>-2.587061</td>\n",
       "      <td>1.139190</td>\n",
       "      <td>0.127312</td>\n",
       "      <td>58.018253</td>\n",
       "      <td>1.805065</td>\n",
       "      <td>0.035532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HA</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.973924</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       oos_r_square  MSFE_adjusted  pvalue_MSFE  success_ratio   PT_stat  \\\n",
       "PLS       -9.845205       0.158533     0.437018      54.498044  1.519034   \n",
       "PCR       -4.371883       0.794236     0.213529      58.539765  2.490715   \n",
       "LASSO     -3.552983       0.877620     0.190075      56.453716  1.127861   \n",
       "ENet      -4.274418       0.664717     0.253116      57.887875  2.087509   \n",
       "RF       -16.130001      -0.308727     0.621235      54.367666  0.120474   \n",
       "NN2      -30.501839       0.497311     0.309485      56.062581  1.102496   \n",
       "NN4      -76.556965      -1.000122     0.841374      54.889179 -0.584516   \n",
       "Ridge     -2.587061       1.139190     0.127312      58.018253  1.805065   \n",
       "HA         0.000000            NaN          NaN      59.973924       NaN   \n",
       "\n",
       "       pvalue_PT  \n",
       "PLS     0.064377  \n",
       "PCR     0.006374  \n",
       "LASSO   0.129689  \n",
       "ENet    0.018421  \n",
       "RF      0.452054  \n",
       "NN2     0.135123  \n",
       "NN4     0.720563  \n",
       "Ridge   0.035532  \n",
       "HA           NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Out-of-sample: 1957:01-2020:12\n",
    "in_out_1957 = predictor_df.index[predictor_df['month'] == 195701][0]\n",
    "actual_1957 = actual[in_out_1957:, ]\n",
    "y_pred_HA_1957 = y_pred_HA[in_out_1957:, ]\n",
    "MSFE_HA_1957 = mean_squared_error(y_pred_HA_1957, actual_1957)\n",
    "\n",
    "# Machine Learning methods used in GKX (2020)\n",
    "y_pred_PLS_1957, y_pred_PCR_1957,  y_pred_LASSO_1957 = [], [], []\n",
    "y_pred_ENet_1957, y_pred_RF_1957 = [], []\n",
    "y_pred_NN2_1957, y_pred_NN4_1957 = [], []\n",
    "\n",
    "## Other commonly used machine learning method\n",
    "y_pred_Ridge_1957 = []\n",
    "\n",
    "# control the update month of models during out-of-sample period. \n",
    "month_index = 1  # We update our models annually, meaning we refresh them in months 1, 13, 25, ...\n",
    "\n",
    "\n",
    "for t in tqdm(range(in_out_1957, N)):\n",
    "    #\n",
    "    X_train_all = predictor[(t - 20 * 12):t, 1:n_cols]\n",
    "    y_train_all = predictor[(t - 20 * 12):t, 0]\n",
    "    # set 15% of all the train data as validation set\n",
    "    X_train = X_train_all[0:int(len(X_train_all) * 0.85), :]\n",
    "    X_validation = X_train_all[int(len(X_train_all) * 0.85):t, :]\n",
    "    y_train = y_train_all[0:int(len(X_train_all) * 0.85)]\n",
    "    y_validation = y_train_all[int(len(X_train_all) * 0.85):t]\n",
    "    #\n",
    "    if month_index % 12 == 1:\n",
    "        month_index += 1\n",
    "\n",
    "        # PLS\n",
    "        PLS_param = {'n_components': [1, 2, 3, 4, 5, 6, 7, 8]}\n",
    "        PLS_result = {}\n",
    "        for param in ParameterGrid(PLS_param):\n",
    "            PLS = PLSRegression(**param)\n",
    "            PLS.fit(X_train, y_train)\n",
    "            mse = mean_squared_error(PLS.predict(X_validation), y_validation)\n",
    "            PLS_result[str(param)] = mse\n",
    "\n",
    "        PLS_best_param = eval(min(PLS_result, key=PLS_result.get))\n",
    "        PLS_model = PLSRegression(**PLS_best_param)\n",
    "        PLS_model.fit(X_train_all, y_train_all)\n",
    "        y_pred_PLS_1957.append(PLS_model.predict(predictor[[t], 1:n_cols])[0][0])\n",
    "\n",
    "        # PCR\n",
    "        PCR_param = {'n_components': [1, 2, 3, 4, 5, 6, 7, 8]}\n",
    "        PCR_result = {}\n",
    "        for param in ParameterGrid(PCR_param):\n",
    "            pca = PCA(**param)\n",
    "            pca.fit(X_train)\n",
    "            comps = pca.transform(X_train)\n",
    "            forecast = LinearRegression()\n",
    "            forecast.fit(comps, y_train)\n",
    "            mse = mean_squared_error(forecast.predict(pca.transform(X_validation)), y_validation)\n",
    "            PCR_result[str(param)] = mse\n",
    "        #\n",
    "        PCR_best_param = eval(min(PCR_result, key=PCR_result.get))\n",
    "        #\n",
    "        PCR_model = PCA(**PCR_best_param)\n",
    "        PCR_model.fit(X_train_all)\n",
    "        PCR_comps = PCR_model.transform(X_train_all)\n",
    "        PCR_forecast = LinearRegression()\n",
    "        PCR_forecast.fit(PCR_comps, y_train_all)\n",
    "        y_pred_PCR_1957.append(PCR_forecast.predict(PCR_model.transform(predictor[[t], 1:n_cols]))[0])\n",
    "\n",
    "        # LASSO\n",
    "        LASSO_param = {'alpha': list(10 ** np.arange(-4, 1 + 0.001, 0.2))}\n",
    "        LASSO_result = {}\n",
    "        for param in ParameterGrid(LASSO_param):\n",
    "            LASSO = Lasso(**param)\n",
    "            LASSO.fit(X_train, y_train)\n",
    "            mse = mean_squared_error(LASSO.predict(X_validation), y_validation)\n",
    "            LASSO_result[str(param)] = mse\n",
    "        #\n",
    "        LASSO_best_param = eval(min(LASSO_result, key=LASSO_result.get))\n",
    "        #\n",
    "        LASSO_model = Lasso(**LASSO_best_param)\n",
    "        LASSO_model.fit(X_train_all, y_train_all)\n",
    "        y_pred_LASSO_1957.append(LASSO_model.predict(predictor[[t], 1:n_cols])[0])\n",
    "\n",
    "        # ENet\n",
    "        ENet_param = {'alpha': list(10 ** np.arange(-4, 1 + 0.001, 0.2)),\n",
    "                      'l1_ratio': list(np.arange(0.2, 1, 0.3))}\n",
    "        ENet_result = {}\n",
    "        for param in ParameterGrid(ENet_param):\n",
    "            ENet = ElasticNet(**param)\n",
    "            ENet.fit(X_train, y_train)\n",
    "            mse = mean_squared_error(ENet.predict(X_validation), y_validation)\n",
    "            ENet_result[str(param)] = mse\n",
    "\n",
    "        ENet_best_param = eval(min(ENet_result, key=ENet_result.get))\n",
    "        ENet_model = ElasticNet(**ENet_best_param)\n",
    "        ENet_model.fit(X_train_all, y_train_all)\n",
    "        y_pred_ENet_1957.append(ENet_model.predict(predictor[[t], 1:n_cols])[0])\n",
    "\n",
    "\n",
    "        # RF\n",
    "        RF_param = {'n_estimators': [10, 50, 100, 150, 200],\n",
    "                    'max_depth': [2, 3, 4],\n",
    "                    'min_samples_leaf': [1, 3, 5]}\n",
    "        RF_result = {}\n",
    "        for param in ParameterGrid(RF_param):\n",
    "            RF = RandomForestRegressor(**param)\n",
    "            RF.fit(X_train, y_train)\n",
    "            mse = mean_squared_error(RF.predict(X_validation), y_validation)\n",
    "            RF_result[str(param)] = mse\n",
    "\n",
    "        RF_best_param = eval(min(RF_result, key=RF_result.get))\n",
    "        RF_model = RandomForestRegressor(**RF_best_param)\n",
    "        RF_model.fit(X_train_all, y_train_all)\n",
    "        y_pred_RF_1957.append(RF_model.predict(predictor[[t], 1:n_cols])[0])\n",
    "\n",
    "        # Neural Network Models: NN2 & NN4\n",
    "        X_train_all_tensor = torch.tensor(X_train_all, dtype=torch.float)\n",
    "        y_train_all_tensor = torch.tensor(y_train_all.reshape(-1, 1), dtype=torch.float)\n",
    "        X_train_tensor = torch.tensor(X_train, dtype=torch.float)\n",
    "        y_train_tensor = torch.tensor(y_train.reshape(-1, 1), dtype=torch.float)\n",
    "        X_validation_tensor = torch.tensor(X_validation, dtype=torch.float)\n",
    "        y_validation_tensor = torch.tensor(y_validation.reshape(-1, 1), dtype=torch.float)\n",
    "\n",
    "        # NN2\n",
    "        NN2_result = {}\n",
    "        NN2_architecture = {\"module__n_feature\": X_train_tensor.shape[1],\n",
    "                            \"module__n_hidden1\": 32, \"module__n_hidden2\": 16,\n",
    "                            \"module__n_output\": 1}\n",
    "        NN2_param = {'module__dropout': [0.2, 0.4, 0.6, 0.8],\n",
    "                    'lr': [0.001, 0.01],\n",
    "                    'optimizer__weight_decay': [0.1, 0.01, 0.001]}\n",
    "        for param in ParameterGrid(NN2_param):\n",
    "            NN2 = NeuralNetRegressor(Net2, verbose=0, max_epochs=200,\n",
    "                                     optimizer=torch.optim.SGD,\n",
    "                                     **NN2_architecture, **param)\n",
    "            NN2.fit(X_train_tensor, y_train_tensor)\n",
    "            mse = mean_squared_error(NN2.predict(X_validation_tensor), y_validation)\n",
    "            NN2_result[str(param)] = mse\n",
    "        \n",
    "        #\n",
    "        NN2_best_param = eval(min(NN2_result, key=NN2_result.get))\n",
    "        NN2_model = NeuralNetRegressor(Net2, verbose=0, max_epochs=200, optimizer=torch.optim.SGD,\n",
    "                                       **NN2_architecture, **NN2_best_param)\n",
    "        NN2_model.fit(X_train_all_tensor, y_train_all_tensor)\n",
    "        y_pred_NN2_1957.append(NN2_model.predict(torch.tensor(predictor[[t], 1:n_cols], dtype=torch.float))[0][0])\n",
    "        #\n",
    "\n",
    "\n",
    "        # NN4\n",
    "        NN4_result = {}\n",
    "        NN4_architecture = {\"module__n_feature\": X_train_tensor.shape[1],\n",
    "                            \"module__n_hidden1\": 32, \"module__n_hidden2\": 16,\n",
    "                            \"module__n_hidden3\": 8,  \"module__n_hidden4\": 4,\n",
    "                            \"module__n_output\": 1}\n",
    "        NN4_param = {'module__dropout': [0.2, 0.4, 0.6, 0.8],\n",
    "                     'lr': [0.001, 0.01],\n",
    "                     'optimizer__weight_decay': [0.1, 0.01, 0.001]}\n",
    "        for param in ParameterGrid(NN4_param):\n",
    "            NN4 = NeuralNetRegressor(Net4, verbose=0, max_epochs=200,\n",
    "                                     optimizer=torch.optim.SGD,\n",
    "                                     **NN4_architecture, **param)\n",
    "            NN4.fit(X_train_tensor, y_train_tensor)\n",
    "            mse = mean_squared_error(NN4.predict(X_validation_tensor), y_validation)\n",
    "            NN4_result[str(param)] = mse\n",
    "\n",
    "        #\n",
    "        NN4_best_param = eval(min(NN4_result, key=NN4_result.get))\n",
    "        NN4_model = NeuralNetRegressor(Net4, verbose=0, max_epochs=200, optimizer=torch.optim.SGD,\n",
    "                                       **NN4_architecture, **NN4_best_param)\n",
    "        NN4_model.fit(X_train_all_tensor, y_train_all_tensor)\n",
    "        y_pred_NN4_1957.append(NN4_model.predict(torch.tensor(predictor[[t], 1:n_cols], dtype=torch.float))[0][0])\n",
    "\n",
    "\n",
    "        ## Other commmonly used ML methods\n",
    "        # Ridge\n",
    "        Ridge_param = {'alpha': list(10 ** np.arange(0, 20 + 0.001, 1))}\n",
    "        Ridge_result = {}\n",
    "        for param in ParameterGrid(Ridge_param):\n",
    "            RIDGE = Ridge(**param)\n",
    "            RIDGE.fit(X_train, y_train)\n",
    "            mse = mean_squared_error(RIDGE.predict(X_validation), y_validation)\n",
    "            Ridge_result[str(param)] = mse\n",
    "        #\n",
    "        Ridge_best_param = eval(min(Ridge_result, key=Ridge_result.get))\n",
    "        Ridge_model = Ridge(**Ridge_best_param)\n",
    "        Ridge_model.fit(X_train_all, y_train_all)\n",
    "        y_pred_Ridge_1957.append(Ridge_model.predict(predictor[[t], 1:n_cols])[0])\n",
    "\n",
    "    else:\n",
    "        month_index += 1\n",
    "        y_pred_PLS_1957.append(PLS_model.predict(predictor[[t], 1:n_cols])[0][0])\n",
    "        y_pred_PCR_1957.append(PCR_forecast.predict(PCR_model.transform(predictor[[t], 1:n_cols]))[0])\n",
    "        y_pred_LASSO_1957.append(LASSO_model.predict(predictor[[t], 1:n_cols])[0])\n",
    "        y_pred_ENet_1957.append(ENet_model.predict(predictor[[t], 1:n_cols])[0])\n",
    "        y_pred_RF_1957.append(RF_model.predict(predictor[[t], 1:n_cols])[0])\n",
    "        y_pred_NN2_1957.append(NN2_model.predict(torch.tensor(predictor[[t], 1:n_cols], dtype=torch.float))[0][0])\n",
    "        y_pred_NN4_1957.append(NN4_model.predict(torch.tensor(predictor[[t], 1:n_cols], dtype=torch.float))[0][0])\n",
    "        # Other commonly used ML methods\n",
    "        y_pred_Ridge_1957.append(Ridge_model.predict(predictor[[t], 1:n_cols])[0])\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "y_ml_pred_1957 = pd.DataFrame(np.array([y_pred_PLS_1957, y_pred_PCR_1957, y_pred_LASSO_1957,\n",
    "                           y_pred_ENet_1957, y_pred_RF_1957, y_pred_NN2_1957,  \n",
    "                           y_pred_NN4_1957, y_pred_Ridge_1957]),\n",
    "                 index=['PLS', 'PCR', 'LASSO', 'ENet', \n",
    "                        'RF', 'NN2', 'NN4', 'Ridge'],\n",
    "                 columns=predictor_df.month[in_out_1957:N]).T\n",
    "\n",
    "# Performance compared with HA benchmark\n",
    "\n",
    "ml_oos_performance_20years = []\n",
    "\n",
    "for col in y_ml_pred_1957.columns:\n",
    "    oos_r_square = compute_oos_r_square(actual_1957, y_pred_HA_1957, y_ml_pred_1957[[col]].to_numpy())\n",
    "    MSFE_adjusted, pvalue_MSFE = CW_test(actual_1957, y_pred_HA_1957, y_ml_pred_1957[[col]].to_numpy())\n",
    "    success_ratio, PT_stat, pvalue_PT = PT_test(actual_1957, y_ml_pred_1957[[col]].to_numpy())\n",
    "    ml_oos_performance_20years.append([oos_r_square * 100, MSFE_adjusted, pvalue_MSFE, success_ratio * 100, PT_stat, pvalue_PT])\n",
    "\n",
    "\n",
    "ml_oos_performance_df_20years = pd.DataFrame(np.array(ml_oos_performance_20years),\n",
    "                                          index=y_ml_pred_1957.columns,\n",
    "                                          columns=['oos_r_square', 'MSFE_adjusted', 'pvalue_MSFE',\n",
    "                                                   'success_ratio', 'PT_stat', 'pvalue_PT'])\n",
    "ml_oos_performance_df_20years.loc['HA'] = [0, np.nan, np.nan, success_ratio_HA_1957 * 100, PT_HA_1957, p2_HA_1957]\n",
    "ml_oos_performance_df_20years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8378dc2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>oos_r_square</th>\n",
       "      <th>MSFE_adjusted</th>\n",
       "      <th>pvalue_MSFE</th>\n",
       "      <th>success_ratio</th>\n",
       "      <th>PT_stat</th>\n",
       "      <th>pvalue_PT</th>\n",
       "      <th>oos_r_square</th>\n",
       "      <th>MSFE_adjusted</th>\n",
       "      <th>pvalue_MSFE</th>\n",
       "      <th>success_ratio</th>\n",
       "      <th>PT_stat</th>\n",
       "      <th>pvalue_PT</th>\n",
       "      <th>oos_r_square</th>\n",
       "      <th>MSFE_adjusted</th>\n",
       "      <th>pvalue_MSFE</th>\n",
       "      <th>success_ratio</th>\n",
       "      <th>PT_stat</th>\n",
       "      <th>pvalue_PT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PLS</th>\n",
       "      <td>-47.239596</td>\n",
       "      <td>1.083377</td>\n",
       "      <td>0.139321</td>\n",
       "      <td>52.411995</td>\n",
       "      <td>-0.164357</td>\n",
       "      <td>0.565275</td>\n",
       "      <td>-15.893212</td>\n",
       "      <td>1.049371</td>\n",
       "      <td>0.147004</td>\n",
       "      <td>55.410691</td>\n",
       "      <td>1.356501</td>\n",
       "      <td>0.087470</td>\n",
       "      <td>-9.845205</td>\n",
       "      <td>0.158533</td>\n",
       "      <td>0.437018</td>\n",
       "      <td>54.498044</td>\n",
       "      <td>1.519034</td>\n",
       "      <td>0.064377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCR</th>\n",
       "      <td>-11.831484</td>\n",
       "      <td>0.818648</td>\n",
       "      <td>0.206494</td>\n",
       "      <td>56.062581</td>\n",
       "      <td>1.013248</td>\n",
       "      <td>0.155471</td>\n",
       "      <td>-6.902878</td>\n",
       "      <td>0.899997</td>\n",
       "      <td>0.184061</td>\n",
       "      <td>57.757497</td>\n",
       "      <td>1.715461</td>\n",
       "      <td>0.043130</td>\n",
       "      <td>-4.371883</td>\n",
       "      <td>0.794236</td>\n",
       "      <td>0.213529</td>\n",
       "      <td>58.539765</td>\n",
       "      <td>2.490715</td>\n",
       "      <td>0.006374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LASSO</th>\n",
       "      <td>-82.461558</td>\n",
       "      <td>-0.003547</td>\n",
       "      <td>0.501415</td>\n",
       "      <td>57.105606</td>\n",
       "      <td>1.118965</td>\n",
       "      <td>0.131578</td>\n",
       "      <td>-4.771582</td>\n",
       "      <td>1.970124</td>\n",
       "      <td>0.024412</td>\n",
       "      <td>59.843546</td>\n",
       "      <td>2.558406</td>\n",
       "      <td>0.005258</td>\n",
       "      <td>-3.552983</td>\n",
       "      <td>0.877620</td>\n",
       "      <td>0.190075</td>\n",
       "      <td>56.453716</td>\n",
       "      <td>1.127861</td>\n",
       "      <td>0.129689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENet</th>\n",
       "      <td>-74.396652</td>\n",
       "      <td>0.606137</td>\n",
       "      <td>0.272212</td>\n",
       "      <td>55.410691</td>\n",
       "      <td>0.585414</td>\n",
       "      <td>0.279135</td>\n",
       "      <td>-5.346111</td>\n",
       "      <td>1.982762</td>\n",
       "      <td>0.023697</td>\n",
       "      <td>59.843546</td>\n",
       "      <td>2.747300</td>\n",
       "      <td>0.003004</td>\n",
       "      <td>-4.274418</td>\n",
       "      <td>0.664717</td>\n",
       "      <td>0.253116</td>\n",
       "      <td>57.887875</td>\n",
       "      <td>2.087509</td>\n",
       "      <td>0.018421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>-16.913349</td>\n",
       "      <td>0.194882</td>\n",
       "      <td>0.422743</td>\n",
       "      <td>52.542373</td>\n",
       "      <td>-0.226891</td>\n",
       "      <td>0.589746</td>\n",
       "      <td>-14.836244</td>\n",
       "      <td>0.534075</td>\n",
       "      <td>0.296645</td>\n",
       "      <td>51.368970</td>\n",
       "      <td>-0.222107</td>\n",
       "      <td>0.587885</td>\n",
       "      <td>-16.130001</td>\n",
       "      <td>-0.308727</td>\n",
       "      <td>0.621235</td>\n",
       "      <td>54.367666</td>\n",
       "      <td>0.120474</td>\n",
       "      <td>0.452054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN2</th>\n",
       "      <td>-102.982502</td>\n",
       "      <td>-0.304749</td>\n",
       "      <td>0.619721</td>\n",
       "      <td>46.675359</td>\n",
       "      <td>-2.474727</td>\n",
       "      <td>0.993333</td>\n",
       "      <td>-100.028150</td>\n",
       "      <td>0.707580</td>\n",
       "      <td>0.239603</td>\n",
       "      <td>52.542373</td>\n",
       "      <td>0.229788</td>\n",
       "      <td>0.409128</td>\n",
       "      <td>-30.501839</td>\n",
       "      <td>0.497311</td>\n",
       "      <td>0.309485</td>\n",
       "      <td>56.062581</td>\n",
       "      <td>1.102496</td>\n",
       "      <td>0.135123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN4</th>\n",
       "      <td>-358.211154</td>\n",
       "      <td>-0.810580</td>\n",
       "      <td>0.791197</td>\n",
       "      <td>51.499348</td>\n",
       "      <td>-1.006715</td>\n",
       "      <td>0.842964</td>\n",
       "      <td>-103.312912</td>\n",
       "      <td>-1.065146</td>\n",
       "      <td>0.856595</td>\n",
       "      <td>55.541069</td>\n",
       "      <td>1.161620</td>\n",
       "      <td>0.122695</td>\n",
       "      <td>-76.556965</td>\n",
       "      <td>-1.000122</td>\n",
       "      <td>0.841374</td>\n",
       "      <td>54.889179</td>\n",
       "      <td>-0.584516</td>\n",
       "      <td>0.720563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>-26.633373</td>\n",
       "      <td>0.143339</td>\n",
       "      <td>0.443011</td>\n",
       "      <td>56.453716</td>\n",
       "      <td>0.790713</td>\n",
       "      <td>0.214556</td>\n",
       "      <td>-5.562798</td>\n",
       "      <td>1.265462</td>\n",
       "      <td>0.102853</td>\n",
       "      <td>58.930900</td>\n",
       "      <td>2.325955</td>\n",
       "      <td>0.010010</td>\n",
       "      <td>-2.587061</td>\n",
       "      <td>1.139190</td>\n",
       "      <td>0.127312</td>\n",
       "      <td>58.018253</td>\n",
       "      <td>1.805065</td>\n",
       "      <td>0.035532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HA</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.973924</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.973924</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.973924</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       oos_r_square  MSFE_adjusted  pvalue_MSFE  success_ratio   PT_stat  \\\n",
       "PLS      -47.239596       1.083377     0.139321      52.411995 -0.164357   \n",
       "PCR      -11.831484       0.818648     0.206494      56.062581  1.013248   \n",
       "LASSO    -82.461558      -0.003547     0.501415      57.105606  1.118965   \n",
       "ENet     -74.396652       0.606137     0.272212      55.410691  0.585414   \n",
       "RF       -16.913349       0.194882     0.422743      52.542373 -0.226891   \n",
       "NN2     -102.982502      -0.304749     0.619721      46.675359 -2.474727   \n",
       "NN4     -358.211154      -0.810580     0.791197      51.499348 -1.006715   \n",
       "Ridge    -26.633373       0.143339     0.443011      56.453716  0.790713   \n",
       "HA         0.000000            NaN          NaN      59.973924       NaN   \n",
       "\n",
       "       pvalue_PT  oos_r_square  MSFE_adjusted  pvalue_MSFE  success_ratio  \\\n",
       "PLS     0.565275    -15.893212       1.049371     0.147004      55.410691   \n",
       "PCR     0.155471     -6.902878       0.899997     0.184061      57.757497   \n",
       "LASSO   0.131578     -4.771582       1.970124     0.024412      59.843546   \n",
       "ENet    0.279135     -5.346111       1.982762     0.023697      59.843546   \n",
       "RF      0.589746    -14.836244       0.534075     0.296645      51.368970   \n",
       "NN2     0.993333   -100.028150       0.707580     0.239603      52.542373   \n",
       "NN4     0.842964   -103.312912      -1.065146     0.856595      55.541069   \n",
       "Ridge   0.214556     -5.562798       1.265462     0.102853      58.930900   \n",
       "HA           NaN      0.000000            NaN          NaN      59.973924   \n",
       "\n",
       "        PT_stat  pvalue_PT  oos_r_square  MSFE_adjusted  pvalue_MSFE  \\\n",
       "PLS    1.356501   0.087470     -9.845205       0.158533     0.437018   \n",
       "PCR    1.715461   0.043130     -4.371883       0.794236     0.213529   \n",
       "LASSO  2.558406   0.005258     -3.552983       0.877620     0.190075   \n",
       "ENet   2.747300   0.003004     -4.274418       0.664717     0.253116   \n",
       "RF    -0.222107   0.587885    -16.130001      -0.308727     0.621235   \n",
       "NN2    0.229788   0.409128    -30.501839       0.497311     0.309485   \n",
       "NN4    1.161620   0.122695    -76.556965      -1.000122     0.841374   \n",
       "Ridge  2.325955   0.010010     -2.587061       1.139190     0.127312   \n",
       "HA          NaN        NaN      0.000000            NaN          NaN   \n",
       "\n",
       "       success_ratio   PT_stat  pvalue_PT  \n",
       "PLS        54.498044  1.519034   0.064377  \n",
       "PCR        58.539765  2.490715   0.006374  \n",
       "LASSO      56.453716  1.127861   0.129689  \n",
       "ENet       57.887875  2.087509   0.018421  \n",
       "RF         54.367666  0.120474   0.452054  \n",
       "NN2        56.062581  1.102496   0.135123  \n",
       "NN4        54.889179 -0.584516   0.720563  \n",
       "Ridge      58.018253  1.805065   0.035532  \n",
       "HA         59.973924       NaN        NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_oos_performance_rolling_window = pd.concat([ml_oos_performance_df_5years, ml_oos_performance_df_10years, ml_oos_performance_df_20years], axis=1)\n",
    "\n",
    "\n",
    "with pd.ExcelWriter(\"ml_equity_premium_robust_checks.xlsx\") as writer:\n",
    "    ml_oos_performance_rolling_window.to_excel(writer, sheet_name='rolling_window_estimation')\n",
    "\n",
    "ml_oos_performance_rolling_window"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
