{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2df2b249",
   "metadata": {},
   "source": [
    "### Alternative macroeconomic datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f822b3b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/xingfuxu/PycharmProjects/EquityPremiumPredictionML-Jupyter'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "# os.chdir(path)    # or you can set your working dir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3c1c50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your working dir should include \"NN_models.py\", Perform_CW_test.py\" and \"Perform_PT_test.py\" files.\n",
    "from Perform_CW_test import CW_test\n",
    "from Perform_PT_test import PT_test\n",
    "from NN_models import Net2, Net4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e772b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import torch\n",
    "from skorch import NeuralNetRegressor\n",
    "from tqdm import tqdm\n",
    "#\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50dbea16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sasdate</th>\n",
       "      <th>RPI</th>\n",
       "      <th>W875RX1</th>\n",
       "      <th>DPCERA3M086SBEA</th>\n",
       "      <th>CMRMTSPLx</th>\n",
       "      <th>RETAILx</th>\n",
       "      <th>INDPRO</th>\n",
       "      <th>IPFPNSS</th>\n",
       "      <th>IPFINAL</th>\n",
       "      <th>IPCONGD</th>\n",
       "      <th>...</th>\n",
       "      <th>DDURRG3M086SBEA</th>\n",
       "      <th>DNDGRG3M086SBEA</th>\n",
       "      <th>DSERRG3M086SBEA</th>\n",
       "      <th>CES0600000008</th>\n",
       "      <th>CES2000000008</th>\n",
       "      <th>CES3000000008</th>\n",
       "      <th>MZMSL</th>\n",
       "      <th>DTCOLNVHFNM</th>\n",
       "      <th>DTCTHFNM</th>\n",
       "      <th>INVEST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/1/1959</td>\n",
       "      <td>2437.296</td>\n",
       "      <td>2288.8</td>\n",
       "      <td>17.302</td>\n",
       "      <td>292258.8329</td>\n",
       "      <td>18235.77392</td>\n",
       "      <td>22.625</td>\n",
       "      <td>23.4581</td>\n",
       "      <td>22.1904</td>\n",
       "      <td>32.4078</td>\n",
       "      <td>...</td>\n",
       "      <td>56.918</td>\n",
       "      <td>17.791</td>\n",
       "      <td>11.358</td>\n",
       "      <td>2.13</td>\n",
       "      <td>2.45</td>\n",
       "      <td>2.04</td>\n",
       "      <td>274.9</td>\n",
       "      <td>6476.0</td>\n",
       "      <td>12298.0</td>\n",
       "      <td>84.2043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2/1/1959</td>\n",
       "      <td>2446.902</td>\n",
       "      <td>2297.0</td>\n",
       "      <td>17.482</td>\n",
       "      <td>294429.5453</td>\n",
       "      <td>18369.56308</td>\n",
       "      <td>23.0681</td>\n",
       "      <td>23.7747</td>\n",
       "      <td>22.3827</td>\n",
       "      <td>32.6455</td>\n",
       "      <td>...</td>\n",
       "      <td>56.951</td>\n",
       "      <td>17.798</td>\n",
       "      <td>11.375</td>\n",
       "      <td>2.14</td>\n",
       "      <td>2.46</td>\n",
       "      <td>2.05</td>\n",
       "      <td>276.0</td>\n",
       "      <td>6476.0</td>\n",
       "      <td>12298.0</td>\n",
       "      <td>83.528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3/1/1959</td>\n",
       "      <td>2462.689</td>\n",
       "      <td>2314.0</td>\n",
       "      <td>17.647</td>\n",
       "      <td>293425.3813</td>\n",
       "      <td>18523.05762</td>\n",
       "      <td>23.4004</td>\n",
       "      <td>23.9186</td>\n",
       "      <td>22.4925</td>\n",
       "      <td>32.6455</td>\n",
       "      <td>...</td>\n",
       "      <td>57.022</td>\n",
       "      <td>17.785</td>\n",
       "      <td>11.395</td>\n",
       "      <td>2.15</td>\n",
       "      <td>2.45</td>\n",
       "      <td>2.07</td>\n",
       "      <td>277.4</td>\n",
       "      <td>6508.0</td>\n",
       "      <td>12349.0</td>\n",
       "      <td>81.6405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4/1/1959</td>\n",
       "      <td>2478.744</td>\n",
       "      <td>2330.3</td>\n",
       "      <td>17.584</td>\n",
       "      <td>299331.6505</td>\n",
       "      <td>18534.466</td>\n",
       "      <td>23.8989</td>\n",
       "      <td>24.2641</td>\n",
       "      <td>22.8221</td>\n",
       "      <td>33.1606</td>\n",
       "      <td>...</td>\n",
       "      <td>57.08</td>\n",
       "      <td>17.796</td>\n",
       "      <td>11.436</td>\n",
       "      <td>2.16</td>\n",
       "      <td>2.47</td>\n",
       "      <td>2.08</td>\n",
       "      <td>278.1</td>\n",
       "      <td>6620.0</td>\n",
       "      <td>12484.0</td>\n",
       "      <td>81.8099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5/1/1959</td>\n",
       "      <td>2493.228</td>\n",
       "      <td>2345.8</td>\n",
       "      <td>17.796</td>\n",
       "      <td>301372.9597</td>\n",
       "      <td>18679.66354</td>\n",
       "      <td>24.2589</td>\n",
       "      <td>24.4655</td>\n",
       "      <td>23.0418</td>\n",
       "      <td>33.319</td>\n",
       "      <td>...</td>\n",
       "      <td>57.175</td>\n",
       "      <td>17.777</td>\n",
       "      <td>11.454</td>\n",
       "      <td>2.17</td>\n",
       "      <td>2.48</td>\n",
       "      <td>2.08</td>\n",
       "      <td>280.1</td>\n",
       "      <td>6753.0</td>\n",
       "      <td>12646.0</td>\n",
       "      <td>80.7315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>8/1/2020</td>\n",
       "      <td>17603.151</td>\n",
       "      <td>13900.7</td>\n",
       "      <td>117.335</td>\n",
       "      <td>1554439.0</td>\n",
       "      <td>543404.0</td>\n",
       "      <td>102.8885</td>\n",
       "      <td>99.8433</td>\n",
       "      <td>99.5522</td>\n",
       "      <td>105.0636</td>\n",
       "      <td>...</td>\n",
       "      <td>86.66</td>\n",
       "      <td>98.922</td>\n",
       "      <td>120.338</td>\n",
       "      <td>25.51</td>\n",
       "      <td>29.39</td>\n",
       "      <td>22.87</td>\n",
       "      <td>21113.5</td>\n",
       "      <td>344302.07</td>\n",
       "      <td>726966.76</td>\n",
       "      <td>4362.8621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>9/1/2020</td>\n",
       "      <td>17698.892</td>\n",
       "      <td>14029.2</td>\n",
       "      <td>118.656</td>\n",
       "      <td>1564146.0</td>\n",
       "      <td>552767.0</td>\n",
       "      <td>102.7766</td>\n",
       "      <td>99.3909</td>\n",
       "      <td>98.7596</td>\n",
       "      <td>103.9916</td>\n",
       "      <td>...</td>\n",
       "      <td>86.611</td>\n",
       "      <td>98.659</td>\n",
       "      <td>120.743</td>\n",
       "      <td>25.49</td>\n",
       "      <td>29.09</td>\n",
       "      <td>23.01</td>\n",
       "      <td>21271.5</td>\n",
       "      <td>345629.27</td>\n",
       "      <td>728899.98</td>\n",
       "      <td>4417.394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>10/1/2020</td>\n",
       "      <td>17569.407</td>\n",
       "      <td>14119.1</td>\n",
       "      <td>118.886</td>\n",
       "      <td>1572531.0</td>\n",
       "      <td>552193.0</td>\n",
       "      <td>103.9494</td>\n",
       "      <td>100.6768</td>\n",
       "      <td>99.7284</td>\n",
       "      <td>104.8031</td>\n",
       "      <td>...</td>\n",
       "      <td>86.515</td>\n",
       "      <td>98.558</td>\n",
       "      <td>120.902</td>\n",
       "      <td>25.58</td>\n",
       "      <td>29.4</td>\n",
       "      <td>22.99</td>\n",
       "      <td>21365.5</td>\n",
       "      <td>348519.86</td>\n",
       "      <td>730630.92</td>\n",
       "      <td>4492.1138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>11/1/2020</td>\n",
       "      <td>17350.354</td>\n",
       "      <td>14015.9</td>\n",
       "      <td>118.173</td>\n",
       "      <td>1569904.0</td>\n",
       "      <td>545248.0</td>\n",
       "      <td>104.8525</td>\n",
       "      <td>101.3136</td>\n",
       "      <td>100.5163</td>\n",
       "      <td>105.1711</td>\n",
       "      <td>...</td>\n",
       "      <td>86.295</td>\n",
       "      <td>98.704</td>\n",
       "      <td>120.929</td>\n",
       "      <td>25.69</td>\n",
       "      <td>29.55</td>\n",
       "      <td>23.1</td>\n",
       "      <td>21576.9</td>\n",
       "      <td>350858.18</td>\n",
       "      <td>733193.14</td>\n",
       "      <td>4605.6462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>12/1/2020</td>\n",
       "      <td>17386.847</td>\n",
       "      <td>13995.8</td>\n",
       "      <td>117.274</td>\n",
       "      <td>1562613.0</td>\n",
       "      <td>539670.0</td>\n",
       "      <td>106.1981</td>\n",
       "      <td>102.6411</td>\n",
       "      <td>101.9052</td>\n",
       "      <td>106.8003</td>\n",
       "      <td>...</td>\n",
       "      <td>86.465</td>\n",
       "      <td>99.146</td>\n",
       "      <td>121.387</td>\n",
       "      <td>25.8</td>\n",
       "      <td>29.65</td>\n",
       "      <td>23.17</td>\n",
       "      <td>21649.5</td>\n",
       "      <td>350687.76</td>\n",
       "      <td>733754.97</td>\n",
       "      <td>4669.2247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>744 rows × 116 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sasdate        RPI  W875RX1 DPCERA3M086SBEA    CMRMTSPLx      RETAILx  \\\n",
       "0     1/1/1959   2437.296   2288.8          17.302  292258.8329  18235.77392   \n",
       "1     2/1/1959   2446.902   2297.0          17.482  294429.5453  18369.56308   \n",
       "2     3/1/1959   2462.689   2314.0          17.647  293425.3813  18523.05762   \n",
       "3     4/1/1959   2478.744   2330.3          17.584  299331.6505    18534.466   \n",
       "4     5/1/1959   2493.228   2345.8          17.796  301372.9597  18679.66354   \n",
       "..         ...        ...      ...             ...          ...          ...   \n",
       "739   8/1/2020  17603.151  13900.7         117.335    1554439.0     543404.0   \n",
       "740   9/1/2020  17698.892  14029.2         118.656    1564146.0     552767.0   \n",
       "741  10/1/2020  17569.407  14119.1         118.886    1572531.0     552193.0   \n",
       "742  11/1/2020  17350.354  14015.9         118.173    1569904.0     545248.0   \n",
       "743  12/1/2020  17386.847  13995.8         117.274    1562613.0     539670.0   \n",
       "\n",
       "       INDPRO   IPFPNSS   IPFINAL   IPCONGD  ... DDURRG3M086SBEA  \\\n",
       "0      22.625   23.4581   22.1904   32.4078  ...          56.918   \n",
       "1     23.0681   23.7747   22.3827   32.6455  ...          56.951   \n",
       "2     23.4004   23.9186   22.4925   32.6455  ...          57.022   \n",
       "3     23.8989   24.2641   22.8221   33.1606  ...           57.08   \n",
       "4     24.2589   24.4655   23.0418    33.319  ...          57.175   \n",
       "..        ...       ...       ...       ...  ...             ...   \n",
       "739  102.8885   99.8433   99.5522  105.0636  ...           86.66   \n",
       "740  102.7766   99.3909   98.7596  103.9916  ...          86.611   \n",
       "741  103.9494  100.6768   99.7284  104.8031  ...          86.515   \n",
       "742  104.8525  101.3136  100.5163  105.1711  ...          86.295   \n",
       "743  106.1981  102.6411  101.9052  106.8003  ...          86.465   \n",
       "\n",
       "    DNDGRG3M086SBEA DSERRG3M086SBEA CES0600000008 CES2000000008 CES3000000008  \\\n",
       "0            17.791          11.358          2.13          2.45          2.04   \n",
       "1            17.798          11.375          2.14          2.46          2.05   \n",
       "2            17.785          11.395          2.15          2.45          2.07   \n",
       "3            17.796          11.436          2.16          2.47          2.08   \n",
       "4            17.777          11.454          2.17          2.48          2.08   \n",
       "..              ...             ...           ...           ...           ...   \n",
       "739          98.922         120.338         25.51         29.39         22.87   \n",
       "740          98.659         120.743         25.49         29.09         23.01   \n",
       "741          98.558         120.902         25.58          29.4         22.99   \n",
       "742          98.704         120.929         25.69         29.55          23.1   \n",
       "743          99.146         121.387          25.8         29.65         23.17   \n",
       "\n",
       "       MZMSL DTCOLNVHFNM   DTCTHFNM     INVEST  \n",
       "0      274.9      6476.0    12298.0    84.2043  \n",
       "1      276.0      6476.0    12298.0     83.528  \n",
       "2      277.4      6508.0    12349.0    81.6405  \n",
       "3      278.1      6620.0    12484.0    81.8099  \n",
       "4      280.1      6753.0    12646.0    80.7315  \n",
       "..       ...         ...        ...        ...  \n",
       "739  21113.5   344302.07  726966.76  4362.8621  \n",
       "740  21271.5   345629.27  728899.98   4417.394  \n",
       "741  21365.5   348519.86  730630.92  4492.1138  \n",
       "742  21576.9   350858.18  733193.14  4605.6462  \n",
       "743  21649.5   350687.76  733754.97  4669.2247  \n",
       "\n",
       "[744 rows x 116 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set seed\n",
    "torch.manual_seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "# read data\n",
    "predictor_df = pd.read_excel(open('ml_equity_premium_data.xlsx', 'rb'), sheet_name='result_predictor')\n",
    "predictor_df.head()\n",
    "\n",
    "# read fred data\n",
    "fred_md0 = pd.read_excel(open('ml_equity_premium_data.xlsx', 'rb'), sheet_name='FRED_MD')\n",
    "fred_md = fred_md0.T.dropna().T\n",
    "fred_md  # range from 1959:01 to 2020:12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d214d186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_equity_premium</th>\n",
       "      <th>RPI</th>\n",
       "      <th>W875RX1</th>\n",
       "      <th>DPCERA3M086SBEA</th>\n",
       "      <th>CMRMTSPLx</th>\n",
       "      <th>RETAILx</th>\n",
       "      <th>INDPRO</th>\n",
       "      <th>IPFPNSS</th>\n",
       "      <th>IPFINAL</th>\n",
       "      <th>IPCONGD</th>\n",
       "      <th>...</th>\n",
       "      <th>MA_2_9</th>\n",
       "      <th>MA_2_12</th>\n",
       "      <th>MA_3_9</th>\n",
       "      <th>MA_3_12</th>\n",
       "      <th>MOM_1</th>\n",
       "      <th>MOM_2</th>\n",
       "      <th>MOM_3</th>\n",
       "      <th>MOM_6</th>\n",
       "      <th>MOM_9</th>\n",
       "      <th>MOM_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.004112</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008774</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.004590</td>\n",
       "      <td>0.000575</td>\n",
       "      <td>0.000681</td>\n",
       "      <td>0.001721</td>\n",
       "      <td>0.010454</td>\n",
       "      <td>0.00025</td>\n",
       "      <td>0.005039</td>\n",
       "      <td>0.003616</td>\n",
       "      <td>0.002224</td>\n",
       "      <td>0.002904</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001446</td>\n",
       "      <td>0.001519</td>\n",
       "      <td>0.002093</td>\n",
       "      <td>0.003299</td>\n",
       "      <td>0.009677</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.008819</td>\n",
       "      <td>0.005259</td>\n",
       "      <td>0.003494</td>\n",
       "      <td>0.002904</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.037071</td>\n",
       "      <td>0.00248</td>\n",
       "      <td>0.003447</td>\n",
       "      <td>0.002696</td>\n",
       "      <td>0.01425</td>\n",
       "      <td>0.000559</td>\n",
       "      <td>0.014488</td>\n",
       "      <td>0.009205</td>\n",
       "      <td>0.007307</td>\n",
       "      <td>0.009198</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.021357</td>\n",
       "      <td>0.003346</td>\n",
       "      <td>0.004734</td>\n",
       "      <td>0.004723</td>\n",
       "      <td>0.01583</td>\n",
       "      <td>0.00083</td>\n",
       "      <td>0.018583</td>\n",
       "      <td>0.011505</td>\n",
       "      <td>0.009848</td>\n",
       "      <td>0.011134</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>0.069491</td>\n",
       "      <td>0.907294</td>\n",
       "      <td>0.9645</td>\n",
       "      <td>0.956412</td>\n",
       "      <td>0.985993</td>\n",
       "      <td>0.982484</td>\n",
       "      <td>0.912847</td>\n",
       "      <td>0.872319</td>\n",
       "      <td>0.894863</td>\n",
       "      <td>0.887766</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>-0.038997</td>\n",
       "      <td>0.913022</td>\n",
       "      <td>0.975173</td>\n",
       "      <td>0.969042</td>\n",
       "      <td>0.993508</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.911574</td>\n",
       "      <td>0.867152</td>\n",
       "      <td>0.885695</td>\n",
       "      <td>0.874667</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>-0.026865</td>\n",
       "      <td>0.905275</td>\n",
       "      <td>0.98264</td>\n",
       "      <td>0.971241</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998926</td>\n",
       "      <td>0.924912</td>\n",
       "      <td>0.881837</td>\n",
       "      <td>0.896901</td>\n",
       "      <td>0.884583</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>0.103719</td>\n",
       "      <td>0.89217</td>\n",
       "      <td>0.974068</td>\n",
       "      <td>0.964424</td>\n",
       "      <td>0.997966</td>\n",
       "      <td>0.985933</td>\n",
       "      <td>0.935183</td>\n",
       "      <td>0.88911</td>\n",
       "      <td>0.906015</td>\n",
       "      <td>0.889079</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>0.040629</td>\n",
       "      <td>0.894354</td>\n",
       "      <td>0.972399</td>\n",
       "      <td>0.955828</td>\n",
       "      <td>0.992321</td>\n",
       "      <td>0.975498</td>\n",
       "      <td>0.950487</td>\n",
       "      <td>0.90427</td>\n",
       "      <td>0.922081</td>\n",
       "      <td>0.908986</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>744 rows × 128 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     log_equity_premium       RPI   W875RX1 DPCERA3M086SBEA CMRMTSPLx  \\\n",
       "0              0.004112       0.0       0.0             0.0  0.008774   \n",
       "1              0.004590  0.000575  0.000681        0.001721  0.010454   \n",
       "2              0.001446  0.001519  0.002093        0.003299  0.009677   \n",
       "3              0.037071   0.00248  0.003447        0.002696   0.01425   \n",
       "4              0.021357  0.003346  0.004734        0.004723   0.01583   \n",
       "..                  ...       ...       ...             ...       ...   \n",
       "739            0.069491  0.907294    0.9645        0.956412  0.985993   \n",
       "740           -0.038997  0.913022  0.975173        0.969042  0.993508   \n",
       "741           -0.026865  0.905275   0.98264        0.971241       1.0   \n",
       "742            0.103719   0.89217  0.974068        0.964424  0.997966   \n",
       "743            0.040629  0.894354  0.972399        0.955828  0.992321   \n",
       "\n",
       "      RETAILx    INDPRO   IPFPNSS   IPFINAL   IPCONGD  ... MA_2_9 MA_2_12  \\\n",
       "0         0.0       0.0       0.0       0.0       0.0  ...      1       1   \n",
       "1     0.00025  0.005039  0.003616  0.002224  0.002904  ...      1       1   \n",
       "2    0.000537  0.008819  0.005259  0.003494  0.002904  ...      1       1   \n",
       "3    0.000559  0.014488  0.009205  0.007307  0.009198  ...      1       1   \n",
       "4     0.00083  0.018583  0.011505  0.009848  0.011134  ...      1       1   \n",
       "..        ...       ...       ...       ...       ...  ...    ...     ...   \n",
       "739  0.982484  0.912847  0.872319  0.894863  0.887766  ...      1       1   \n",
       "740       1.0  0.911574  0.867152  0.885695  0.874667  ...      1       1   \n",
       "741  0.998926  0.924912  0.881837  0.896901  0.884583  ...      1       1   \n",
       "742  0.985933  0.935183   0.88911  0.906015  0.889079  ...      1       1   \n",
       "743  0.975498  0.950487   0.90427  0.922081  0.908986  ...      1       1   \n",
       "\n",
       "    MA_3_9 MA_3_12 MOM_1 MOM_2 MOM_3 MOM_6 MOM_9 MOM_12  \n",
       "0        1       1     1     1     1     1     1      1  \n",
       "1        1       1     0     1     1     1     1      1  \n",
       "2        1       1     1     1     1     1     1      1  \n",
       "3        1       1     1     1     1     1     1      1  \n",
       "4        1       1     1     1     1     1     1      1  \n",
       "..     ...     ...   ...   ...   ...   ...   ...    ...  \n",
       "739      1       1     1     1     1     1     1      1  \n",
       "740      1       1     0     1     1     1     1      1  \n",
       "741      1       1     0     0     0     1     1      1  \n",
       "742      1       1     1     1     1     1     1      1  \n",
       "743      1       1     1     1     1     1     1      1  \n",
       "\n",
       "[744 rows x 128 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_month = predictor_df.index[predictor_df['month'] == 195901][0]\n",
    "predictor_df = predictor_df.iloc[start_month:, :]\n",
    "predictor_df.reset_index(inplace=True, drop=True)\n",
    "predictor_df.head()\n",
    "#\n",
    "fred_md.iloc[:, 1:] = minmax_scale(fred_md.iloc[:, 1:])\n",
    "tech_ind = predictor_df.columns.get_loc('MA_1_9')\n",
    "predictor0 = pd.concat([predictor_df.loc[:, ['log_equity_premium']],\n",
    "                        fred_md.iloc[:, 1:], predictor_df.iloc[:, 15:]],axis=1)\n",
    "predictor0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5218722b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the predictors and set the log equity premium 1-month ahead\n",
    "predictor = np.concatenate([predictor0['log_equity_premium'][1:].values.reshape(-1, 1),\n",
    "                            predictor0.iloc[0:(predictor0.shape[0] - 1), 1:]], axis=1)\n",
    "predictor = predictor.astype(float)\n",
    "# number of rows\n",
    "N = predictor.shape[0]\n",
    "\n",
    "# number of all columns, including the log equity premium\n",
    "n_cols = predictor.shape[1]\n",
    "\n",
    "# Actual one-month ahead log equity premium\n",
    "actual = predictor[:, [0]]\n",
    "\n",
    "# Historical average forecasting as benchmark\n",
    "y_pred_HA = predictor0['log_equity_premium'].values[0:(predictor0.shape[0] - 1), ].cumsum() / np.arange(1, N + 1)\n",
    "y_pred_HA = y_pred_HA.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f59806b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Out-of-sample: 1990:01-2020:12\n",
    "in_out_1990 = predictor_df.index[predictor_df['month'] == 199001][0]\n",
    "actual_1990 = actual[in_out_1990:, ]\n",
    "y_pred_HA_1990 = y_pred_HA[in_out_1990:, ]\n",
    "MSFE_HA_1990 = mean_squared_error(y_pred_HA_1990, actual_1990)\n",
    "\n",
    "# Machine Learning methods used in GKX (2020)\n",
    "y_pred_PLS_1990, y_pred_PCR_1990,  y_pred_LASSO_1990 = [], [], []\n",
    "y_pred_ENet_1990, y_pred_RF_1990 = [], []\n",
    "y_pred_NN2_1990, y_pred_NN4_1990 = [], []\n",
    "\n",
    "## Other commonly used machine learning method\n",
    "y_pred_Ridge_1990 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b69658e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# control the update month of models during out-of-sample period. \n",
    "month_index = 1  # We update our models annually, meaning we refresh them in months 1, 13, 25, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5dcc763",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 371/371 [51:12<00:00,  8.28s/it]\n"
     ]
    }
   ],
   "source": [
    "for t in tqdm(range(in_out_1990, N)):\n",
    "    X_train_all = predictor[:t, 1:n_cols]\n",
    "    y_train_all = predictor[:t, 0]\n",
    "    # set 15% of all the train data as validation set\n",
    "    X_train = X_train_all[0:int(len(X_train_all) * 0.85), :]\n",
    "    X_validation = X_train_all[int(len(X_train_all) * 0.85):t, :]\n",
    "    y_train = y_train_all[0:int(len(X_train_all) * 0.85)]\n",
    "    y_validation = y_train_all[int(len(X_train_all) * 0.85):t]\n",
    "    #\n",
    "    warnings.filterwarnings('ignore')\n",
    "    #\n",
    "    if month_index % 12 == 1:\n",
    "        month_index += 1\n",
    "        # PLS\n",
    "        PLS_param = {'n_components': [1, 2, 3, 4, 5, 6, 7, 8]}\n",
    "        PLS_result = {}\n",
    "        for param in ParameterGrid(PLS_param):\n",
    "            PLS = PLSRegression(**param)\n",
    "            PLS.fit(X_train, y_train)\n",
    "            mse = mean_squared_error(PLS.predict(X_validation), y_validation)\n",
    "            PLS_result[str(param)] = mse\n",
    "\n",
    "        PLS_best_param = eval(min(PLS_result, key=PLS_result.get))\n",
    "        PLS_model = PLSRegression(**PLS_best_param)\n",
    "        PLS_model.fit(X_train_all, y_train_all)\n",
    "        y_pred_PLS_1990.append(PLS_model.predict(predictor[[t], 1:n_cols])[0][0])\n",
    "\n",
    "        # PCR\n",
    "        PCR_param = {'n_components': [1, 2, 3, 4, 5, 6, 7, 8]}\n",
    "        PCR_result = {}\n",
    "        for param in ParameterGrid(PCR_param):\n",
    "            pca = PCA(**param)\n",
    "            pca.fit(X_train)\n",
    "            comps = pca.transform(X_train)\n",
    "            forecast = LinearRegression()\n",
    "            forecast.fit(comps, y_train)\n",
    "            mse = mean_squared_error(forecast.predict(pca.transform(X_validation)), y_validation)\n",
    "            PCR_result[str(param)] = mse\n",
    "        #\n",
    "        PCR_best_param = eval(min(PCR_result, key=PCR_result.get))\n",
    "        #\n",
    "        PCR_model = PCA(**PCR_best_param)\n",
    "        PCR_model.fit(X_train_all)\n",
    "        PCR_comps = PCR_model.transform(X_train_all)\n",
    "        PCR_forecast = LinearRegression()\n",
    "        PCR_forecast.fit(PCR_comps, y_train_all)\n",
    "        y_pred_PCR_1990.append(PCR_forecast.predict(PCR_model.transform(predictor[[t], 1:n_cols]))[0])\n",
    "\n",
    "        # LASSO\n",
    "        LASSO_param = {'alpha': list(10 ** np.arange(-4, 1 + 0.001, 0.2))}\n",
    "        LASSO_result = {}\n",
    "        for param in ParameterGrid(LASSO_param):\n",
    "            LASSO = Lasso(**param)\n",
    "            LASSO.fit(X_train, y_train)\n",
    "            mse = mean_squared_error(LASSO.predict(X_validation), y_validation)\n",
    "            LASSO_result[str(param)] = mse\n",
    "        #\n",
    "        LASSO_best_param = eval(min(LASSO_result, key=LASSO_result.get))\n",
    "        #\n",
    "        LASSO_model = Lasso(**LASSO_best_param)\n",
    "        LASSO_model.fit(X_train_all, y_train_all)\n",
    "        y_pred_LASSO_1990.append(LASSO_model.predict(predictor[[t], 1:n_cols])[0])\n",
    "\n",
    "        # ENet\n",
    "        ENet_param = {'alpha': list(10 ** np.arange(-4, 1 + 0.001, 0.2)),\n",
    "                      'l1_ratio': list(np.arange(0.2, 1, 0.3))}\n",
    "        ENet_result = {}\n",
    "        for param in ParameterGrid(ENet_param):\n",
    "            ENet = ElasticNet(**param)\n",
    "            ENet.fit(X_train, y_train)\n",
    "            mse = mean_squared_error(ENet.predict(X_validation), y_validation)\n",
    "            ENet_result[str(param)] = mse\n",
    "\n",
    "        ENet_best_param = eval(min(ENet_result, key=ENet_result.get))\n",
    "        ENet_model = ElasticNet(**ENet_best_param)\n",
    "        ENet_model.fit(X_train_all, y_train_all)\n",
    "        y_pred_ENet_1990.append(ENet_model.predict(predictor[[t], 1:n_cols])[0])\n",
    "\n",
    "\n",
    "        # RF\n",
    "        RF_param = {'n_estimators': [10, 50, 100, 150, 200],\n",
    "                    'max_depth': [2, 3, 4],\n",
    "                    'min_samples_leaf': [1, 3, 5]}\n",
    "        RF_result = {}\n",
    "        for param in ParameterGrid(RF_param):\n",
    "            RF = RandomForestRegressor(**param)\n",
    "            RF.fit(X_train, y_train)\n",
    "            mse = mean_squared_error(RF.predict(X_validation), y_validation)\n",
    "            RF_result[str(param)] = mse\n",
    "\n",
    "        RF_best_param = eval(min(RF_result, key=RF_result.get))\n",
    "        RF_model = RandomForestRegressor(**RF_best_param)\n",
    "        RF_model.fit(X_train_all, y_train_all)\n",
    "        y_pred_RF_1990.append(RF_model.predict(predictor[[t], 1:n_cols])[0])\n",
    "\n",
    "        # Neural Network Models: NN2 & NN4\n",
    "        X_train_all_tensor = torch.tensor(X_train_all, dtype=torch.float)\n",
    "        y_train_all_tensor = torch.tensor(y_train_all.reshape(-1, 1), dtype=torch.float)\n",
    "        X_train_tensor = torch.tensor(X_train, dtype=torch.float)\n",
    "        y_train_tensor = torch.tensor(y_train.reshape(-1, 1), dtype=torch.float)\n",
    "        X_validation_tensor = torch.tensor(X_validation, dtype=torch.float)\n",
    "        y_validation_tensor = torch.tensor(y_validation.reshape(-1, 1), dtype=torch.float)\n",
    "\n",
    "        # NN2\n",
    "        NN2_result = {}\n",
    "        NN2_architecture = {\"module__n_feature\": X_train_tensor.shape[1],\n",
    "                            \"module__n_hidden1\": 32, \"module__n_hidden2\": 16,\n",
    "                            \"module__n_output\": 1}\n",
    "        NN2_param = {'module__dropout': [0.2, 0.4, 0.6, 0.8],\n",
    "                    'lr': [0.001, 0.01],\n",
    "                    'optimizer__weight_decay': [0.1, 0.01, 0.001]}\n",
    "        for param in ParameterGrid(NN2_param):\n",
    "            NN2 = NeuralNetRegressor(Net2, verbose=0, max_epochs=200,\n",
    "                                     optimizer=torch.optim.SGD,\n",
    "                                     **NN2_architecture, **param)\n",
    "            NN2.fit(X_train_tensor, y_train_tensor)\n",
    "            mse = mean_squared_error(NN2.predict(X_validation_tensor), y_validation)\n",
    "            NN2_result[str(param)] = mse\n",
    "        \n",
    "        #\n",
    "        NN2_best_param = eval(min(NN2_result, key=NN2_result.get))\n",
    "        NN2_model = NeuralNetRegressor(Net2, verbose=0, max_epochs=200, optimizer=torch.optim.SGD,\n",
    "                                       **NN2_architecture, **NN2_best_param)\n",
    "        NN2_model.fit(X_train_all_tensor, y_train_all_tensor)\n",
    "        y_pred_NN2_1990.append(NN2_model.predict(torch.tensor(predictor[[t], 1:n_cols], dtype=torch.float))[0][0])\n",
    "        #\n",
    "\n",
    "\n",
    "        # NN4\n",
    "        NN4_result = {}\n",
    "        NN4_architecture = {\"module__n_feature\": X_train_tensor.shape[1],\n",
    "                            \"module__n_hidden1\": 32, \"module__n_hidden2\": 16,\n",
    "                            \"module__n_hidden3\": 8,  \"module__n_hidden4\": 4,\n",
    "                            \"module__n_output\": 1}\n",
    "        NN4_param = {'module__dropout': [0.2, 0.4, 0.6, 0.8],\n",
    "                     'lr': [0.001, 0.01],\n",
    "                     'optimizer__weight_decay': [0.1, 0.01, 0.001]}\n",
    "        for param in ParameterGrid(NN4_param):\n",
    "            NN4 = NeuralNetRegressor(Net4, verbose=0, max_epochs=200,\n",
    "                                     optimizer=torch.optim.SGD,\n",
    "                                     **NN4_architecture, **param)\n",
    "            NN4.fit(X_train_tensor, y_train_tensor)\n",
    "            mse = mean_squared_error(NN4.predict(X_validation_tensor), y_validation)\n",
    "            NN4_result[str(param)] = mse\n",
    "\n",
    "        #\n",
    "        NN4_best_param = eval(min(NN4_result, key=NN4_result.get))\n",
    "        NN4_model = NeuralNetRegressor(Net4, verbose=0, max_epochs=200, optimizer=torch.optim.SGD,\n",
    "                                       **NN4_architecture, **NN4_best_param)\n",
    "        NN4_model.fit(X_train_all_tensor, y_train_all_tensor)\n",
    "        y_pred_NN4_1990.append(NN4_model.predict(torch.tensor(predictor[[t], 1:n_cols], dtype=torch.float))[0][0])\n",
    "\n",
    "\n",
    "        ## Other commmonly used ML methods\n",
    "        # Ridge\n",
    "        Ridge_param = {'alpha': list(10 ** np.arange(0, 20 + 0.001, 1))}\n",
    "        Ridge_result = {}\n",
    "        for param in ParameterGrid(Ridge_param):\n",
    "            RIDGE = Ridge(**param)\n",
    "            RIDGE.fit(X_train, y_train)\n",
    "            mse = mean_squared_error(RIDGE.predict(X_validation), y_validation)\n",
    "            Ridge_result[str(param)] = mse\n",
    "        #\n",
    "        Ridge_best_param = eval(min(Ridge_result, key=Ridge_result.get))\n",
    "        Ridge_model = Ridge(**Ridge_best_param)\n",
    "        Ridge_model.fit(X_train_all, y_train_all)\n",
    "        y_pred_Ridge_1990.append(Ridge_model.predict(predictor[[t], 1:n_cols])[0])\n",
    "\n",
    "    else:\n",
    "        month_index += 1\n",
    "        y_pred_PLS_1990.append(PLS_model.predict(predictor[[t], 1:n_cols])[0][0])\n",
    "        y_pred_PCR_1990.append(PCR_forecast.predict(PCR_model.transform(predictor[[t], 1:n_cols]))[0])\n",
    "        y_pred_LASSO_1990.append(LASSO_model.predict(predictor[[t], 1:n_cols])[0])\n",
    "        y_pred_ENet_1990.append(ENet_model.predict(predictor[[t], 1:n_cols])[0])\n",
    "        y_pred_RF_1990.append(RF_model.predict(predictor[[t], 1:n_cols])[0])\n",
    "        y_pred_NN2_1990.append(NN2_model.predict(torch.tensor(predictor[[t], 1:n_cols], dtype=torch.float))[0][0])\n",
    "        y_pred_NN4_1990.append(NN4_model.predict(torch.tensor(predictor[[t], 1:n_cols], dtype=torch.float))[0][0])\n",
    "        # Other commonly used ML methods\n",
    "        y_pred_Ridge_1990.append(Ridge_model.predict(predictor[[t], 1:n_cols])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6a1f3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ml_pred_1990 = pd.DataFrame(np.array([y_pred_PLS_1990, y_pred_PCR_1990, y_pred_LASSO_1990,\n",
    "                                   y_pred_ENet_1990, y_pred_RF_1990, y_pred_NN2_1990,  \n",
    "                                   y_pred_NN4_1990, y_pred_Ridge_1990]),\n",
    "                         index=['PLS', 'PCR', 'LASSO', 'ENet', \n",
    "                                'RF', 'NN2', 'NN4', 'Ridge'],\n",
    "                         columns=predictor_df.month[in_out_1990:N]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8378dc2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Performance compared with HA benchmark\n",
    "\n",
    "def compute_oos_r_square(actual, y_benchmark, y_pred):\n",
    "    MSFE_benchmark = mean_squared_error(y_benchmark, actual)\n",
    "    MSFE_pred = mean_squared_error(y_pred, actual)\n",
    "    return 1 - MSFE_pred / MSFE_benchmark\n",
    "\n",
    "\n",
    "ml_oos_performance_macro = []\n",
    "\n",
    "for col in y_ml_pred_1990.columns:\n",
    "    oos_r_square = compute_oos_r_square(actual_1990, y_pred_HA_1990, y_ml_pred_1990[[col]].to_numpy())\n",
    "    MSFE_adjusted, pvalue_MSFE = CW_test(actual_1990, y_pred_HA_1990, y_ml_pred_1990[[col]].to_numpy())\n",
    "    success_ratio, PT_stat, pvalue_PT = PT_test(actual_1990, y_ml_pred_1990[[col]].to_numpy())\n",
    "    ml_oos_performance_macro.append([oos_r_square * 100, MSFE_adjusted, pvalue_MSFE, success_ratio * 100, PT_stat, pvalue_PT])\n",
    "\n",
    "\n",
    "ml_oos_performance_df_macro = pd.DataFrame(np.array(ml_oos_performance_macro),\n",
    "                                          index=y_ml_pred_1990.columns,\n",
    "                                          columns=['oos_r_square', 'MSFE_adjusted', 'pvalue_MSFE',\n",
    "                                                   'success_ratio', 'PT_stat', 'pvalue_PT'])\n",
    "# success ratio of HA\n",
    "success_ratio_HA_1990, PT_HA_1990, p2_HA_1990 = PT_test(actual_1990, y_pred_HA_1990)\n",
    "ml_oos_performance_df_macro.loc['HA'] = [0, np.nan, np.nan, success_ratio_HA_1990 * 100, PT_HA_1990, p2_HA_1990]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0fba4ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>oos_r_square</th>\n",
       "      <th>MSFE_adjusted</th>\n",
       "      <th>pvalue_MSFE</th>\n",
       "      <th>success_ratio</th>\n",
       "      <th>PT_stat</th>\n",
       "      <th>pvalue_PT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PLS</th>\n",
       "      <td>-12.780186</td>\n",
       "      <td>-1.414876</td>\n",
       "      <td>0.921448</td>\n",
       "      <td>57.951482</td>\n",
       "      <td>-0.838793</td>\n",
       "      <td>0.799207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCR</th>\n",
       "      <td>-2.656288</td>\n",
       "      <td>-0.088368</td>\n",
       "      <td>0.535208</td>\n",
       "      <td>59.299191</td>\n",
       "      <td>-2.259486</td>\n",
       "      <td>0.988073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LASSO</th>\n",
       "      <td>-3.819944</td>\n",
       "      <td>-2.137887</td>\n",
       "      <td>0.983737</td>\n",
       "      <td>57.412399</td>\n",
       "      <td>-2.172524</td>\n",
       "      <td>0.985092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENet</th>\n",
       "      <td>-3.525860</td>\n",
       "      <td>-0.941180</td>\n",
       "      <td>0.826694</td>\n",
       "      <td>57.412399</td>\n",
       "      <td>-1.439037</td>\n",
       "      <td>0.924930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>-21.424013</td>\n",
       "      <td>-1.037624</td>\n",
       "      <td>0.850278</td>\n",
       "      <td>53.908356</td>\n",
       "      <td>0.918448</td>\n",
       "      <td>0.179192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN2</th>\n",
       "      <td>-11.775560</td>\n",
       "      <td>-0.830699</td>\n",
       "      <td>0.796928</td>\n",
       "      <td>56.334232</td>\n",
       "      <td>-0.408842</td>\n",
       "      <td>0.658672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN4</th>\n",
       "      <td>-17.873034</td>\n",
       "      <td>-0.024890</td>\n",
       "      <td>0.509929</td>\n",
       "      <td>64.150943</td>\n",
       "      <td>1.040546</td>\n",
       "      <td>0.149043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.120724</td>\n",
       "      <td>1.184863</td>\n",
       "      <td>0.118036</td>\n",
       "      <td>63.611860</td>\n",
       "      <td>0.674617</td>\n",
       "      <td>0.249959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HA</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64.150943</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       oos_r_square  MSFE_adjusted  pvalue_MSFE  success_ratio   PT_stat  \\\n",
       "PLS      -12.780186      -1.414876     0.921448      57.951482 -0.838793   \n",
       "PCR       -2.656288      -0.088368     0.535208      59.299191 -2.259486   \n",
       "LASSO     -3.819944      -2.137887     0.983737      57.412399 -2.172524   \n",
       "ENet      -3.525860      -0.941180     0.826694      57.412399 -1.439037   \n",
       "RF       -21.424013      -1.037624     0.850278      53.908356  0.918448   \n",
       "NN2      -11.775560      -0.830699     0.796928      56.334232 -0.408842   \n",
       "NN4      -17.873034      -0.024890     0.509929      64.150943  1.040546   \n",
       "Ridge      0.120724       1.184863     0.118036      63.611860  0.674617   \n",
       "HA         0.000000            NaN          NaN      64.150943       NaN   \n",
       "\n",
       "       pvalue_PT  \n",
       "PLS     0.799207  \n",
       "PCR     0.988073  \n",
       "LASSO   0.985092  \n",
       "ENet    0.924930  \n",
       "RF      0.179192  \n",
       "NN2     0.658672  \n",
       "NN4     0.149043  \n",
       "Ridge   0.249959  \n",
       "HA           NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save\n",
    "import openpyxl\n",
    "with pd.ExcelWriter(\"ml_equity_premium_robust_checks.xlsx\", engine='openpyxl', mode='a') as writer:\n",
    "    ml_oos_performance_df_macro.to_excel(writer, sheet_name='Alternative_macro_datasets')\n",
    "ml_oos_performance_df_macro"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
