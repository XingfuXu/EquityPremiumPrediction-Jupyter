{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2df2b249",
   "metadata": {},
   "source": [
    "### Using a robust scoring function on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f822b3b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/xingfuxu/PycharmProjects/EquityPremiumPredictionML-Jupyter'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "# os.chdir(path)    # or you can set your working dir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3c1c50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your working dir should include \"NN_models.py\", Perform_CW_test.py\" and \"Perform_PT_test.py\" files.\n",
    "from Perform_CW_test import CW_test\n",
    "from Perform_PT_test import PT_test\n",
    "from NN_models import Net1, Net2, Net3, Net4, Net5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e772b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import torch\n",
    "from skorch import NeuralNetRegressor\n",
    "from tqdm import tqdm\n",
    "#\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, median_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50dbea16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>log_equity_premium</th>\n",
       "      <th>equity_premium</th>\n",
       "      <th>DP</th>\n",
       "      <th>DY</th>\n",
       "      <th>EP</th>\n",
       "      <th>SVAR</th>\n",
       "      <th>BM</th>\n",
       "      <th>NTIS</th>\n",
       "      <th>TBL</th>\n",
       "      <th>...</th>\n",
       "      <th>MA_2_9</th>\n",
       "      <th>MA_2_12</th>\n",
       "      <th>MA_3_9</th>\n",
       "      <th>MA_3_12</th>\n",
       "      <th>MOM_1</th>\n",
       "      <th>MOM_2</th>\n",
       "      <th>MOM_3</th>\n",
       "      <th>MOM_6</th>\n",
       "      <th>MOM_9</th>\n",
       "      <th>MOM_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>192701</td>\n",
       "      <td>-0.005710</td>\n",
       "      <td>-0.00571</td>\n",
       "      <td>-2.942374</td>\n",
       "      <td>-2.963349</td>\n",
       "      <td>-2.374773</td>\n",
       "      <td>0.00047</td>\n",
       "      <td>0.44371</td>\n",
       "      <td>0.05082</td>\n",
       "      <td>3.23</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>192702</td>\n",
       "      <td>0.042017</td>\n",
       "      <td>0.04302</td>\n",
       "      <td>-2.979535</td>\n",
       "      <td>-2.932946</td>\n",
       "      <td>-2.430353</td>\n",
       "      <td>0.00029</td>\n",
       "      <td>0.42850</td>\n",
       "      <td>0.05167</td>\n",
       "      <td>3.29</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>192703</td>\n",
       "      <td>0.004697</td>\n",
       "      <td>0.00472</td>\n",
       "      <td>-2.976535</td>\n",
       "      <td>-2.970053</td>\n",
       "      <td>-2.445079</td>\n",
       "      <td>0.00092</td>\n",
       "      <td>0.46977</td>\n",
       "      <td>0.04636</td>\n",
       "      <td>3.20</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>192704</td>\n",
       "      <td>0.009940</td>\n",
       "      <td>0.01002</td>\n",
       "      <td>-2.984225</td>\n",
       "      <td>-2.967143</td>\n",
       "      <td>-2.471309</td>\n",
       "      <td>0.00060</td>\n",
       "      <td>0.45675</td>\n",
       "      <td>0.05051</td>\n",
       "      <td>3.39</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>192705</td>\n",
       "      <td>0.057987</td>\n",
       "      <td>0.05985</td>\n",
       "      <td>-3.025963</td>\n",
       "      <td>-2.975058</td>\n",
       "      <td>-2.531446</td>\n",
       "      <td>0.00039</td>\n",
       "      <td>0.43478</td>\n",
       "      <td>0.05528</td>\n",
       "      <td>3.33</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    month  log_equity_premium  equity_premium        DP        DY        EP  \\\n",
       "0  192701           -0.005710        -0.00571 -2.942374 -2.963349 -2.374773   \n",
       "1  192702            0.042017         0.04302 -2.979535 -2.932946 -2.430353   \n",
       "2  192703            0.004697         0.00472 -2.976535 -2.970053 -2.445079   \n",
       "3  192704            0.009940         0.01002 -2.984225 -2.967143 -2.471309   \n",
       "4  192705            0.057987         0.05985 -3.025963 -2.975058 -2.531446   \n",
       "\n",
       "      SVAR       BM     NTIS   TBL  ...  MA_2_9  MA_2_12  MA_3_9  MA_3_12  \\\n",
       "0  0.00047  0.44371  0.05082  3.23  ...       1        1       1        1   \n",
       "1  0.00029  0.42850  0.05167  3.29  ...       1        1       1        1   \n",
       "2  0.00092  0.46977  0.04636  3.20  ...       1        1       1        1   \n",
       "3  0.00060  0.45675  0.05051  3.39  ...       1        1       1        1   \n",
       "4  0.00039  0.43478  0.05528  3.33  ...       1        1       1        1   \n",
       "\n",
       "   MOM_1  MOM_2  MOM_3  MOM_6  MOM_9  MOM_12  \n",
       "0      0      0      1      1      1       1  \n",
       "1      1      1      1      1      1       1  \n",
       "2      1      1      1      1      1       1  \n",
       "3      1      1      1      1      1       1  \n",
       "4      1      1      1      1      1       1  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set seed\n",
    "torch.manual_seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "# read data\n",
    "predictor_df = pd.read_excel(open('ml_equity_premium_data.xlsx', 'rb'), sheet_name='result_predictor')\n",
    "predictor_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5218722b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove irrelavent columns\n",
    "predictor0 = predictor_df.drop(['month', 'equity_premium'], axis=1)\n",
    "# get all the predictors and set the log equity premium 1-month ahead\n",
    "predictor = np.concatenate([predictor0['log_equity_premium'][1:].values.reshape(-1, 1),\n",
    "                            predictor0.iloc[0:(predictor0.shape[0] - 1), 1:]], axis=1)\n",
    "\n",
    "# number of rows\n",
    "N = predictor.shape[0]\n",
    "\n",
    "# number of all columns, including the log equity premium\n",
    "n_cols = predictor.shape[1]\n",
    "\n",
    "# Actual one-month ahead log equity premium\n",
    "actual = predictor[:, [0]]\n",
    "\n",
    "# Historical average forecasting as benchmark\n",
    "y_pred_HA = predictor0['log_equity_premium'].values[0:(predictor0.shape[0] - 1), ].cumsum() / np.arange(1, N + 1)\n",
    "y_pred_HA = y_pred_HA.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f59806b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Out-of-sample: 1957:01-2020:12\n",
    "in_out_1957 = predictor_df.index[predictor_df['month'] == 195701][0]\n",
    "actual_1957 = actual[in_out_1957:, ]\n",
    "y_pred_HA_1957 = y_pred_HA[in_out_1957:, ]\n",
    "MSFE_HA_1957 = mean_squared_error(y_pred_HA_1957, actual_1957)\n",
    "\n",
    "# Machine Learning methods used in GKX (2020)\n",
    "y_pred_OLS_1957, y_pred_PLS_1957, y_pred_PCR_1957,  y_pred_LASSO_1957 = [], [], [], []\n",
    "y_pred_ENet_1957, y_pred_GBRT_1957, y_pred_RF_1957 = [], [], []\n",
    "y_pred_NN1_1957, y_pred_NN2_1957, y_pred_NN3_1957, y_pred_NN4_1957, y_pred_NN5_1957 = [], [], [], [], []\n",
    "\n",
    "## Other commonly used machine learning method\n",
    "y_pred_Ridge_1957, y_pred_SVR_1957, y_pred_KNR_1957,  y_pred_XGBoost_1957 = [], [], [], []\n",
    "y_pred_combination_1957 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3aaf62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# control the update month of models during out-of-sample period. \n",
    "month_index = 1  # We update our models annually, meaning we refresh them in months 1, 13, 25, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5dcc763",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 767/767 [12:21:54<00:00, 58.04s/it]\n"
     ]
    }
   ],
   "source": [
    "for t in tqdm(range(in_out_1957, N)):\n",
    "    #\n",
    "    X_train_all = predictor[:t, 1:n_cols]\n",
    "    y_train_all = predictor[:t, 0]\n",
    "    # set 15% of all the train data as validation set\n",
    "    X_train = X_train_all[0:int(len(X_train_all) * 0.85), :]\n",
    "    X_validation = X_train_all[int(len(X_train_all) * 0.85):t, :]\n",
    "    y_train = y_train_all[0:int(len(X_train_all) * 0.85)]\n",
    "    y_validation = y_train_all[int(len(X_train_all) * 0.85):t]\n",
    "    #\n",
    "    if month_index % 12 == 1:\n",
    "        month_index += 1\n",
    "        # OLS\n",
    "        OLS = LinearRegression()\n",
    "        OLS.fit(X_train_all, y_train_all)\n",
    "        y_pred_OLS_1957.append(OLS.predict(predictor[[t], 1:n_cols])[0])\n",
    "\n",
    "        # PLS\n",
    "        PLS_param = {'n_components': [1, 2, 3, 4, 5, 6, 7, 8]}\n",
    "        PLS_result = {}\n",
    "        for param in ParameterGrid(PLS_param):\n",
    "            PLS = PLSRegression(**param)\n",
    "            PLS.fit(X_train, y_train)\n",
    "            mse = median_absolute_error(PLS.predict(X_validation), y_validation)\n",
    "            PLS_result[str(param)] = mse\n",
    "\n",
    "        PLS_best_param = eval(min(PLS_result, key=PLS_result.get))\n",
    "        PLS_model = PLSRegression(**PLS_best_param)\n",
    "        PLS_model.fit(X_train_all, y_train_all)\n",
    "        y_pred_PLS_1957.append(PLS_model.predict(predictor[[t], 1:n_cols])[0][0])\n",
    "\n",
    "        # PCR\n",
    "        PCR_param = {'n_components': [1, 2, 3, 4, 5, 6, 7, 8]}\n",
    "        PCR_result = {}\n",
    "        for param in ParameterGrid(PCR_param):\n",
    "            pca = PCA(**param)\n",
    "            pca.fit(X_train)\n",
    "            comps = pca.transform(X_train)\n",
    "            forecast = LinearRegression()\n",
    "            forecast.fit(comps, y_train)\n",
    "            mse = median_absolute_error(forecast.predict(pca.transform(X_validation)), y_validation)\n",
    "            PCR_result[str(param)] = mse\n",
    "        #\n",
    "        PCR_best_param = eval(min(PCR_result, key=PCR_result.get))\n",
    "        #\n",
    "        PCR_model = PCA(**PCR_best_param)\n",
    "        PCR_model.fit(X_train_all)\n",
    "        PCR_comps = PCR_model.transform(X_train_all)\n",
    "        PCR_forecast = LinearRegression()\n",
    "        PCR_forecast.fit(PCR_comps, y_train_all)\n",
    "        y_pred_PCR_1957.append(PCR_forecast.predict(PCR_model.transform(predictor[[t], 1:n_cols]))[0])\n",
    "\n",
    "        # LASSO\n",
    "        LASSO_param = {'alpha': list(10 ** np.arange(-4, 1 + 0.001, 0.2))}\n",
    "        LASSO_result = {}\n",
    "        for param in ParameterGrid(LASSO_param):\n",
    "            LASSO = Lasso(**param)\n",
    "            LASSO.fit(X_train, y_train)\n",
    "            mse = median_absolute_error(LASSO.predict(X_validation), y_validation)\n",
    "            LASSO_result[str(param)] = mse\n",
    "        #\n",
    "        LASSO_best_param = eval(min(LASSO_result, key=LASSO_result.get))\n",
    "        #\n",
    "        LASSO_model = Lasso(**LASSO_best_param)\n",
    "        LASSO_model.fit(X_train_all, y_train_all)\n",
    "        y_pred_LASSO_1957.append(LASSO_model.predict(predictor[[t], 1:n_cols])[0])\n",
    "\n",
    "        # ENet\n",
    "        ENet_param = {'alpha': list(10 ** np.arange(-4, 1 + 0.001, 0.2)),\n",
    "                      'l1_ratio': list(np.arange(0.2, 1, 0.3))}\n",
    "        ENet_result = {}\n",
    "        for param in ParameterGrid(ENet_param):\n",
    "            ENet = ElasticNet(**param)\n",
    "            ENet.fit(X_train, y_train)\n",
    "            mse = median_absolute_error(ENet.predict(X_validation), y_validation)\n",
    "            ENet_result[str(param)] = mse\n",
    "\n",
    "        ENet_best_param = eval(min(ENet_result, key=ENet_result.get))\n",
    "        ENet_model = ElasticNet(**ENet_best_param)\n",
    "        ENet_model.fit(X_train_all, y_train_all)\n",
    "        y_pred_ENet_1957.append(ENet_model.predict(predictor[[t], 1:n_cols])[0])\n",
    "\n",
    "        # GBRT\n",
    "        GBRT_param = {'n_estimators': [10, 50, 100, 150, 200],\n",
    "                      'max_depth': [2, 3, 4],\n",
    "                      'min_samples_leaf': [1, 3, 5]}\n",
    "        GBRT_result = {}\n",
    "        for param in ParameterGrid(GBRT_param):\n",
    "            GBRT = GradientBoostingRegressor(**param)\n",
    "            GBRT.fit(X_train, y_train)\n",
    "            mse = median_absolute_error(GBRT.predict(X_validation), y_validation)\n",
    "            GBRT_result[str(param)] = mse\n",
    "\n",
    "        GBRT_best_param = eval(min(GBRT_result, key=GBRT_result.get))\n",
    "        GBRT_model = GradientBoostingRegressor(**GBRT_best_param)\n",
    "        GBRT_model.fit(X_train_all, y_train_all)\n",
    "        y_pred_GBRT_1957.append(GBRT_model.predict(predictor[[t], 1:n_cols])[0])\n",
    "\n",
    "        # RF\n",
    "        RF_param = {'n_estimators': [10, 50, 100, 150, 200],\n",
    "                    'max_depth': [2, 3, 4],\n",
    "                    'min_samples_leaf': [1, 3, 5]}\n",
    "        RF_result = {}\n",
    "        for param in ParameterGrid(RF_param):\n",
    "            RF = RandomForestRegressor(**param)\n",
    "            RF.fit(X_train, y_train)\n",
    "            mse = median_absolute_error(RF.predict(X_validation), y_validation)\n",
    "            RF_result[str(param)] = mse\n",
    "\n",
    "        RF_best_param = eval(min(RF_result, key=RF_result.get))\n",
    "        RF_model = RandomForestRegressor(**RF_best_param)\n",
    "        RF_model.fit(X_train_all, y_train_all)\n",
    "        y_pred_RF_1957.append(RF_model.predict(predictor[[t], 1:n_cols])[0])\n",
    "\n",
    "        # Neural Network Models: NN1~NN5\n",
    "        X_train_all_tensor = torch.tensor(X_train_all, dtype=torch.float)\n",
    "        y_train_all_tensor = torch.tensor(y_train_all.reshape(-1, 1), dtype=torch.float)\n",
    "        X_train_tensor = torch.tensor(X_train, dtype=torch.float)\n",
    "        y_train_tensor = torch.tensor(y_train.reshape(-1, 1), dtype=torch.float)\n",
    "        X_validation_tensor = torch.tensor(X_validation, dtype=torch.float)\n",
    "        y_validation_tensor = torch.tensor(y_validation.reshape(-1, 1), dtype=torch.float)\n",
    "\n",
    "        # NN1\n",
    "        NN1_result = {}\n",
    "        NN1_architecture = {\"module__n_feature\": X_train_tensor.shape[1],  # n_feature should be the number of predictors\n",
    "                            \"module__n_hidden1\": 32,\n",
    "                            \"module__n_output\": 1}\n",
    "        NN1_param = {'module__dropout': [0.2, 0.4, 0.6, 0.8],\n",
    "                    'lr': [0.001, 0.01],\n",
    "                    'optimizer__weight_decay': [0.1, 0.01, 0.001]}\n",
    "        for param in ParameterGrid(NN1_param):\n",
    "            NN1 = NeuralNetRegressor(Net1, verbose=0, max_epochs=200,\n",
    "                                     optimizer=torch.optim.SGD,\n",
    "                                     **NN1_architecture, **param)\n",
    "            NN1.fit(X_train_tensor, y_train_tensor)\n",
    "            mse = median_absolute_error(NN1.predict(X_validation_tensor), y_validation)\n",
    "            NN1_result[str(param)] = mse\n",
    "\n",
    "        #\n",
    "        NN1_best_param = eval(min(NN1_result, key=NN1_result.get))\n",
    "        NN1_model = NeuralNetRegressor(Net1, verbose=0, max_epochs=200, optimizer=torch.optim.SGD,\n",
    "                                       **NN1_architecture, **NN1_best_param)\n",
    "        NN1_model.fit(X_train_all_tensor, y_train_all_tensor)\n",
    "        y_pred_NN1_1957.append(NN1_model.predict(torch.tensor(predictor[[t], 1:n_cols], dtype=torch.float))[0][0])\n",
    "\n",
    "\n",
    "        # NN2\n",
    "        NN2_result = {}\n",
    "        NN2_architecture = {\"module__n_feature\": X_train_tensor.shape[1],\n",
    "                            \"module__n_hidden1\": 32, \"module__n_hidden2\": 16,\n",
    "                            \"module__n_output\": 1}\n",
    "        NN2_param = {'module__dropout': [0.2, 0.4, 0.6, 0.8],\n",
    "                    'lr': [0.001, 0.01],\n",
    "                    'optimizer__weight_decay': [0.1, 0.01, 0.001]}\n",
    "        for param in ParameterGrid(NN2_param):\n",
    "            NN2 = NeuralNetRegressor(Net2, verbose=0, max_epochs=200,\n",
    "                                     optimizer=torch.optim.SGD,\n",
    "                                     **NN2_architecture, **param)\n",
    "            NN2.fit(X_train_tensor, y_train_tensor)\n",
    "            mse = median_absolute_error(NN2.predict(X_validation_tensor), y_validation)\n",
    "            NN2_result[str(param)] = mse\n",
    "        \n",
    "        #\n",
    "        NN2_best_param = eval(min(NN2_result, key=NN2_result.get))\n",
    "        NN2_model = NeuralNetRegressor(Net2, verbose=0, max_epochs=200, optimizer=torch.optim.SGD,\n",
    "                                       **NN2_architecture, **NN2_best_param)\n",
    "        NN2_model.fit(X_train_all_tensor, y_train_all_tensor)\n",
    "        y_pred_NN2_1957.append(NN2_model.predict(torch.tensor(predictor[[t], 1:n_cols], dtype=torch.float))[0][0])\n",
    "        #\n",
    "\n",
    "        # NN3\n",
    "        NN3_result = {}\n",
    "        NN3_architecture = {\"module__n_feature\": X_train_tensor.shape[1],\n",
    "                            # n_feature should be the number of predictors\n",
    "                            \"module__n_hidden1\": 32, \"module__n_hidden2\": 16,\n",
    "                            \"module__n_hidden3\": 8,\n",
    "                            \"module__n_output\": 1}\n",
    "        NN3_param = {'module__dropout': [0.2, 0.4, 0.6, 0.8],\n",
    "                     'lr': [0.001, 0.01],\n",
    "                     'optimizer__weight_decay': [0.1, 0.01, 0.001]}\n",
    "        for param in ParameterGrid(NN3_param):\n",
    "            NN3 = NeuralNetRegressor(Net3, verbose=0, max_epochs=200,\n",
    "                                     optimizer=torch.optim.SGD,\n",
    "                                     **NN3_architecture, **param)\n",
    "            NN3.fit(X_train_tensor, y_train_tensor)\n",
    "            mse = median_absolute_error(NN3.predict(X_validation_tensor), y_validation)\n",
    "            NN3_result[str(param)] = mse\n",
    "\n",
    "        #\n",
    "        NN3_best_param = eval(min(NN3_result, key=NN3_result.get))\n",
    "        NN3_model = NeuralNetRegressor(Net3, verbose=0, max_epochs=200, optimizer=torch.optim.SGD,\n",
    "                                       **NN3_architecture, **NN3_best_param)\n",
    "        NN3_model.fit(X_train_all_tensor, y_train_all_tensor)\n",
    "        y_pred_NN3_1957.append(NN3_model.predict(torch.tensor(predictor[[t], 1:n_cols], dtype=torch.float))[0][0])\n",
    "        #\n",
    "\n",
    "        # NN4\n",
    "        NN4_result = {}\n",
    "        NN4_architecture = {\"module__n_feature\": X_train_tensor.shape[1],\n",
    "                            \"module__n_hidden1\": 32, \"module__n_hidden2\": 16,\n",
    "                            \"module__n_hidden3\": 8,  \"module__n_hidden4\": 4,\n",
    "                            \"module__n_output\": 1}\n",
    "        NN4_param = {'module__dropout': [0.2, 0.4, 0.6, 0.8],\n",
    "                     'lr': [0.001, 0.01],\n",
    "                     'optimizer__weight_decay': [0.1, 0.01, 0.001]}\n",
    "        for param in ParameterGrid(NN4_param):\n",
    "            NN4 = NeuralNetRegressor(Net4, verbose=0, max_epochs=200,\n",
    "                                     optimizer=torch.optim.SGD,\n",
    "                                     **NN4_architecture, **param)\n",
    "            NN4.fit(X_train_tensor, y_train_tensor)\n",
    "            mse = median_absolute_error(NN4.predict(X_validation_tensor), y_validation)\n",
    "            NN4_result[str(param)] = mse\n",
    "\n",
    "        #\n",
    "        NN4_best_param = eval(min(NN4_result, key=NN4_result.get))\n",
    "        NN4_model = NeuralNetRegressor(Net4, verbose=0, max_epochs=200, optimizer=torch.optim.SGD,\n",
    "                                       **NN4_architecture, **NN4_best_param)\n",
    "        NN4_model.fit(X_train_all_tensor, y_train_all_tensor)\n",
    "        y_pred_NN4_1957.append(NN4_model.predict(torch.tensor(predictor[[t], 1:n_cols], dtype=torch.float))[0][0])\n",
    "        #\n",
    "\n",
    "        # NN5\n",
    "        NN5_result = {}\n",
    "        NN5_architecture = {\"module__n_feature\": X_train_tensor.shape[1],\n",
    "                            \"module__n_hidden1\": 32, \"module__n_hidden2\": 16,\n",
    "                            \"module__n_hidden3\": 8,  \"module__n_hidden4\": 4,\n",
    "                            \"module__n_hidden5\": 2,\n",
    "                            \"module__n_output\": 1}\n",
    "        NN5_param = {'module__dropout': [0.2, 0.4, 0.6, 0.8],\n",
    "                     'lr': [0.001, 0.01],\n",
    "                     'optimizer__weight_decay': [0.1, 0.01, 0.001]}\n",
    "        for param in ParameterGrid(NN5_param):\n",
    "            NN5 = NeuralNetRegressor(Net5, verbose=0, max_epochs=200,\n",
    "                                     optimizer=torch.optim.SGD,\n",
    "                                     **NN5_architecture, **param)\n",
    "            NN5.fit(X_train_tensor, y_train_tensor)\n",
    "            mse = median_absolute_error(NN5.predict(X_validation_tensor), y_validation)\n",
    "            NN5_result[str(param)] = mse\n",
    "\n",
    "        #\n",
    "        NN5_best_param = eval(min(NN5_result, key=NN5_result.get))\n",
    "        NN5_model = NeuralNetRegressor(Net5, verbose=0, max_epochs=200, optimizer=torch.optim.SGD,\n",
    "                                       **NN5_architecture, **NN5_best_param)\n",
    "        NN5_model.fit(X_train_all_tensor, y_train_all_tensor)\n",
    "        y_pred_NN5_1957.append(NN5_model.predict(torch.tensor(predictor[[t], 1:n_cols], dtype=torch.float))[0][0])\n",
    "        #\n",
    "\n",
    "        ## Other commmonly used ML methods\n",
    "        # Ridge\n",
    "        Ridge_param = {'alpha': list(10 ** np.arange(0, 20 + 0.001, 1))}\n",
    "        Ridge_result = {}\n",
    "        for param in ParameterGrid(Ridge_param):\n",
    "            RIDGE = Ridge(**param)\n",
    "            RIDGE.fit(X_train, y_train)\n",
    "            mse = median_absolute_error(RIDGE.predict(X_validation), y_validation)\n",
    "            Ridge_result[str(param)] = mse\n",
    "        #\n",
    "        Ridge_best_param = eval(min(Ridge_result, key=Ridge_result.get))\n",
    "        Ridge_model = Ridge(**Ridge_best_param)\n",
    "        Ridge_model.fit(X_train_all, y_train_all)\n",
    "        y_pred_Ridge_1957.append(Ridge_model.predict(predictor[[t], 1:n_cols])[0])\n",
    "\n",
    "        # SVR\n",
    "        SVR_param = {'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'degree': [2, 3, 4], 'C': [0.1, 0.5, 1]}\n",
    "        SVR_result = {}\n",
    "        for param in ParameterGrid(SVR_param):\n",
    "            SVR_tmp = SVR(**param)\n",
    "            SVR_tmp.fit(X_train, y_train)\n",
    "            mse = median_absolute_error(SVR_tmp.predict(X_validation), y_validation)\n",
    "            SVR_result[str(param)] = mse\n",
    "        SVR_best_param = eval(min(SVR_result, key=SVR_result.get))\n",
    "        SVR_model = SVR(**SVR_best_param)\n",
    "        SVR_model.fit(X_train_all, y_train_all)\n",
    "        y_pred_SVR_1957.append(SVR_model.predict(predictor[[t], 1:n_cols])[0])\n",
    "\n",
    "        # KNR\n",
    "        KNR = KNeighborsRegressor()\n",
    "        KNR_param = {'n_neighbors': [3, 4, 5, 6, 7], 'weights': ['distance', 'uniform'],\n",
    "                     'leaf_size': [20, 30, 40], 'p': [1, 2, 3]}\n",
    "        KNR_result = {}\n",
    "        for param in ParameterGrid(KNR_param):\n",
    "            KNR = KNeighborsRegressor(**param)\n",
    "            KNR.fit(X_train, y_train)\n",
    "            mse = median_absolute_error(KNR.predict(X_validation), y_validation)\n",
    "            KNR_result[str(param)] = mse\n",
    "\n",
    "        KNR_best_param = eval(min(KNR_result, key=KNR_result.get))\n",
    "        KNR_model = KNeighborsRegressor(**KNR_best_param)\n",
    "        KNR_model.fit(X_train_all, y_train_all)\n",
    "        y_pred_KNR_1957.append(KNR_model.predict(predictor[[t], 1:n_cols])[0])\n",
    "\n",
    "\n",
    "        # XGBoost\n",
    "        XGBoost_param =  {'max_depth': [4, 5, 6, 7, 8], 'eta': [0.01, 0.1],\n",
    "                          'lambda': [0, 0.5, 1], 'alpha': [0, 0.5, 1]}\n",
    "        XGBoost_result = {}\n",
    "        for param in ParameterGrid(XGBoost_param):\n",
    "            XGBoost = XGBRegressor(**param)\n",
    "            XGBoost.fit(X_train, y_train)\n",
    "            mse = median_absolute_error(XGBoost.predict(X_validation), y_validation)\n",
    "            XGBoost_result[str(param)] = mse\n",
    "\n",
    "        XGB_best_param = eval(min(XGBoost_result, key=XGBoost_result.get))\n",
    "        XGB_model = XGBRegressor(**XGB_best_param)\n",
    "        XGB_model.fit(X_train_all, y_train_all)\n",
    "        y_pred_XGBoost_1957.append(XGB_model.predict(predictor[[t], 1:n_cols])[0])\n",
    "    else:\n",
    "        month_index += 1\n",
    "        y_pred_OLS_1957.append(OLS.predict(predictor[[t], 1:n_cols])[0])\n",
    "        y_pred_PLS_1957.append(PLS_model.predict(predictor[[t], 1:n_cols])[0][0])\n",
    "        y_pred_PCR_1957.append(PCR_forecast.predict(PCR_model.transform(predictor[[t], 1:n_cols]))[0])\n",
    "        y_pred_LASSO_1957.append(LASSO_model.predict(predictor[[t], 1:n_cols])[0])\n",
    "        y_pred_ENet_1957.append(ENet_model.predict(predictor[[t], 1:n_cols])[0])\n",
    "        y_pred_GBRT_1957.append(GBRT_model.predict(predictor[[t], 1:n_cols])[0])\n",
    "        y_pred_RF_1957.append(RF_model.predict(predictor[[t], 1:n_cols])[0])\n",
    "        y_pred_NN1_1957.append(NN1_model.predict(torch.tensor(predictor[[t], 1:n_cols], dtype=torch.float))[0][0])\n",
    "        y_pred_NN2_1957.append(NN2_model.predict(torch.tensor(predictor[[t], 1:n_cols], dtype=torch.float))[0][0])\n",
    "        y_pred_NN3_1957.append(NN3_model.predict(torch.tensor(predictor[[t], 1:n_cols], dtype=torch.float))[0][0])\n",
    "        y_pred_NN4_1957.append(NN4_model.predict(torch.tensor(predictor[[t], 1:n_cols], dtype=torch.float))[0][0])\n",
    "        y_pred_NN5_1957.append(NN5_model.predict(torch.tensor(predictor[[t], 1:n_cols], dtype=torch.float))[0][0])\n",
    "        # Other commonly used ML methods\n",
    "        y_pred_Ridge_1957.append(Ridge_model.predict(predictor[[t], 1:n_cols])[0])\n",
    "        y_pred_SVR_1957.append(SVR_model.predict(predictor[[t], 1:n_cols])[0])\n",
    "        y_pred_KNR_1957.append(KNR_model.predict(predictor[[t], 1:n_cols])[0])\n",
    "        y_pred_XGBoost_1957.append(XGB_model.predict(predictor[[t], 1:n_cols])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6a1f3d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OLS</th>\n",
       "      <th>PLS</th>\n",
       "      <th>PCR</th>\n",
       "      <th>LASSO</th>\n",
       "      <th>ENet</th>\n",
       "      <th>GBRT</th>\n",
       "      <th>RF</th>\n",
       "      <th>NN1</th>\n",
       "      <th>NN2</th>\n",
       "      <th>NN3</th>\n",
       "      <th>NN4</th>\n",
       "      <th>NN5</th>\n",
       "      <th>Ridge</th>\n",
       "      <th>SVR</th>\n",
       "      <th>KNR</th>\n",
       "      <th>XGBoost</th>\n",
       "      <th>Combined</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>195701</th>\n",
       "      <td>0.004428</td>\n",
       "      <td>0.017212</td>\n",
       "      <td>0.007213</td>\n",
       "      <td>0.006473</td>\n",
       "      <td>0.006473</td>\n",
       "      <td>0.006212</td>\n",
       "      <td>0.008328</td>\n",
       "      <td>-0.020846</td>\n",
       "      <td>0.009036</td>\n",
       "      <td>-0.044783</td>\n",
       "      <td>0.020064</td>\n",
       "      <td>0.011484</td>\n",
       "      <td>0.006473</td>\n",
       "      <td>0.051700</td>\n",
       "      <td>0.032029</td>\n",
       "      <td>0.007727</td>\n",
       "      <td>0.008077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195702</th>\n",
       "      <td>0.005713</td>\n",
       "      <td>0.008221</td>\n",
       "      <td>0.007902</td>\n",
       "      <td>0.006473</td>\n",
       "      <td>0.006473</td>\n",
       "      <td>0.006212</td>\n",
       "      <td>0.010835</td>\n",
       "      <td>0.033707</td>\n",
       "      <td>0.009018</td>\n",
       "      <td>-0.059487</td>\n",
       "      <td>0.016915</td>\n",
       "      <td>0.011484</td>\n",
       "      <td>0.006473</td>\n",
       "      <td>-0.022794</td>\n",
       "      <td>0.011661</td>\n",
       "      <td>-0.004940</td>\n",
       "      <td>0.003367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195703</th>\n",
       "      <td>0.000727</td>\n",
       "      <td>0.013473</td>\n",
       "      <td>0.008082</td>\n",
       "      <td>0.006473</td>\n",
       "      <td>0.006473</td>\n",
       "      <td>0.006212</td>\n",
       "      <td>0.010835</td>\n",
       "      <td>0.006636</td>\n",
       "      <td>0.006358</td>\n",
       "      <td>-0.062820</td>\n",
       "      <td>0.016444</td>\n",
       "      <td>0.011484</td>\n",
       "      <td>0.006473</td>\n",
       "      <td>-0.001442</td>\n",
       "      <td>0.010643</td>\n",
       "      <td>-0.004789</td>\n",
       "      <td>0.002579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195704</th>\n",
       "      <td>-0.007605</td>\n",
       "      <td>0.007329</td>\n",
       "      <td>0.009294</td>\n",
       "      <td>0.006473</td>\n",
       "      <td>0.006473</td>\n",
       "      <td>0.007569</td>\n",
       "      <td>0.011015</td>\n",
       "      <td>-0.056333</td>\n",
       "      <td>-0.003324</td>\n",
       "      <td>-0.049180</td>\n",
       "      <td>0.016485</td>\n",
       "      <td>0.011484</td>\n",
       "      <td>0.006473</td>\n",
       "      <td>-0.030523</td>\n",
       "      <td>-0.002674</td>\n",
       "      <td>-0.005620</td>\n",
       "      <td>-0.004542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195705</th>\n",
       "      <td>-0.002662</td>\n",
       "      <td>0.002282</td>\n",
       "      <td>0.009749</td>\n",
       "      <td>0.006473</td>\n",
       "      <td>0.006473</td>\n",
       "      <td>0.012371</td>\n",
       "      <td>0.011293</td>\n",
       "      <td>0.021646</td>\n",
       "      <td>-0.002817</td>\n",
       "      <td>-0.031841</td>\n",
       "      <td>0.017856</td>\n",
       "      <td>0.011484</td>\n",
       "      <td>0.006473</td>\n",
       "      <td>-0.039166</td>\n",
       "      <td>0.013793</td>\n",
       "      <td>-0.007002</td>\n",
       "      <td>0.002275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             OLS       PLS       PCR     LASSO      ENet      GBRT        RF  \\\n",
       "month                                                                          \n",
       "195701  0.004428  0.017212  0.007213  0.006473  0.006473  0.006212  0.008328   \n",
       "195702  0.005713  0.008221  0.007902  0.006473  0.006473  0.006212  0.010835   \n",
       "195703  0.000727  0.013473  0.008082  0.006473  0.006473  0.006212  0.010835   \n",
       "195704 -0.007605  0.007329  0.009294  0.006473  0.006473  0.007569  0.011015   \n",
       "195705 -0.002662  0.002282  0.009749  0.006473  0.006473  0.012371  0.011293   \n",
       "\n",
       "             NN1       NN2       NN3       NN4       NN5     Ridge       SVR  \\\n",
       "month                                                                          \n",
       "195701 -0.020846  0.009036 -0.044783  0.020064  0.011484  0.006473  0.051700   \n",
       "195702  0.033707  0.009018 -0.059487  0.016915  0.011484  0.006473 -0.022794   \n",
       "195703  0.006636  0.006358 -0.062820  0.016444  0.011484  0.006473 -0.001442   \n",
       "195704 -0.056333 -0.003324 -0.049180  0.016485  0.011484  0.006473 -0.030523   \n",
       "195705  0.021646 -0.002817 -0.031841  0.017856  0.011484  0.006473 -0.039166   \n",
       "\n",
       "             KNR   XGBoost  Combined  \n",
       "month                                 \n",
       "195701  0.032029  0.007727  0.008077  \n",
       "195702  0.011661 -0.004940  0.003367  \n",
       "195703  0.010643 -0.004789  0.002579  \n",
       "195704 -0.002674 -0.005620 -0.004542  \n",
       "195705  0.013793 -0.007002  0.002275  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_ml_pred = pd.DataFrame(np.array([y_pred_OLS_1957, y_pred_PLS_1957, y_pred_PCR_1957, y_pred_LASSO_1957,\n",
    "                                   y_pred_ENet_1957, y_pred_GBRT_1957, y_pred_RF_1957, y_pred_NN1_1957,\n",
    "                                   y_pred_NN2_1957, y_pred_NN3_1957, y_pred_NN4_1957, y_pred_NN5_1957,\n",
    "                                   y_pred_Ridge_1957, y_pred_SVR_1957, y_pred_KNR_1957, y_pred_XGBoost_1957]),\n",
    "                         index=['OLS', 'PLS', 'PCR', 'LASSO', 'ENet', 'GBRT', 'RF', 'NN1',\n",
    "                                'NN2', 'NN3', 'NN4', 'NN5', 'Ridge', 'SVR', 'KNR', 'XGBoost'],\n",
    "                         columns=predictor_df.month[in_out_1957:N]).T\n",
    "y_ml_pred['Combined'] = y_ml_pred.mean(axis=1)\n",
    "y_ml_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8378dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xingfuxu/PycharmProjects/EquityPremiumPredictionML-Jupyter/Perform_PT_test.py:38: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  stat = (p_hat - p_star) / np.sqrt(p_hat_var - p_star_var)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>oos_r_square</th>\n",
       "      <th>MSFE_adjusted</th>\n",
       "      <th>pvalue_MSFE</th>\n",
       "      <th>success_ratio</th>\n",
       "      <th>PT_stat</th>\n",
       "      <th>pvalue_PT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>OLS</th>\n",
       "      <td>-12.679806</td>\n",
       "      <td>0.613661</td>\n",
       "      <td>0.269720</td>\n",
       "      <td>56.062581</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>0.013903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PLS</th>\n",
       "      <td>-4.702669</td>\n",
       "      <td>0.172314</td>\n",
       "      <td>0.431595</td>\n",
       "      <td>55.671447</td>\n",
       "      <td>0.719744</td>\n",
       "      <td>0.235841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCR</th>\n",
       "      <td>0.072784</td>\n",
       "      <td>1.925798</td>\n",
       "      <td>0.027065</td>\n",
       "      <td>59.713168</td>\n",
       "      <td>3.112951</td>\n",
       "      <td>0.000926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LASSO</th>\n",
       "      <td>-0.696281</td>\n",
       "      <td>1.197421</td>\n",
       "      <td>0.115571</td>\n",
       "      <td>58.800522</td>\n",
       "      <td>2.632330</td>\n",
       "      <td>0.004240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENet</th>\n",
       "      <td>-1.772084</td>\n",
       "      <td>0.771034</td>\n",
       "      <td>0.220343</td>\n",
       "      <td>58.930900</td>\n",
       "      <td>2.653842</td>\n",
       "      <td>0.003979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBRT</th>\n",
       "      <td>-22.579738</td>\n",
       "      <td>-0.475949</td>\n",
       "      <td>0.682945</td>\n",
       "      <td>56.584094</td>\n",
       "      <td>-0.867959</td>\n",
       "      <td>0.807292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>-16.507013</td>\n",
       "      <td>0.337619</td>\n",
       "      <td>0.367825</td>\n",
       "      <td>56.192960</td>\n",
       "      <td>-0.965328</td>\n",
       "      <td>0.832810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN1</th>\n",
       "      <td>-26.869047</td>\n",
       "      <td>-1.028946</td>\n",
       "      <td>0.848247</td>\n",
       "      <td>58.409387</td>\n",
       "      <td>1.460584</td>\n",
       "      <td>0.072065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN2</th>\n",
       "      <td>-13.608669</td>\n",
       "      <td>1.334754</td>\n",
       "      <td>0.090978</td>\n",
       "      <td>57.105606</td>\n",
       "      <td>0.634978</td>\n",
       "      <td>0.262721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN3</th>\n",
       "      <td>-20.497497</td>\n",
       "      <td>-0.112818</td>\n",
       "      <td>0.544913</td>\n",
       "      <td>55.932203</td>\n",
       "      <td>0.410294</td>\n",
       "      <td>0.340795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN4</th>\n",
       "      <td>-16.441042</td>\n",
       "      <td>-0.447005</td>\n",
       "      <td>0.672564</td>\n",
       "      <td>55.541069</td>\n",
       "      <td>-0.749125</td>\n",
       "      <td>0.773109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN5</th>\n",
       "      <td>-29.205795</td>\n",
       "      <td>2.736229</td>\n",
       "      <td>0.003107</td>\n",
       "      <td>58.800522</td>\n",
       "      <td>1.985705</td>\n",
       "      <td>0.023533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.306944</td>\n",
       "      <td>1.467498</td>\n",
       "      <td>0.071120</td>\n",
       "      <td>61.538462</td>\n",
       "      <td>3.679306</td>\n",
       "      <td>0.000117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>-61.125864</td>\n",
       "      <td>-0.159734</td>\n",
       "      <td>0.563455</td>\n",
       "      <td>42.894394</td>\n",
       "      <td>-1.531520</td>\n",
       "      <td>0.937179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNR</th>\n",
       "      <td>-18.507781</td>\n",
       "      <td>0.030518</td>\n",
       "      <td>0.487827</td>\n",
       "      <td>55.019557</td>\n",
       "      <td>1.622264</td>\n",
       "      <td>0.052373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>-32.889814</td>\n",
       "      <td>0.759669</td>\n",
       "      <td>0.223726</td>\n",
       "      <td>54.106910</td>\n",
       "      <td>-0.173392</td>\n",
       "      <td>0.568828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Combined</th>\n",
       "      <td>-1.014887</td>\n",
       "      <td>1.028814</td>\n",
       "      <td>0.151784</td>\n",
       "      <td>58.670143</td>\n",
       "      <td>1.768042</td>\n",
       "      <td>0.038527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HA</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.973924</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          oos_r_square  MSFE_adjusted  pvalue_MSFE  success_ratio   PT_stat  \\\n",
       "OLS         -12.679806       0.613661     0.269720      56.062581  2.200000   \n",
       "PLS          -4.702669       0.172314     0.431595      55.671447  0.719744   \n",
       "PCR           0.072784       1.925798     0.027065      59.713168  3.112951   \n",
       "LASSO        -0.696281       1.197421     0.115571      58.800522  2.632330   \n",
       "ENet         -1.772084       0.771034     0.220343      58.930900  2.653842   \n",
       "GBRT        -22.579738      -0.475949     0.682945      56.584094 -0.867959   \n",
       "RF          -16.507013       0.337619     0.367825      56.192960 -0.965328   \n",
       "NN1         -26.869047      -1.028946     0.848247      58.409387  1.460584   \n",
       "NN2         -13.608669       1.334754     0.090978      57.105606  0.634978   \n",
       "NN3         -20.497497      -0.112818     0.544913      55.932203  0.410294   \n",
       "NN4         -16.441042      -0.447005     0.672564      55.541069 -0.749125   \n",
       "NN5         -29.205795       2.736229     0.003107      58.800522  1.985705   \n",
       "Ridge         0.306944       1.467498     0.071120      61.538462  3.679306   \n",
       "SVR         -61.125864      -0.159734     0.563455      42.894394 -1.531520   \n",
       "KNR         -18.507781       0.030518     0.487827      55.019557  1.622264   \n",
       "XGBoost     -32.889814       0.759669     0.223726      54.106910 -0.173392   \n",
       "Combined     -1.014887       1.028814     0.151784      58.670143  1.768042   \n",
       "HA            0.000000            NaN          NaN      59.973924       NaN   \n",
       "\n",
       "          pvalue_PT  \n",
       "OLS        0.013903  \n",
       "PLS        0.235841  \n",
       "PCR        0.000926  \n",
       "LASSO      0.004240  \n",
       "ENet       0.003979  \n",
       "GBRT       0.807292  \n",
       "RF         0.832810  \n",
       "NN1        0.072065  \n",
       "NN2        0.262721  \n",
       "NN3        0.340795  \n",
       "NN4        0.773109  \n",
       "NN5        0.023533  \n",
       "Ridge      0.000117  \n",
       "SVR        0.937179  \n",
       "KNR        0.052373  \n",
       "XGBoost    0.568828  \n",
       "Combined   0.038527  \n",
       "HA              NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Performance compared with HA benchmark\n",
    "\n",
    "def compute_oos_r_square(actual, y_benchmark, y_pred):\n",
    "    MSFE_benchmark = mean_squared_error(y_benchmark, actual)\n",
    "    MSFE_pred = mean_squared_error(y_pred, actual)\n",
    "    return 1 - MSFE_pred / MSFE_benchmark\n",
    "\n",
    "ml_oos_performance = []\n",
    "\n",
    "for col in y_ml_pred.columns:\n",
    "    oos_r_square = compute_oos_r_square(actual_1957, y_pred_HA_1957, y_ml_pred[[col]].to_numpy())\n",
    "    MSFE_adjusted, pvalue_MSFE = CW_test(actual_1957, y_pred_HA_1957, y_ml_pred[[col]].to_numpy())\n",
    "    success_ratio, PT_stat, pvalue_PT = PT_test(actual_1957, y_ml_pred[[col]].to_numpy())\n",
    "    ml_oos_performance.append([oos_r_square * 100, MSFE_adjusted, pvalue_MSFE, success_ratio * 100, PT_stat, pvalue_PT])\n",
    "\n",
    "\n",
    "ml_oos_performance_df = pd.DataFrame(np.array(ml_oos_performance),\n",
    "                                     index=y_ml_pred.columns,\n",
    "                                     columns=['oos_r_square', 'MSFE_adjusted', 'pvalue_MSFE',\n",
    "                                              'success_ratio', 'PT_stat', 'pvalue_PT'])\n",
    "# success ratio of HA\n",
    "success_ratio_HA_1957, PT_HA_1957, p2_HA_1957 = PT_test(actual_1957, y_pred_HA_1957)\n",
    "ml_oos_performance_df.loc['HA'] = [0, np.nan, np.nan, success_ratio_HA_1957 * 100, PT_HA_1957, p2_HA_1957]\n",
    "ml_oos_performance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f97638c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "with pd.ExcelWriter(\"ml_equity_premium_results.xlsx\", engine='openpyxl', mode='a') as writer:\n",
    "    ml_oos_performance_df.to_excel(writer, sheet_name='using_robust_scoring_function')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
