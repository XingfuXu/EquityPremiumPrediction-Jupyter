{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2df2b249",
   "metadata": {},
   "source": [
    "### Machine Learning Out-of-sample Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f822b3b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/xingfuxu/PycharmProjects/EquityPremiumPredictionML-Jupyter'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "# os.chdir(path)    # or you can set your working dir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3c1c50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your working dir should include \"NN_models.py\"\n",
    "from NN_models import Net1, Net2, Net3, Net4, Net5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e772b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import torch\n",
    "from skorch import NeuralNetRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e2654b",
   "metadata": {},
   "source": [
    "#### Generate macro variables and technical indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d37299e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>log_equity_premium</th>\n",
       "      <th>equity_premium</th>\n",
       "      <th>DP</th>\n",
       "      <th>DY</th>\n",
       "      <th>EP</th>\n",
       "      <th>SVAR</th>\n",
       "      <th>BM</th>\n",
       "      <th>NTIS</th>\n",
       "      <th>TBL</th>\n",
       "      <th>...</th>\n",
       "      <th>MA_2_9</th>\n",
       "      <th>MA_2_12</th>\n",
       "      <th>MA_3_9</th>\n",
       "      <th>MA_3_12</th>\n",
       "      <th>MOM_1</th>\n",
       "      <th>MOM_2</th>\n",
       "      <th>MOM_3</th>\n",
       "      <th>MOM_6</th>\n",
       "      <th>MOM_9</th>\n",
       "      <th>MOM_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>192701.0</td>\n",
       "      <td>-0.005710</td>\n",
       "      <td>-0.00571</td>\n",
       "      <td>-2.942374</td>\n",
       "      <td>-2.963349</td>\n",
       "      <td>-2.374773</td>\n",
       "      <td>0.00047</td>\n",
       "      <td>0.44371</td>\n",
       "      <td>0.05082</td>\n",
       "      <td>3.23</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>192702.0</td>\n",
       "      <td>0.042017</td>\n",
       "      <td>0.04302</td>\n",
       "      <td>-2.979535</td>\n",
       "      <td>-2.932946</td>\n",
       "      <td>-2.430353</td>\n",
       "      <td>0.00029</td>\n",
       "      <td>0.42850</td>\n",
       "      <td>0.05167</td>\n",
       "      <td>3.29</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>192703.0</td>\n",
       "      <td>0.004697</td>\n",
       "      <td>0.00472</td>\n",
       "      <td>-2.976535</td>\n",
       "      <td>-2.970053</td>\n",
       "      <td>-2.445079</td>\n",
       "      <td>0.00092</td>\n",
       "      <td>0.46977</td>\n",
       "      <td>0.04636</td>\n",
       "      <td>3.20</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>192704.0</td>\n",
       "      <td>0.009940</td>\n",
       "      <td>0.01002</td>\n",
       "      <td>-2.984225</td>\n",
       "      <td>-2.967143</td>\n",
       "      <td>-2.471309</td>\n",
       "      <td>0.00060</td>\n",
       "      <td>0.45675</td>\n",
       "      <td>0.05051</td>\n",
       "      <td>3.39</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>192705.0</td>\n",
       "      <td>0.057987</td>\n",
       "      <td>0.05985</td>\n",
       "      <td>-3.025963</td>\n",
       "      <td>-2.975058</td>\n",
       "      <td>-2.531446</td>\n",
       "      <td>0.00039</td>\n",
       "      <td>0.43478</td>\n",
       "      <td>0.05528</td>\n",
       "      <td>3.33</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123</th>\n",
       "      <td>202008.0</td>\n",
       "      <td>0.069491</td>\n",
       "      <td>0.07197</td>\n",
       "      <td>-4.080892</td>\n",
       "      <td>-4.013173</td>\n",
       "      <td>-3.569975</td>\n",
       "      <td>0.00074</td>\n",
       "      <td>0.23597</td>\n",
       "      <td>-0.00850</td>\n",
       "      <td>0.10</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1124</th>\n",
       "      <td>202009.0</td>\n",
       "      <td>-0.038997</td>\n",
       "      <td>-0.03825</td>\n",
       "      <td>-4.045576</td>\n",
       "      <td>-4.085595</td>\n",
       "      <td>-3.533379</td>\n",
       "      <td>0.00491</td>\n",
       "      <td>0.24148</td>\n",
       "      <td>-0.00570</td>\n",
       "      <td>0.11</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>202010.0</td>\n",
       "      <td>-0.026865</td>\n",
       "      <td>-0.02651</td>\n",
       "      <td>-4.020768</td>\n",
       "      <td>-4.048824</td>\n",
       "      <td>-3.519300</td>\n",
       "      <td>0.00366</td>\n",
       "      <td>0.25315</td>\n",
       "      <td>-0.00190</td>\n",
       "      <td>0.10</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>202011.0</td>\n",
       "      <td>0.103719</td>\n",
       "      <td>0.10930</td>\n",
       "      <td>-4.126173</td>\n",
       "      <td>-4.024026</td>\n",
       "      <td>-3.635623</td>\n",
       "      <td>0.00249</td>\n",
       "      <td>0.22635</td>\n",
       "      <td>-0.00526</td>\n",
       "      <td>0.09</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1127</th>\n",
       "      <td>202012.0</td>\n",
       "      <td>0.040629</td>\n",
       "      <td>0.04147</td>\n",
       "      <td>-4.165890</td>\n",
       "      <td>-4.129441</td>\n",
       "      <td>-3.686452</td>\n",
       "      <td>0.00068</td>\n",
       "      <td>0.21919</td>\n",
       "      <td>-0.00009</td>\n",
       "      <td>0.09</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1128 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         month  log_equity_premium  equity_premium        DP        DY  \\\n",
       "0     192701.0           -0.005710        -0.00571 -2.942374 -2.963349   \n",
       "1     192702.0            0.042017         0.04302 -2.979535 -2.932946   \n",
       "2     192703.0            0.004697         0.00472 -2.976535 -2.970053   \n",
       "3     192704.0            0.009940         0.01002 -2.984225 -2.967143   \n",
       "4     192705.0            0.057987         0.05985 -3.025963 -2.975058   \n",
       "...        ...                 ...             ...       ...       ...   \n",
       "1123  202008.0            0.069491         0.07197 -4.080892 -4.013173   \n",
       "1124  202009.0           -0.038997        -0.03825 -4.045576 -4.085595   \n",
       "1125  202010.0           -0.026865        -0.02651 -4.020768 -4.048824   \n",
       "1126  202011.0            0.103719         0.10930 -4.126173 -4.024026   \n",
       "1127  202012.0            0.040629         0.04147 -4.165890 -4.129441   \n",
       "\n",
       "            EP     SVAR       BM     NTIS   TBL  ...  MA_2_9  MA_2_12  MA_3_9  \\\n",
       "0    -2.374773  0.00047  0.44371  0.05082  3.23  ...     1.0      1.0     1.0   \n",
       "1    -2.430353  0.00029  0.42850  0.05167  3.29  ...     1.0      1.0     1.0   \n",
       "2    -2.445079  0.00092  0.46977  0.04636  3.20  ...     1.0      1.0     1.0   \n",
       "3    -2.471309  0.00060  0.45675  0.05051  3.39  ...     1.0      1.0     1.0   \n",
       "4    -2.531446  0.00039  0.43478  0.05528  3.33  ...     1.0      1.0     1.0   \n",
       "...        ...      ...      ...      ...   ...  ...     ...      ...     ...   \n",
       "1123 -3.569975  0.00074  0.23597 -0.00850  0.10  ...     1.0      1.0     1.0   \n",
       "1124 -3.533379  0.00491  0.24148 -0.00570  0.11  ...     1.0      1.0     1.0   \n",
       "1125 -3.519300  0.00366  0.25315 -0.00190  0.10  ...     1.0      1.0     1.0   \n",
       "1126 -3.635623  0.00249  0.22635 -0.00526  0.09  ...     1.0      1.0     1.0   \n",
       "1127 -3.686452  0.00068  0.21919 -0.00009  0.09  ...     1.0      1.0     1.0   \n",
       "\n",
       "      MA_3_12  MOM_1  MOM_2  MOM_3  MOM_6  MOM_9  MOM_12  \n",
       "0         1.0    0.0    0.0    1.0    1.0    1.0     1.0  \n",
       "1         1.0    1.0    1.0    1.0    1.0    1.0     1.0  \n",
       "2         1.0    1.0    1.0    1.0    1.0    1.0     1.0  \n",
       "3         1.0    1.0    1.0    1.0    1.0    1.0     1.0  \n",
       "4         1.0    1.0    1.0    1.0    1.0    1.0     1.0  \n",
       "...       ...    ...    ...    ...    ...    ...     ...  \n",
       "1123      1.0    1.0    1.0    1.0    1.0    1.0     1.0  \n",
       "1124      1.0    0.0    1.0    1.0    1.0    1.0     1.0  \n",
       "1125      1.0    0.0    0.0    0.0    1.0    1.0     1.0  \n",
       "1126      1.0    1.0    1.0    1.0    1.0    1.0     1.0  \n",
       "1127      1.0    1.0    1.0    1.0    1.0    1.0     1.0  \n",
       "\n",
       "[1128 rows x 27 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor_raw = pd.read_excel(open('ml_equity_premium_data.xlsx', 'rb'), sheet_name='PredictorData1926-2020')\n",
    "# predictor_raw.tail()\n",
    "# predictor_raw.columns\n",
    "\n",
    "\n",
    "## Generating equity risk premium, 1927:01-2020:12\n",
    "n_rows = predictor_raw.shape[0]\n",
    "market_return = predictor_raw['CRSP_SPvw'][1:].values\n",
    "risk_free_lag = predictor_raw['Rfree'][0:(n_rows - 1)].values\n",
    "log_equity_premium = np.log(1 + market_return) - np.log(1 + risk_free_lag)\n",
    "equity_premium = market_return - risk_free_lag\n",
    "\n",
    "\n",
    "### Generating 12 macroeconomic variables, 1927:01-2020:12\n",
    "# Notes: we exclude the log dividend-earnings ratio (DE) and the long-term yield (LTY).\n",
    "\n",
    "# (1) Dividend-price ratio (log), DP\n",
    "D12 = predictor_raw['D12'][1:].values\n",
    "SP500 = predictor_raw['Index'][1:].values\n",
    "DP = np.log(D12) - np.log(SP500)\n",
    "\n",
    "# (2) Dividend yield (log), DY\n",
    "SP500_lag = predictor_raw['Index'][0:(n_rows - 1)].values\n",
    "DY = np.log(D12) - np.log(SP500_lag)\n",
    "\n",
    "# (3) Earnings-price ratio (log), EP\n",
    "E12 = predictor_raw['E12'][1:].values\n",
    "EP = np.log(E12) - np.log(SP500)\n",
    "\n",
    "# (4) stock variance, SVAR\n",
    "SVAR = predictor_raw['svar'][1:].values\n",
    "\n",
    "# (5) Book-to-market ratio, BM\n",
    "BM = predictor_raw['b/m'][1:].values\n",
    "\n",
    "# (6) Net equity expansion, NTIS\n",
    "NTIS = predictor_raw['ntis'][1:].values\n",
    "\n",
    "# (7) Treasury bill rate (annual %), TBL\n",
    "TBL = predictor_raw['tbl'][1:].values\n",
    "TBL = 100 * TBL\n",
    "\n",
    "# (8) Long-term return (%), LTR\n",
    "LTR = predictor_raw['ltr'][1:].values\n",
    "LTR = 100 * LTR\n",
    "\n",
    "# (9) Term spread (annual %), TMS\n",
    "LTY = predictor_raw['lty'][1:].values\n",
    "LTY = 100 * LTY\n",
    "TMS = LTY - TBL\n",
    "\n",
    "# (10) Default yield spread, DFY\n",
    "AAA = predictor_raw['AAA'][1:].values\n",
    "BAA = predictor_raw['BAA'][1:].values\n",
    "DFY = 100 * (BAA - AAA)\n",
    "\n",
    "# (11) Default return spread, DFR\n",
    "CORPR = predictor_raw['corpr'][1:].values\n",
    "DFR = 100 * CORPR - LTR\n",
    "\n",
    "# (12) Inflation (%, lagged), INFL\n",
    "INFL = predictor_raw['infl'][0:(n_rows - 1)].values\n",
    "INFL = 100 * INFL\n",
    "\n",
    "## Collect 12 macroeconomic variables\n",
    "macro = np.concatenate([DP.reshape(-1, 1), DY.reshape(-1, 1), EP.reshape(-1, 1),\n",
    "                        SVAR.reshape(-1, 1), BM.reshape(-1, 1), NTIS.reshape(-1, 1),\n",
    "                        TBL.reshape(-1, 1), LTR.reshape(-1, 1), TMS.reshape(-1, 1),\n",
    "                        DFY.reshape(-1, 1), DFR.reshape(-1, 1), INFL.reshape(-1, 1)], axis=1)\n",
    "# macro.shape\n",
    "#\n",
    "\n",
    "\n",
    "## Collect 12 technical indicators\n",
    "technical = predictor_raw[['MA_1_9', 'MA_1_12', 'MA_2_9', 'MA_2_12', 'MA_3_9',\n",
    "                           'MA_3_12', 'MOM_1', 'MOM_2', 'MOM_3', 'MOM_6', 'MOM_9',\n",
    "                           'MOM_12']].values[1:]\n",
    "# technical.shape\n",
    "\n",
    "#\n",
    "predictor_matrix = np.concatenate([predictor_raw['yyyymm'][1:].values.reshape(-1, 1), log_equity_premium.reshape(-1, 1),\n",
    "                     equity_premium.reshape(-1, 1), macro, technical], axis=1)\n",
    "\n",
    "#\n",
    "result_predictor = pd.DataFrame(predictor_matrix,\n",
    "                                columns=['month', 'log_equity_premium', 'equity_premium', 'DP', 'DY', 'EP', 'SVAR',\n",
    "                                         'BM', 'NTIS', 'TBL', 'LTR', 'TMS', 'DFY', 'DFR', 'INFL','MA_1_9', 'MA_1_12',\n",
    "                                         'MA_2_9', 'MA_2_12', 'MA_3_9', 'MA_3_12', 'MOM_1', 'MOM_2', 'MOM_3', 'MOM_6',\n",
    "                                         'MOM_9', 'MOM_12'])\n",
    "result_predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1375a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "import openpyxl\n",
    "with pd.ExcelWriter(\"ml_equity_premium_data.xlsx\", engine='openpyxl', mode='a') as writer:\n",
    "    result_predictor.to_excel(writer, sheet_name='result_predictor', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50dbea16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>log_equity_premium</th>\n",
       "      <th>equity_premium</th>\n",
       "      <th>DP</th>\n",
       "      <th>DY</th>\n",
       "      <th>EP</th>\n",
       "      <th>SVAR</th>\n",
       "      <th>BM</th>\n",
       "      <th>NTIS</th>\n",
       "      <th>TBL</th>\n",
       "      <th>...</th>\n",
       "      <th>MA_2_9</th>\n",
       "      <th>MA_2_12</th>\n",
       "      <th>MA_3_9</th>\n",
       "      <th>MA_3_12</th>\n",
       "      <th>MOM_1</th>\n",
       "      <th>MOM_2</th>\n",
       "      <th>MOM_3</th>\n",
       "      <th>MOM_6</th>\n",
       "      <th>MOM_9</th>\n",
       "      <th>MOM_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>192701</td>\n",
       "      <td>-0.005710</td>\n",
       "      <td>-0.00571</td>\n",
       "      <td>-2.942374</td>\n",
       "      <td>-2.963349</td>\n",
       "      <td>-2.374773</td>\n",
       "      <td>0.00047</td>\n",
       "      <td>0.44371</td>\n",
       "      <td>0.05082</td>\n",
       "      <td>3.23</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>192702</td>\n",
       "      <td>0.042017</td>\n",
       "      <td>0.04302</td>\n",
       "      <td>-2.979535</td>\n",
       "      <td>-2.932946</td>\n",
       "      <td>-2.430353</td>\n",
       "      <td>0.00029</td>\n",
       "      <td>0.42850</td>\n",
       "      <td>0.05167</td>\n",
       "      <td>3.29</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>192703</td>\n",
       "      <td>0.004697</td>\n",
       "      <td>0.00472</td>\n",
       "      <td>-2.976535</td>\n",
       "      <td>-2.970053</td>\n",
       "      <td>-2.445079</td>\n",
       "      <td>0.00092</td>\n",
       "      <td>0.46977</td>\n",
       "      <td>0.04636</td>\n",
       "      <td>3.20</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>192704</td>\n",
       "      <td>0.009940</td>\n",
       "      <td>0.01002</td>\n",
       "      <td>-2.984225</td>\n",
       "      <td>-2.967143</td>\n",
       "      <td>-2.471309</td>\n",
       "      <td>0.00060</td>\n",
       "      <td>0.45675</td>\n",
       "      <td>0.05051</td>\n",
       "      <td>3.39</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>192705</td>\n",
       "      <td>0.057987</td>\n",
       "      <td>0.05985</td>\n",
       "      <td>-3.025963</td>\n",
       "      <td>-2.975058</td>\n",
       "      <td>-2.531446</td>\n",
       "      <td>0.00039</td>\n",
       "      <td>0.43478</td>\n",
       "      <td>0.05528</td>\n",
       "      <td>3.33</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123</th>\n",
       "      <td>202008</td>\n",
       "      <td>0.069491</td>\n",
       "      <td>0.07197</td>\n",
       "      <td>-4.080892</td>\n",
       "      <td>-4.013173</td>\n",
       "      <td>-3.569975</td>\n",
       "      <td>0.00074</td>\n",
       "      <td>0.23597</td>\n",
       "      <td>-0.00850</td>\n",
       "      <td>0.10</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1124</th>\n",
       "      <td>202009</td>\n",
       "      <td>-0.038997</td>\n",
       "      <td>-0.03825</td>\n",
       "      <td>-4.045576</td>\n",
       "      <td>-4.085595</td>\n",
       "      <td>-3.533379</td>\n",
       "      <td>0.00491</td>\n",
       "      <td>0.24148</td>\n",
       "      <td>-0.00570</td>\n",
       "      <td>0.11</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>202010</td>\n",
       "      <td>-0.026865</td>\n",
       "      <td>-0.02651</td>\n",
       "      <td>-4.020768</td>\n",
       "      <td>-4.048824</td>\n",
       "      <td>-3.519300</td>\n",
       "      <td>0.00366</td>\n",
       "      <td>0.25315</td>\n",
       "      <td>-0.00190</td>\n",
       "      <td>0.10</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>202011</td>\n",
       "      <td>0.103719</td>\n",
       "      <td>0.10930</td>\n",
       "      <td>-4.126173</td>\n",
       "      <td>-4.024026</td>\n",
       "      <td>-3.635623</td>\n",
       "      <td>0.00249</td>\n",
       "      <td>0.22635</td>\n",
       "      <td>-0.00526</td>\n",
       "      <td>0.09</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1127</th>\n",
       "      <td>202012</td>\n",
       "      <td>0.040629</td>\n",
       "      <td>0.04147</td>\n",
       "      <td>-4.165890</td>\n",
       "      <td>-4.129441</td>\n",
       "      <td>-3.686452</td>\n",
       "      <td>0.00068</td>\n",
       "      <td>0.21919</td>\n",
       "      <td>-0.00009</td>\n",
       "      <td>0.09</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1128 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       month  log_equity_premium  equity_premium        DP        DY  \\\n",
       "0     192701           -0.005710        -0.00571 -2.942374 -2.963349   \n",
       "1     192702            0.042017         0.04302 -2.979535 -2.932946   \n",
       "2     192703            0.004697         0.00472 -2.976535 -2.970053   \n",
       "3     192704            0.009940         0.01002 -2.984225 -2.967143   \n",
       "4     192705            0.057987         0.05985 -3.025963 -2.975058   \n",
       "...      ...                 ...             ...       ...       ...   \n",
       "1123  202008            0.069491         0.07197 -4.080892 -4.013173   \n",
       "1124  202009           -0.038997        -0.03825 -4.045576 -4.085595   \n",
       "1125  202010           -0.026865        -0.02651 -4.020768 -4.048824   \n",
       "1126  202011            0.103719         0.10930 -4.126173 -4.024026   \n",
       "1127  202012            0.040629         0.04147 -4.165890 -4.129441   \n",
       "\n",
       "            EP     SVAR       BM     NTIS   TBL  ...  MA_2_9  MA_2_12  MA_3_9  \\\n",
       "0    -2.374773  0.00047  0.44371  0.05082  3.23  ...       1        1       1   \n",
       "1    -2.430353  0.00029  0.42850  0.05167  3.29  ...       1        1       1   \n",
       "2    -2.445079  0.00092  0.46977  0.04636  3.20  ...       1        1       1   \n",
       "3    -2.471309  0.00060  0.45675  0.05051  3.39  ...       1        1       1   \n",
       "4    -2.531446  0.00039  0.43478  0.05528  3.33  ...       1        1       1   \n",
       "...        ...      ...      ...      ...   ...  ...     ...      ...     ...   \n",
       "1123 -3.569975  0.00074  0.23597 -0.00850  0.10  ...       1        1       1   \n",
       "1124 -3.533379  0.00491  0.24148 -0.00570  0.11  ...       1        1       1   \n",
       "1125 -3.519300  0.00366  0.25315 -0.00190  0.10  ...       1        1       1   \n",
       "1126 -3.635623  0.00249  0.22635 -0.00526  0.09  ...       1        1       1   \n",
       "1127 -3.686452  0.00068  0.21919 -0.00009  0.09  ...       1        1       1   \n",
       "\n",
       "      MA_3_12  MOM_1  MOM_2  MOM_3  MOM_6  MOM_9  MOM_12  \n",
       "0           1      0      0      1      1      1       1  \n",
       "1           1      1      1      1      1      1       1  \n",
       "2           1      1      1      1      1      1       1  \n",
       "3           1      1      1      1      1      1       1  \n",
       "4           1      1      1      1      1      1       1  \n",
       "...       ...    ...    ...    ...    ...    ...     ...  \n",
       "1123        1      1      1      1      1      1       1  \n",
       "1124        1      0      1      1      1      1       1  \n",
       "1125        1      0      0      0      1      1       1  \n",
       "1126        1      1      1      1      1      1       1  \n",
       "1127        1      1      1      1      1      1       1  \n",
       "\n",
       "[1128 rows x 27 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set seed\n",
    "np.random.seed(12)\n",
    "torch.manual_seed(12)\n",
    "\n",
    "# read data\n",
    "predictor_df = pd.read_excel(open('ml_equity_premium_data.xlsx', 'rb'), sheet_name='result_predictor')\n",
    "predictor_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5218722b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove irrelavent columns\n",
    "predictor0 = predictor_df.drop(['month', 'equity_premium'], axis=1)\n",
    "# get all the predictors and set the log equity premium 1-month ahead\n",
    "predictor = np.concatenate([predictor0['log_equity_premium'][1:].values.reshape(-1, 1),\n",
    "                            predictor0.iloc[0:(predictor0.shape[0] - 1), 1:]], axis=1)\n",
    "\n",
    "# number of rows\n",
    "N = predictor.shape[0]\n",
    "\n",
    "# number of all columns, including the log equity premium\n",
    "n_cols = predictor.shape[1]\n",
    "\n",
    "# Actual one-month ahead log equity premium\n",
    "actual = predictor[:, [0]]\n",
    "\n",
    "# Historical average forecasting as benchmark\n",
    "y_pred_HA = predictor0['log_equity_premium'].values[0:(predictor0.shape[0] - 1), ].cumsum() / np.arange(1, N + 1)\n",
    "y_pred_HA = y_pred_HA.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4187e650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the training data to full sample\n",
    "X_train_all = predictor[:, 1:n_cols]\n",
    "y_train_all = predictor[:, 0]\n",
    "# set 15% of all the train data as validation set\n",
    "X_train = X_train_all[0:int(len(X_train_all) * 0.85), :]\n",
    "X_validation = X_train_all[int(len(X_train_all) * 0.85):, :]\n",
    "y_train = y_train_all[0:int(len(X_train_all) * 0.85)]\n",
    "y_validation = y_train_all[int(len(X_train_all) * 0.85):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d6c5a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting OLS ...\n",
      "Starting PLS ...\n",
      "Starting PCR ...\n",
      "Starting LASSO...\n",
      "Starting ENet ...\n",
      "Starting GBRT ...\n",
      "Starting RF ...\n",
      "Starting Neural Network Models ...\n",
      "Starting Ridge ...\n",
      "Starting SVR ...\n",
      "Starting KNR ...\n",
      "Starting XGBoost ...\n"
     ]
    }
   ],
   "source": [
    "# OLS\n",
    "print(\"Starting OLS ...\")\n",
    "OLS = LinearRegression()\n",
    "OLS.fit(X_train_all, y_train_all)\n",
    "y_in_pred_OLS = OLS.predict(X_train_all).reshape(-1, 1)\n",
    "\n",
    "# PLS\n",
    "print(\"Starting PLS ...\")\n",
    "PLS_param = {'n_components': [1, 2, 3, 4, 5, 6, 7, 8]}\n",
    "PLS_result = {}\n",
    "for param in ParameterGrid(PLS_param):\n",
    "    PLS = PLSRegression(**param)\n",
    "    PLS.fit(X_train, y_train)\n",
    "    mse = mean_squared_error(PLS.predict(X_validation), y_validation)\n",
    "    PLS_result[str(param)] = mse\n",
    "\n",
    "PLS_best_param = eval(min(PLS_result, key=PLS_result.get))\n",
    "PLS_model = PLSRegression(**PLS_best_param)\n",
    "PLS_model.fit(X_train_all, y_train_all)\n",
    "y_in_pred_PLS = PLS_model.predict(X_train_all).reshape(-1, 1)\n",
    "\n",
    "# PCR\n",
    "print(\"Starting PCR ...\")\n",
    "PCR_param = {'n_components': [1, 2, 3, 4, 5, 6, 7, 8]}\n",
    "PCR_result = {}\n",
    "for param in ParameterGrid(PCR_param):\n",
    "    pca = PCA(**param)\n",
    "    pca.fit(X_train)\n",
    "    comps = pca.transform(X_train)\n",
    "    forecast = LinearRegression()\n",
    "    forecast.fit(comps, y_train)\n",
    "    mse = mean_squared_error(forecast.predict(pca.transform(X_validation)), y_validation)\n",
    "    PCR_result[str(param)] = mse\n",
    "#\n",
    "PCR_best_param = eval(min(PCR_result, key=PCR_result.get))\n",
    "#\n",
    "PCR_model = PCA(**PCR_best_param)\n",
    "PCR_model.fit(X_train_all)\n",
    "PCR_comps = PCR_model.transform(X_train_all)\n",
    "PCR_forecast = LinearRegression()\n",
    "PCR_forecast.fit(PCR_comps, y_train_all)\n",
    "y_in_pred_PCR = PCR_forecast.predict(PCR_model.transform(X_train_all)).reshape(-1, 1)\n",
    "\n",
    "# LASSO\n",
    "print(\"Starting LASSO...\")\n",
    "LASSO_param = {'alpha': list(10 ** np.arange(-4, 1 + 0.001, 0.2))}\n",
    "LASSO_result = {}\n",
    "for param in ParameterGrid(LASSO_param):\n",
    "    LASSO = Lasso(**param)\n",
    "    LASSO.fit(X_train, y_train)\n",
    "    mse = mean_squared_error(LASSO.predict(X_validation), y_validation)\n",
    "    LASSO_result[str(param)] = mse\n",
    "#\n",
    "LASSO_best_param = eval(min(LASSO_result, key=LASSO_result.get))\n",
    "#\n",
    "LASSO_model = Lasso(**LASSO_best_param)\n",
    "LASSO_model.fit(X_train_all, y_train_all)\n",
    "y_in_pred_LASSO = LASSO_model.predict(X_train_all).reshape(-1, 1)\n",
    "\n",
    "# ENet\n",
    "print(\"Starting ENet ...\")\n",
    "ENet_param = {'alpha': list(10 ** np.arange(-4, 1 + 0.001, 0.2)),\n",
    "              'l1_ratio': list(np.arange(0.2, 1, 0.3))}\n",
    "ENet_result = {}\n",
    "for param in ParameterGrid(ENet_param):\n",
    "    ENet = ElasticNet(**param)\n",
    "    ENet.fit(X_train, y_train)\n",
    "    mse = mean_squared_error(ENet.predict(X_validation), y_validation)\n",
    "    ENet_result[str(param)] = mse\n",
    "\n",
    "ENet_best_param = eval(min(ENet_result, key=ENet_result.get))\n",
    "ENet_model = ElasticNet(**ENet_best_param)\n",
    "ENet_model.fit(X_train_all, y_train_all)\n",
    "y_in_pred_ENet = ENet_model.predict(X_train_all).reshape(-1, 1)\n",
    "\n",
    "# GBRT\n",
    "print(\"Starting GBRT ...\")\n",
    "GBRT_param = {'n_estimators': [10, 50, 100, 150, 200],\n",
    "              'max_depth': [2, 3, 4],\n",
    "              'min_samples_leaf': [1, 3, 5]}\n",
    "GBRT_result = {}\n",
    "for param in ParameterGrid(GBRT_param):\n",
    "    GBRT = GradientBoostingRegressor(**param)\n",
    "    GBRT.fit(X_train, y_train)\n",
    "    mse = mean_squared_error(GBRT.predict(X_validation), y_validation)\n",
    "    GBRT_result[str(param)] = mse\n",
    "\n",
    "GBRT_best_param = eval(min(GBRT_result, key=GBRT_result.get))\n",
    "GBRT_model = GradientBoostingRegressor(**GBRT_best_param)\n",
    "GBRT_model.fit(X_train_all, y_train_all)\n",
    "y_in_pred_GBRT = GBRT_model.predict(X_train_all).reshape(-1, 1)\n",
    "\n",
    "# RF\n",
    "print(\"Starting RF ...\")\n",
    "RF_param = {'n_estimators': [10, 50, 100, 150, 200],\n",
    "            'max_depth': [2, 3, 4],\n",
    "            'min_samples_leaf': [1, 3, 5]}\n",
    "RF_result = {}\n",
    "for param in ParameterGrid(RF_param):\n",
    "    RF = RandomForestRegressor(**param)\n",
    "    RF.fit(X_train, y_train)\n",
    "    mse = mean_squared_error(RF.predict(X_validation), y_validation)\n",
    "    RF_result[str(param)] = mse\n",
    "\n",
    "RF_best_param = eval(min(RF_result, key=RF_result.get))\n",
    "RF_model = RandomForestRegressor(**RF_best_param)\n",
    "RF_model.fit(X_train_all, y_train_all)\n",
    "y_in_pred_RF = RF_model.predict(X_train_all).reshape(-1, 1)\n",
    "\n",
    "# Neural Network Models: NN1~NN5\n",
    "print(\"Starting Neural Network Models ...\")\n",
    "X_train_all_tensor = torch.tensor(X_train_all, dtype=torch.float)\n",
    "y_train_all_tensor = torch.tensor(y_train_all.reshape(-1, 1), dtype=torch.float)\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float)\n",
    "y_train_tensor = torch.tensor(y_train.reshape(-1, 1), dtype=torch.float)\n",
    "X_validation_tensor = torch.tensor(X_validation, dtype=torch.float)\n",
    "y_validation_tensor = torch.tensor(y_validation.reshape(-1, 1), dtype=torch.float)\n",
    "\n",
    "# NN1\n",
    "NN1_result = {}\n",
    "NN1_architecture = {\"module__n_feature\": X_train_tensor.shape[1],  # n_feature should be the number of predictors\n",
    "                    \"module__n_hidden1\": 32,\n",
    "                    \"module__n_output\": 1}\n",
    "NN1_param = {'module__dropout': [0.2, 0.4, 0.6, 0.8],\n",
    "            'lr': [0.001, 0.01],\n",
    "            'optimizer__weight_decay': [0.1, 0.01, 0.001]}\n",
    "for param in ParameterGrid(NN1_param):\n",
    "    NN1 = NeuralNetRegressor(Net1, verbose=0, max_epochs=200,\n",
    "                             optimizer=torch.optim.SGD,\n",
    "                             **NN1_architecture, **param)\n",
    "    NN1.fit(X_train_tensor, y_train_tensor)\n",
    "    mse = mean_squared_error(NN1.predict(X_validation_tensor), y_validation)\n",
    "    NN1_result[str(param)] = mse\n",
    "\n",
    "#\n",
    "NN1_best_param = eval(min(NN1_result, key=NN1_result.get))\n",
    "NN1_model = NeuralNetRegressor(Net1, verbose=0, max_epochs=200, optimizer=torch.optim.SGD,\n",
    "                               **NN1_architecture, **NN1_best_param)\n",
    "NN1_model.fit(X_train_all_tensor, y_train_all_tensor)\n",
    "y_in_pred_NN1 = NN1_model.predict(torch.tensor(X_train_all, dtype=torch.float)).reshape(-1, 1)\n",
    "\n",
    "\n",
    "# NN2\n",
    "NN2_result = {}\n",
    "NN2_architecture = {\"module__n_feature\": X_train_tensor.shape[1],\n",
    "                    \"module__n_hidden1\": 32, \"module__n_hidden2\": 16,\n",
    "                    \"module__n_output\": 1}\n",
    "NN2_param = {'module__dropout': [0.2, 0.4, 0.6, 0.8],\n",
    "            'lr': [0.001, 0.01],\n",
    "            'optimizer__weight_decay': [0.1, 0.01, 0.001]}\n",
    "for param in ParameterGrid(NN2_param):\n",
    "    NN2 = NeuralNetRegressor(Net2, verbose=0, max_epochs=200,\n",
    "                             optimizer=torch.optim.SGD,\n",
    "                             **NN2_architecture, **param)\n",
    "    NN2.fit(X_train_tensor, y_train_tensor)\n",
    "    mse = mean_squared_error(NN2.predict(X_validation_tensor), y_validation)\n",
    "    NN2_result[str(param)] = mse\n",
    "\n",
    "#\n",
    "NN2_best_param = eval(min(NN2_result, key=NN2_result.get))\n",
    "NN2_model = NeuralNetRegressor(Net2, verbose=0, max_epochs=200, optimizer=torch.optim.SGD,\n",
    "                               **NN2_architecture, **NN2_best_param)\n",
    "NN2_model.fit(X_train_all_tensor, y_train_all_tensor)\n",
    "y_in_pred_NN2 = NN2_model.predict(torch.tensor(X_train_all, dtype=torch.float)).reshape(-1, 1)\n",
    "#\n",
    "\n",
    "# NN3\n",
    "NN3_result = {}\n",
    "NN3_architecture = {\"module__n_feature\": X_train_tensor.shape[1],\n",
    "                    # n_feature should be the number of predictors\n",
    "                    \"module__n_hidden1\": 32, \"module__n_hidden2\": 16,\n",
    "                    \"module__n_hidden3\": 8,\n",
    "                    \"module__n_output\": 1}\n",
    "NN3_param = {'module__dropout': [0.2, 0.4, 0.6, 0.8],\n",
    "             'lr': [0.001, 0.01],\n",
    "             'optimizer__weight_decay': [0.1, 0.01, 0.001]}\n",
    "for param in ParameterGrid(NN3_param):\n",
    "    NN3 = NeuralNetRegressor(Net3, verbose=0, max_epochs=200,\n",
    "                             optimizer=torch.optim.SGD,\n",
    "                             **NN3_architecture, **param)\n",
    "    NN3.fit(X_train_tensor, y_train_tensor)\n",
    "    mse = mean_squared_error(NN3.predict(X_validation_tensor), y_validation)\n",
    "    NN3_result[str(param)] = mse\n",
    "\n",
    "#\n",
    "NN3_best_param = eval(min(NN3_result, key=NN3_result.get))\n",
    "NN3_model = NeuralNetRegressor(Net3, verbose=0, max_epochs=200, optimizer=torch.optim.SGD,\n",
    "                               **NN3_architecture, **NN3_best_param)\n",
    "NN3_model.fit(X_train_all_tensor, y_train_all_tensor)\n",
    "y_in_pred_NN3 = NN3_model.predict(torch.tensor(X_train_all, dtype=torch.float)).reshape(-1, 1)\n",
    "#\n",
    "\n",
    "# NN4\n",
    "NN4_result = {}\n",
    "NN4_architecture = {\"module__n_feature\": X_train_tensor.shape[1],\n",
    "                    \"module__n_hidden1\": 32, \"module__n_hidden2\": 16,\n",
    "                    \"module__n_hidden3\": 8,  \"module__n_hidden4\": 4,\n",
    "                    \"module__n_output\": 1}\n",
    "NN4_param = {'module__dropout': [0.2, 0.4, 0.6, 0.8],\n",
    "             'lr': [0.001, 0.01],\n",
    "             'optimizer__weight_decay': [0.1, 0.01, 0.001]}\n",
    "for param in ParameterGrid(NN4_param):\n",
    "    NN4 = NeuralNetRegressor(Net4, verbose=0, max_epochs=200,\n",
    "                             optimizer=torch.optim.SGD,\n",
    "                             **NN4_architecture, **param)\n",
    "    NN4.fit(X_train_tensor, y_train_tensor)\n",
    "    mse = mean_squared_error(NN4.predict(X_validation_tensor), y_validation)\n",
    "    NN4_result[str(param)] = mse\n",
    "\n",
    "#\n",
    "NN4_best_param = eval(min(NN4_result, key=NN4_result.get))\n",
    "NN4_model = NeuralNetRegressor(Net4, verbose=0, max_epochs=200, optimizer=torch.optim.SGD,\n",
    "                               **NN4_architecture, **NN4_best_param)\n",
    "NN4_model.fit(X_train_all_tensor, y_train_all_tensor)\n",
    "y_in_pred_NN4 = NN4_model.predict(torch.tensor(X_train_all, dtype=torch.float)).reshape(-1, 1)\n",
    "#\n",
    "\n",
    "# NN5\n",
    "NN5_result = {}\n",
    "NN5_architecture = {\"module__n_feature\": X_train_tensor.shape[1],\n",
    "                    \"module__n_hidden1\": 32, \"module__n_hidden2\": 16,\n",
    "                    \"module__n_hidden3\": 8,  \"module__n_hidden4\": 4,\n",
    "                    \"module__n_hidden5\": 2,\n",
    "                    \"module__n_output\": 1}\n",
    "NN5_param = {'module__dropout': [0.2, 0.4, 0.6, 0.8],\n",
    "             'lr': [0.001, 0.01],\n",
    "             'optimizer__weight_decay': [0.1, 0.01, 0.001]}\n",
    "for param in ParameterGrid(NN5_param):\n",
    "    NN5 = NeuralNetRegressor(Net5, verbose=0, max_epochs=200,\n",
    "                             optimizer=torch.optim.SGD,\n",
    "                             **NN5_architecture, **param)\n",
    "    NN5.fit(X_train_tensor, y_train_tensor)\n",
    "    mse = mean_squared_error(NN5.predict(X_validation_tensor), y_validation)\n",
    "    NN5_result[str(param)] = mse\n",
    "\n",
    "#\n",
    "NN5_best_param = eval(min(NN5_result, key=NN5_result.get))\n",
    "NN5_model = NeuralNetRegressor(Net5, verbose=0, max_epochs=200, optimizer=torch.optim.SGD,\n",
    "                               **NN5_architecture, **NN5_best_param)\n",
    "NN5_model.fit(X_train_all_tensor, y_train_all_tensor)\n",
    "y_in_pred_NN5 = NN5_model.predict(torch.tensor(X_train_all, dtype=torch.float)).reshape(-1, 1)\n",
    "#\n",
    "\n",
    "## Other commmonly used ML methods\n",
    "# Ridge\n",
    "print(\"Starting Ridge ...\")\n",
    "Ridge_param = {'alpha': list(10 ** np.arange(0, 20 + 0.001, 1))}\n",
    "Ridge_result = {}\n",
    "for param in ParameterGrid(Ridge_param):\n",
    "    RIDGE = Ridge(**param)\n",
    "    RIDGE.fit(X_train, y_train)\n",
    "    mse = mean_squared_error(RIDGE.predict(X_validation), y_validation)\n",
    "    Ridge_result[str(param)] = mse\n",
    "#\n",
    "Ridge_best_param = eval(min(Ridge_result, key=Ridge_result.get))\n",
    "Ridge_model = Ridge(**Ridge_best_param)\n",
    "Ridge_model.fit(X_train_all, y_train_all)\n",
    "y_in_pred_Ridge = Ridge_model.predict(X_train_all).reshape(-1, 1)\n",
    "\n",
    "# SVR\n",
    "print(\"Starting SVR ...\")\n",
    "SVR_param = {'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'degree': [2, 3, 4], 'C': [0.1, 0.5, 1]}\n",
    "SVR_result = {}\n",
    "for param in ParameterGrid(SVR_param):\n",
    "    SVR_tmp = SVR(**param)\n",
    "    SVR_tmp.fit(X_train, y_train)\n",
    "    mse = mean_squared_error(SVR_tmp.predict(X_validation), y_validation)\n",
    "    SVR_result[str(param)] = mse\n",
    "SVR_best_param = eval(min(SVR_result, key=SVR_result.get))\n",
    "SVR_model = SVR(**SVR_best_param)\n",
    "SVR_model.fit(X_train_all, y_train_all)\n",
    "y_in_pred_SVR = SVR_model.predict(X_train_all).reshape(-1, 1)\n",
    "\n",
    "# KNR\n",
    "print(\"Starting KNR ...\")\n",
    "KNR = KNeighborsRegressor()\n",
    "KNR_param = {'n_neighbors': [3, 4, 5, 6, 7], 'weights': ['distance', 'uniform'],\n",
    "             'leaf_size': [20, 30, 40], 'p': [1, 2, 3]}\n",
    "KNR_result = {}\n",
    "for param in ParameterGrid(KNR_param):\n",
    "    KNR = KNeighborsRegressor(**param)\n",
    "    KNR.fit(X_train, y_train)\n",
    "    mse = mean_squared_error(KNR.predict(X_validation), y_validation)\n",
    "    KNR_result[str(param)] = mse\n",
    "\n",
    "KNR_best_param = eval(min(KNR_result, key=KNR_result.get))\n",
    "KNR_model = KNeighborsRegressor(**KNR_best_param)\n",
    "KNR_model.fit(X_train_all, y_train_all)\n",
    "y_in_pred_KNR = KNR_model.predict(X_train_all).reshape(-1, 1)\n",
    "\n",
    "\n",
    "# XGBoost\n",
    "print(\"Starting XGBoost ...\")\n",
    "XGBoost_param =  {'max_depth': [4, 5, 6, 7, 8], 'eta': [0.01, 0.1],\n",
    "                  'lambda': [0, 0.5, 1], 'alpha': [0, 0.5, 1]}\n",
    "XGBoost_result = {}\n",
    "for param in ParameterGrid(XGBoost_param):\n",
    "    XGBoost = XGBRegressor(**param)\n",
    "    XGBoost.fit(X_train, y_train)\n",
    "    mse = mean_squared_error(XGBoost.predict(X_validation), y_validation)\n",
    "    XGBoost_result[str(param)] = mse\n",
    "\n",
    "XGB_best_param = eval(min(XGBoost_result, key=XGBoost_result.get))\n",
    "XGB_model = XGBRegressor(**XGB_best_param)\n",
    "XGB_model.fit(X_train_all, y_train_all)\n",
    "y_in_pred_XGBoost = XGB_model.predict(X_train_all).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4195a4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ml_in_array = np.concatenate([y_in_pred_OLS, y_in_pred_PLS, y_in_pred_PCR, y_in_pred_LASSO,\n",
    "                                   y_in_pred_ENet, y_in_pred_GBRT, y_in_pred_RF, y_in_pred_NN1,\n",
    "                                   y_in_pred_NN2, y_in_pred_NN3, y_in_pred_NN4, y_in_pred_NN5,\n",
    "                                   y_in_pred_Ridge, y_in_pred_SVR, y_in_pred_KNR, y_in_pred_XGBoost], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82836292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OLS</th>\n",
       "      <th>PLS</th>\n",
       "      <th>PCR</th>\n",
       "      <th>LASSO</th>\n",
       "      <th>ENet</th>\n",
       "      <th>GBRT</th>\n",
       "      <th>RF</th>\n",
       "      <th>NN1</th>\n",
       "      <th>NN2</th>\n",
       "      <th>NN3</th>\n",
       "      <th>NN4</th>\n",
       "      <th>NN5</th>\n",
       "      <th>Ridge</th>\n",
       "      <th>SVR</th>\n",
       "      <th>KNR</th>\n",
       "      <th>XGBoost</th>\n",
       "      <th>Combined</th>\n",
       "      <th>HA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>192701</th>\n",
       "      <td>0.009202</td>\n",
       "      <td>0.009648</td>\n",
       "      <td>0.005764</td>\n",
       "      <td>0.005956</td>\n",
       "      <td>0.005364</td>\n",
       "      <td>0.005499</td>\n",
       "      <td>0.006797</td>\n",
       "      <td>0.009285</td>\n",
       "      <td>0.010538</td>\n",
       "      <td>0.008334</td>\n",
       "      <td>0.007474</td>\n",
       "      <td>0.009078</td>\n",
       "      <td>0.008233</td>\n",
       "      <td>-0.007226</td>\n",
       "      <td>0.039649</td>\n",
       "      <td>0.027951</td>\n",
       "      <td>0.010097</td>\n",
       "      <td>-0.005710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192702</th>\n",
       "      <td>0.004380</td>\n",
       "      <td>0.010465</td>\n",
       "      <td>0.007155</td>\n",
       "      <td>0.006050</td>\n",
       "      <td>0.005456</td>\n",
       "      <td>-0.000099</td>\n",
       "      <td>-0.016054</td>\n",
       "      <td>0.008263</td>\n",
       "      <td>0.011065</td>\n",
       "      <td>0.008335</td>\n",
       "      <td>0.006241</td>\n",
       "      <td>0.009078</td>\n",
       "      <td>0.007794</td>\n",
       "      <td>-0.014032</td>\n",
       "      <td>0.016533</td>\n",
       "      <td>0.009114</td>\n",
       "      <td>0.004984</td>\n",
       "      <td>0.018154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192703</th>\n",
       "      <td>-0.002157</td>\n",
       "      <td>0.010130</td>\n",
       "      <td>0.005868</td>\n",
       "      <td>0.005457</td>\n",
       "      <td>0.005066</td>\n",
       "      <td>0.005499</td>\n",
       "      <td>0.006797</td>\n",
       "      <td>0.008238</td>\n",
       "      <td>0.011121</td>\n",
       "      <td>0.008334</td>\n",
       "      <td>0.006754</td>\n",
       "      <td>0.009078</td>\n",
       "      <td>0.007206</td>\n",
       "      <td>-0.022366</td>\n",
       "      <td>0.023124</td>\n",
       "      <td>0.007397</td>\n",
       "      <td>0.005972</td>\n",
       "      <td>0.013668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192704</th>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.010147</td>\n",
       "      <td>0.007508</td>\n",
       "      <td>0.006225</td>\n",
       "      <td>0.005554</td>\n",
       "      <td>0.005499</td>\n",
       "      <td>0.006797</td>\n",
       "      <td>0.007824</td>\n",
       "      <td>0.011017</td>\n",
       "      <td>0.008334</td>\n",
       "      <td>0.004626</td>\n",
       "      <td>0.009078</td>\n",
       "      <td>0.007585</td>\n",
       "      <td>-0.008991</td>\n",
       "      <td>0.002476</td>\n",
       "      <td>0.006952</td>\n",
       "      <td>0.005673</td>\n",
       "      <td>0.012736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192705</th>\n",
       "      <td>-0.002836</td>\n",
       "      <td>0.009058</td>\n",
       "      <td>0.004528</td>\n",
       "      <td>0.004476</td>\n",
       "      <td>0.004208</td>\n",
       "      <td>0.005499</td>\n",
       "      <td>0.006797</td>\n",
       "      <td>0.006729</td>\n",
       "      <td>0.009890</td>\n",
       "      <td>0.008334</td>\n",
       "      <td>0.008107</td>\n",
       "      <td>0.009078</td>\n",
       "      <td>0.005689</td>\n",
       "      <td>-0.019990</td>\n",
       "      <td>0.008594</td>\n",
       "      <td>0.012183</td>\n",
       "      <td>0.005022</td>\n",
       "      <td>0.021786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202007</th>\n",
       "      <td>0.017213</td>\n",
       "      <td>0.009551</td>\n",
       "      <td>0.023311</td>\n",
       "      <td>0.016457</td>\n",
       "      <td>0.014564</td>\n",
       "      <td>0.005499</td>\n",
       "      <td>0.008094</td>\n",
       "      <td>0.016089</td>\n",
       "      <td>0.011787</td>\n",
       "      <td>0.008329</td>\n",
       "      <td>0.007517</td>\n",
       "      <td>0.009078</td>\n",
       "      <td>0.015512</td>\n",
       "      <td>-0.011391</td>\n",
       "      <td>0.029582</td>\n",
       "      <td>0.016882</td>\n",
       "      <td>0.012380</td>\n",
       "      <td>0.005218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202008</th>\n",
       "      <td>-0.006437</td>\n",
       "      <td>0.006043</td>\n",
       "      <td>-0.000628</td>\n",
       "      <td>0.000752</td>\n",
       "      <td>0.001497</td>\n",
       "      <td>0.005499</td>\n",
       "      <td>-0.011331</td>\n",
       "      <td>0.008112</td>\n",
       "      <td>0.008588</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.006171</td>\n",
       "      <td>0.009078</td>\n",
       "      <td>-0.001269</td>\n",
       "      <td>-0.014053</td>\n",
       "      <td>0.005672</td>\n",
       "      <td>-0.017673</td>\n",
       "      <td>0.000522</td>\n",
       "      <td>0.005275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202009</th>\n",
       "      <td>-0.003173</td>\n",
       "      <td>0.006459</td>\n",
       "      <td>0.009180</td>\n",
       "      <td>0.007654</td>\n",
       "      <td>0.007312</td>\n",
       "      <td>0.005499</td>\n",
       "      <td>0.008094</td>\n",
       "      <td>0.012772</td>\n",
       "      <td>0.011439</td>\n",
       "      <td>0.008330</td>\n",
       "      <td>0.009184</td>\n",
       "      <td>0.009078</td>\n",
       "      <td>0.005946</td>\n",
       "      <td>-0.019148</td>\n",
       "      <td>-0.001256</td>\n",
       "      <td>-0.011811</td>\n",
       "      <td>0.004097</td>\n",
       "      <td>0.005236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202010</th>\n",
       "      <td>0.010124</td>\n",
       "      <td>0.006452</td>\n",
       "      <td>0.004954</td>\n",
       "      <td>0.005367</td>\n",
       "      <td>0.005292</td>\n",
       "      <td>0.005499</td>\n",
       "      <td>0.008094</td>\n",
       "      <td>0.012940</td>\n",
       "      <td>0.010679</td>\n",
       "      <td>0.008334</td>\n",
       "      <td>0.004850</td>\n",
       "      <td>0.009078</td>\n",
       "      <td>0.004779</td>\n",
       "      <td>0.003784</td>\n",
       "      <td>0.025179</td>\n",
       "      <td>0.026451</td>\n",
       "      <td>0.009491</td>\n",
       "      <td>0.005207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202011</th>\n",
       "      <td>0.022786</td>\n",
       "      <td>0.009079</td>\n",
       "      <td>0.022743</td>\n",
       "      <td>0.015739</td>\n",
       "      <td>0.013923</td>\n",
       "      <td>0.005499</td>\n",
       "      <td>0.008094</td>\n",
       "      <td>0.015124</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.008332</td>\n",
       "      <td>0.009339</td>\n",
       "      <td>0.009078</td>\n",
       "      <td>0.014468</td>\n",
       "      <td>-0.004185</td>\n",
       "      <td>0.028279</td>\n",
       "      <td>0.020428</td>\n",
       "      <td>0.013142</td>\n",
       "      <td>0.005295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1127 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             OLS       PLS       PCR     LASSO      ENet      GBRT        RF  \\\n",
       "month                                                                          \n",
       "192701  0.009202  0.009648  0.005764  0.005956  0.005364  0.005499  0.006797   \n",
       "192702  0.004380  0.010465  0.007155  0.006050  0.005456 -0.000099 -0.016054   \n",
       "192703 -0.002157  0.010130  0.005868  0.005457  0.005066  0.005499  0.006797   \n",
       "192704  0.000146  0.010147  0.007508  0.006225  0.005554  0.005499  0.006797   \n",
       "192705 -0.002836  0.009058  0.004528  0.004476  0.004208  0.005499  0.006797   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "202007  0.017213  0.009551  0.023311  0.016457  0.014564  0.005499  0.008094   \n",
       "202008 -0.006437  0.006043 -0.000628  0.000752  0.001497  0.005499 -0.011331   \n",
       "202009 -0.003173  0.006459  0.009180  0.007654  0.007312  0.005499  0.008094   \n",
       "202010  0.010124  0.006452  0.004954  0.005367  0.005292  0.005499  0.008094   \n",
       "202011  0.022786  0.009079  0.022743  0.015739  0.013923  0.005499  0.008094   \n",
       "\n",
       "             NN1       NN2       NN3       NN4       NN5     Ridge       SVR  \\\n",
       "month                                                                          \n",
       "192701  0.009285  0.010538  0.008334  0.007474  0.009078  0.008233 -0.007226   \n",
       "192702  0.008263  0.011065  0.008335  0.006241  0.009078  0.007794 -0.014032   \n",
       "192703  0.008238  0.011121  0.008334  0.006754  0.009078  0.007206 -0.022366   \n",
       "192704  0.007824  0.011017  0.008334  0.004626  0.009078  0.007585 -0.008991   \n",
       "192705  0.006729  0.009890  0.008334  0.008107  0.009078  0.005689 -0.019990   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "202007  0.016089  0.011787  0.008329  0.007517  0.009078  0.015512 -0.011391   \n",
       "202008  0.008112  0.008588  0.008333  0.006171  0.009078 -0.001269 -0.014053   \n",
       "202009  0.012772  0.011439  0.008330  0.009184  0.009078  0.005946 -0.019148   \n",
       "202010  0.012940  0.010679  0.008334  0.004850  0.009078  0.004779  0.003784   \n",
       "202011  0.015124  0.011547  0.008332  0.009339  0.009078  0.014468 -0.004185   \n",
       "\n",
       "             KNR   XGBoost  Combined        HA  \n",
       "month                                           \n",
       "192701  0.039649  0.027951  0.010097 -0.005710  \n",
       "192702  0.016533  0.009114  0.004984  0.018154  \n",
       "192703  0.023124  0.007397  0.005972  0.013668  \n",
       "192704  0.002476  0.006952  0.005673  0.012736  \n",
       "192705  0.008594  0.012183  0.005022  0.021786  \n",
       "...          ...       ...       ...       ...  \n",
       "202007  0.029582  0.016882  0.012380  0.005218  \n",
       "202008  0.005672 -0.017673  0.000522  0.005275  \n",
       "202009 -0.001256 -0.011811  0.004097  0.005236  \n",
       "202010  0.025179  0.026451  0.009491  0.005207  \n",
       "202011  0.028279  0.020428  0.013142  0.005295  \n",
       "\n",
       "[1127 rows x 18 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_ml_in_pred = pd.DataFrame(y_ml_in_array,\n",
    "                            columns=['OLS', 'PLS', 'PCR', 'LASSO', 'ENet', 'GBRT', 'RF', 'NN1',\n",
    "                                'NN2', 'NN3', 'NN4', 'NN5', 'Ridge', 'SVR', 'KNR', 'XGBoost'],\n",
    "                            index=predictor_df.month[:N])\n",
    "y_ml_in_pred['Combined'] = y_ml_in_pred.mean(axis=1)\n",
    "y_ml_in_pred['HA'] = y_pred_HA.ravel()\n",
    "y_ml_in_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4943680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>in_r_square(%)</th>\n",
       "      <th>success_ratio(%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>OLS</th>\n",
       "      <td>5.509803</td>\n",
       "      <td>60.514641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PLS</th>\n",
       "      <td>2.216518</td>\n",
       "      <td>60.070985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCR</th>\n",
       "      <td>2.046334</td>\n",
       "      <td>59.094942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LASSO</th>\n",
       "      <td>1.970166</td>\n",
       "      <td>60.248447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENet</th>\n",
       "      <td>1.681969</td>\n",
       "      <td>60.425909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBRT</th>\n",
       "      <td>10.725015</td>\n",
       "      <td>60.958296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>9.767483</td>\n",
       "      <td>60.692103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN1</th>\n",
       "      <td>1.393710</td>\n",
       "      <td>60.425909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN2</th>\n",
       "      <td>0.327844</td>\n",
       "      <td>60.248447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN3</th>\n",
       "      <td>0.613812</td>\n",
       "      <td>60.070985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN4</th>\n",
       "      <td>1.530346</td>\n",
       "      <td>59.716060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN5</th>\n",
       "      <td>0.444986</td>\n",
       "      <td>60.070985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>2.653534</td>\n",
       "      <td>60.248447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>-4.771874</td>\n",
       "      <td>42.147294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNR</th>\n",
       "      <td>15.383371</td>\n",
       "      <td>66.104703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>45.057436</td>\n",
       "      <td>75.510204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Combined</th>\n",
       "      <td>8.985874</td>\n",
       "      <td>64.418811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HA</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>59.006211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          in_r_square(%)  success_ratio(%)\n",
       "OLS             5.509803         60.514641\n",
       "PLS             2.216518         60.070985\n",
       "PCR             2.046334         59.094942\n",
       "LASSO           1.970166         60.248447\n",
       "ENet            1.681969         60.425909\n",
       "GBRT           10.725015         60.958296\n",
       "RF              9.767483         60.692103\n",
       "NN1             1.393710         60.425909\n",
       "NN2             0.327844         60.248447\n",
       "NN3             0.613812         60.070985\n",
       "NN4             1.530346         59.716060\n",
       "NN5             0.444986         60.070985\n",
       "Ridge           2.653534         60.248447\n",
       "SVR            -4.771874         42.147294\n",
       "KNR            15.383371         66.104703\n",
       "XGBoost        45.057436         75.510204\n",
       "Combined        8.985874         64.418811\n",
       "HA              0.000000         59.006211"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Report the in-sample R squares for comparison with historical mean\n",
    "def compute_in_r_square(actual, y_benchmark, y_pred):\n",
    "    MSFE_benchmark = mean_squared_error(y_benchmark, actual)\n",
    "    MSFE_pred = mean_squared_error(y_pred, actual)\n",
    "    return 1 - MSFE_pred / MSFE_benchmark\n",
    "\n",
    "# 2. Report success ratio\n",
    "def compute_success_ratio(actual, y_pred):\n",
    "    return np.sum(actual * y_pred > 0) / len(actual)\n",
    "\n",
    "\n",
    "ml_in_performance = []\n",
    "\n",
    "for col in y_ml_in_pred.columns:\n",
    "    oos_r_square = compute_in_r_square(actual, y_pred_HA, y_ml_in_pred[[col]].to_numpy())\n",
    "    success_ratio = compute_success_ratio(actual, y_ml_in_pred[[col]].to_numpy())\n",
    "    ml_in_performance.append([oos_r_square * 100, success_ratio * 100])\n",
    "\n",
    "    \n",
    "ml_in_performance_df = pd.DataFrame(np.array(ml_in_performance), index=y_ml_in_pred.columns,\n",
    "                                     columns=['in_r_square(%)', 'success_ratio(%)'])\n",
    "ml_in_performance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63837db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(\"ml_equity_premium_in_sample_results.xlsx\") as writer:\n",
    "    ml_in_performance_df.to_excel(writer, sheet_name='in_sample_performance')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
