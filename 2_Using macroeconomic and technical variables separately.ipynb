{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2df2b249",
   "metadata": {},
   "source": [
    "### Using macroeconomic and technical variables separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f822b3b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/xingfuxu/PycharmProjects/EquityPremiumPredictionML-Jupyter'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "# os.chdir(path)    # or you can set your working dir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3c1c50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your working dir should include \"NN_models.py\", Perform_CW_test.py\" and \"Perform_PT_test.py\" files.\n",
    "from Perform_CW_test import CW_test\n",
    "from Perform_PT_test import PT_test\n",
    "from NN_models import Net1, Net2, Net3, Net4, Net5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e772b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import torch\n",
    "from skorch import NeuralNetRegressor\n",
    "from tqdm import tqdm\n",
    "#\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50dbea16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>log_equity_premium</th>\n",
       "      <th>equity_premium</th>\n",
       "      <th>DP</th>\n",
       "      <th>DY</th>\n",
       "      <th>EP</th>\n",
       "      <th>SVAR</th>\n",
       "      <th>BM</th>\n",
       "      <th>NTIS</th>\n",
       "      <th>TBL</th>\n",
       "      <th>...</th>\n",
       "      <th>MA_2_9</th>\n",
       "      <th>MA_2_12</th>\n",
       "      <th>MA_3_9</th>\n",
       "      <th>MA_3_12</th>\n",
       "      <th>MOM_1</th>\n",
       "      <th>MOM_2</th>\n",
       "      <th>MOM_3</th>\n",
       "      <th>MOM_6</th>\n",
       "      <th>MOM_9</th>\n",
       "      <th>MOM_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>192701</td>\n",
       "      <td>-0.005710</td>\n",
       "      <td>-0.00571</td>\n",
       "      <td>-2.942374</td>\n",
       "      <td>-2.963349</td>\n",
       "      <td>-2.374773</td>\n",
       "      <td>0.00047</td>\n",
       "      <td>0.44371</td>\n",
       "      <td>0.05082</td>\n",
       "      <td>3.23</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>192702</td>\n",
       "      <td>0.042017</td>\n",
       "      <td>0.04302</td>\n",
       "      <td>-2.979535</td>\n",
       "      <td>-2.932946</td>\n",
       "      <td>-2.430353</td>\n",
       "      <td>0.00029</td>\n",
       "      <td>0.42850</td>\n",
       "      <td>0.05167</td>\n",
       "      <td>3.29</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>192703</td>\n",
       "      <td>0.004697</td>\n",
       "      <td>0.00472</td>\n",
       "      <td>-2.976535</td>\n",
       "      <td>-2.970053</td>\n",
       "      <td>-2.445079</td>\n",
       "      <td>0.00092</td>\n",
       "      <td>0.46977</td>\n",
       "      <td>0.04636</td>\n",
       "      <td>3.20</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>192704</td>\n",
       "      <td>0.009940</td>\n",
       "      <td>0.01002</td>\n",
       "      <td>-2.984225</td>\n",
       "      <td>-2.967143</td>\n",
       "      <td>-2.471309</td>\n",
       "      <td>0.00060</td>\n",
       "      <td>0.45675</td>\n",
       "      <td>0.05051</td>\n",
       "      <td>3.39</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>192705</td>\n",
       "      <td>0.057987</td>\n",
       "      <td>0.05985</td>\n",
       "      <td>-3.025963</td>\n",
       "      <td>-2.975058</td>\n",
       "      <td>-2.531446</td>\n",
       "      <td>0.00039</td>\n",
       "      <td>0.43478</td>\n",
       "      <td>0.05528</td>\n",
       "      <td>3.33</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    month  log_equity_premium  equity_premium        DP        DY        EP  \\\n",
       "0  192701           -0.005710        -0.00571 -2.942374 -2.963349 -2.374773   \n",
       "1  192702            0.042017         0.04302 -2.979535 -2.932946 -2.430353   \n",
       "2  192703            0.004697         0.00472 -2.976535 -2.970053 -2.445079   \n",
       "3  192704            0.009940         0.01002 -2.984225 -2.967143 -2.471309   \n",
       "4  192705            0.057987         0.05985 -3.025963 -2.975058 -2.531446   \n",
       "\n",
       "      SVAR       BM     NTIS   TBL  ...  MA_2_9  MA_2_12  MA_3_9  MA_3_12  \\\n",
       "0  0.00047  0.44371  0.05082  3.23  ...       1        1       1        1   \n",
       "1  0.00029  0.42850  0.05167  3.29  ...       1        1       1        1   \n",
       "2  0.00092  0.46977  0.04636  3.20  ...       1        1       1        1   \n",
       "3  0.00060  0.45675  0.05051  3.39  ...       1        1       1        1   \n",
       "4  0.00039  0.43478  0.05528  3.33  ...       1        1       1        1   \n",
       "\n",
       "   MOM_1  MOM_2  MOM_3  MOM_6  MOM_9  MOM_12  \n",
       "0      0      0      1      1      1       1  \n",
       "1      1      1      1      1      1       1  \n",
       "2      1      1      1      1      1       1  \n",
       "3      1      1      1      1      1       1  \n",
       "4      1      1      1      1      1       1  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set seed\n",
    "torch.manual_seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "# read data\n",
    "predictor_df = pd.read_excel(open('ml_equity_premium_data.xlsx', 'rb'), sheet_name='result_predictor')\n",
    "predictor_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5218722b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove irrelavent columns\n",
    "predictor0 = predictor_df.drop(['month', 'equity_premium'], axis=1)\n",
    "# get all the predictors and set the log equity premium 1-month ahead\n",
    "predictor = np.concatenate([predictor0['log_equity_premium'][1:].values.reshape(-1, 1),\n",
    "                            predictor0.iloc[0:(predictor0.shape[0] - 1), 1:]], axis=1)\n",
    "\n",
    "# number of rows\n",
    "N = predictor.shape[0]\n",
    "\n",
    "# number of all columns, including the log equity premium\n",
    "n_cols = predictor.shape[1]\n",
    "\n",
    "# Actual one-month ahead log equity premium\n",
    "actual = predictor[:, [0]]\n",
    "\n",
    "# Historical average forecasting as benchmark\n",
    "y_pred_HA = predictor0['log_equity_premium'].values[0:(predictor0.shape[0] - 1), ].cumsum() / np.arange(1, N + 1)\n",
    "y_pred_HA = y_pred_HA.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f59806b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Out-of-sample: 1957:01-2020:12\n",
    "in_out_1957 = predictor_df.index[predictor_df['month'] == 195701][0]\n",
    "actual_1957 = actual[in_out_1957:, ]\n",
    "y_pred_HA_1957 = y_pred_HA[in_out_1957:, ]\n",
    "MSFE_HA_1957 = mean_squared_error(y_pred_HA_1957, actual_1957)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5dcc763",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 767/767 [5:17:04<00:00, 24.80s/it]\n"
     ]
    }
   ],
   "source": [
    "## For macroeconomic variables\n",
    "\n",
    "# Machine Learning methods used in GKX (2020)\n",
    "y_pred_OLS_1957, y_pred_PLS_1957, y_pred_PCR_1957,  y_pred_LASSO_1957 = [], [], [], []\n",
    "y_pred_ENet_1957, y_pred_GBRT_1957, y_pred_RF_1957 = [], [], []\n",
    "y_pred_NN1_1957, y_pred_NN2_1957, y_pred_NN3_1957, y_pred_NN4_1957, y_pred_NN5_1957 = [], [], [], [], []\n",
    "\n",
    "## Other commonly used machine learning method\n",
    "y_pred_Ridge_1957, y_pred_SVR_1957, y_pred_KNR_1957,  y_pred_XGBoost_1957 = [], [], [], []\n",
    "y_pred_combination_1957 = []\n",
    "\n",
    "# control the update month of models during out-of-sample period. \n",
    "month_index = 1  # We update our models annually, meaning we refresh them in months 1, 13, 25, ...\n",
    "\n",
    "for t in tqdm(range(in_out_1957, N)):\n",
    "    #\n",
    "    X_train_all = predictor[:t, 1:13]\n",
    "    y_train_all = predictor[:t, 0]\n",
    "    # set 15% of all the train data as validation set\n",
    "    X_train = X_train_all[0:int(len(X_train_all) * 0.85), :]\n",
    "    X_validation = X_train_all[int(len(X_train_all) * 0.85):t, :]\n",
    "    y_train = y_train_all[0:int(len(X_train_all) * 0.85)]\n",
    "    y_validation = y_train_all[int(len(X_train_all) * 0.85):t]\n",
    "    #\n",
    "    if month_index % 12 == 1:\n",
    "        month_index += 1\n",
    "        # OLS\n",
    "        OLS = LinearRegression()\n",
    "        OLS.fit(X_train_all, y_train_all)\n",
    "        y_pred_OLS_1957.append(OLS.predict(predictor[[t], 1:13])[0])\n",
    "\n",
    "        # PLS\n",
    "        PLS_param = {'n_components': [1, 2, 3, 4, 5, 6, 7, 8]}\n",
    "        PLS_result = {}\n",
    "        for param in ParameterGrid(PLS_param):\n",
    "            PLS = PLSRegression(**param)\n",
    "            PLS.fit(X_train, y_train)\n",
    "            mse = mean_squared_error(PLS.predict(X_validation), y_validation)\n",
    "            PLS_result[str(param)] = mse\n",
    "\n",
    "        PLS_best_param = eval(min(PLS_result, key=PLS_result.get))\n",
    "        PLS_model = PLSRegression(**PLS_best_param)\n",
    "        PLS_model.fit(X_train_all, y_train_all)\n",
    "        y_pred_PLS_1957.append(PLS_model.predict(predictor[[t], 1:13])[0][0])\n",
    "\n",
    "        # PCR\n",
    "        PCR_param = {'n_components': [1, 2, 3, 4, 5, 6, 7, 8]}\n",
    "        PCR_result = {}\n",
    "        for param in ParameterGrid(PCR_param):\n",
    "            pca = PCA(**param)\n",
    "            pca.fit(X_train)\n",
    "            comps = pca.transform(X_train)\n",
    "            forecast = LinearRegression()\n",
    "            forecast.fit(comps, y_train)\n",
    "            mse = mean_squared_error(forecast.predict(pca.transform(X_validation)), y_validation)\n",
    "            PCR_result[str(param)] = mse\n",
    "        #\n",
    "        PCR_best_param = eval(min(PCR_result, key=PCR_result.get))\n",
    "        #\n",
    "        PCR_model = PCA(**PCR_best_param)\n",
    "        PCR_model.fit(X_train_all)\n",
    "        PCR_comps = PCR_model.transform(X_train_all)\n",
    "        PCR_forecast = LinearRegression()\n",
    "        PCR_forecast.fit(PCR_comps, y_train_all)\n",
    "        y_pred_PCR_1957.append(PCR_forecast.predict(PCR_model.transform(predictor[[t], 1:13]))[0])\n",
    "\n",
    "        # LASSO\n",
    "        LASSO_param = {'alpha': list(10 ** np.arange(-4, 1 + 0.001, 0.2))}\n",
    "        LASSO_result = {}\n",
    "        for param in ParameterGrid(LASSO_param):\n",
    "            LASSO = Lasso(**param)\n",
    "            LASSO.fit(X_train, y_train)\n",
    "            mse = mean_squared_error(LASSO.predict(X_validation), y_validation)\n",
    "            LASSO_result[str(param)] = mse\n",
    "        #\n",
    "        LASSO_best_param = eval(min(LASSO_result, key=LASSO_result.get))\n",
    "        #\n",
    "        LASSO_model = Lasso(**LASSO_best_param)\n",
    "        LASSO_model.fit(X_train_all, y_train_all)\n",
    "        y_pred_LASSO_1957.append(LASSO_model.predict(predictor[[t], 1:13])[0])\n",
    "\n",
    "        # ENet\n",
    "        ENet_param = {'alpha': list(10 ** np.arange(-4, 1 + 0.001, 0.2)),\n",
    "                      'l1_ratio': list(np.arange(0.2, 1, 0.3))}\n",
    "        ENet_result = {}\n",
    "        for param in ParameterGrid(ENet_param):\n",
    "            ENet = ElasticNet(**param)\n",
    "            ENet.fit(X_train, y_train)\n",
    "            mse = mean_squared_error(ENet.predict(X_validation), y_validation)\n",
    "            ENet_result[str(param)] = mse\n",
    "\n",
    "        ENet_best_param = eval(min(ENet_result, key=ENet_result.get))\n",
    "        ENet_model = ElasticNet(**ENet_best_param)\n",
    "        ENet_model.fit(X_train_all, y_train_all)\n",
    "        y_pred_ENet_1957.append(ENet_model.predict(predictor[[t], 1:13])[0])\n",
    "\n",
    "        # GBRT\n",
    "        GBRT_param = {'n_estimators': [10, 50, 100, 150, 200],\n",
    "                      'max_depth': [2, 3, 4],\n",
    "                      'min_samples_leaf': [1, 3, 5]}\n",
    "        GBRT_result = {}\n",
    "        for param in ParameterGrid(GBRT_param):\n",
    "            GBRT = GradientBoostingRegressor(**param)\n",
    "            GBRT.fit(X_train, y_train)\n",
    "            mse = mean_squared_error(GBRT.predict(X_validation), y_validation)\n",
    "            GBRT_result[str(param)] = mse\n",
    "\n",
    "        GBRT_best_param = eval(min(GBRT_result, key=GBRT_result.get))\n",
    "        GBRT_model = GradientBoostingRegressor(**GBRT_best_param)\n",
    "        GBRT_model.fit(X_train_all, y_train_all)\n",
    "        y_pred_GBRT_1957.append(GBRT_model.predict(predictor[[t], 1:13])[0])\n",
    "\n",
    "        # RF\n",
    "        RF_param = {'n_estimators': [10, 50, 100, 150, 200],\n",
    "                    'max_depth': [2, 3, 4],\n",
    "                    'min_samples_leaf': [1, 3, 5]}\n",
    "        RF_result = {}\n",
    "        for param in ParameterGrid(RF_param):\n",
    "            RF = RandomForestRegressor(**param)\n",
    "            RF.fit(X_train, y_train)\n",
    "            mse = mean_squared_error(RF.predict(X_validation), y_validation)\n",
    "            RF_result[str(param)] = mse\n",
    "\n",
    "        RF_best_param = eval(min(RF_result, key=RF_result.get))\n",
    "        RF_model = RandomForestRegressor(**RF_best_param)\n",
    "        RF_model.fit(X_train_all, y_train_all)\n",
    "        y_pred_RF_1957.append(RF_model.predict(predictor[[t], 1:13])[0])\n",
    "\n",
    "        # Neural Network Models: NN1~NN5\n",
    "        X_train_all_tensor = torch.tensor(X_train_all, dtype=torch.float)\n",
    "        y_train_all_tensor = torch.tensor(y_train_all.reshape(-1, 1), dtype=torch.float)\n",
    "        X_train_tensor = torch.tensor(X_train, dtype=torch.float)\n",
    "        y_train_tensor = torch.tensor(y_train.reshape(-1, 1), dtype=torch.float)\n",
    "        X_validation_tensor = torch.tensor(X_validation, dtype=torch.float)\n",
    "        y_validation_tensor = torch.tensor(y_validation.reshape(-1, 1), dtype=torch.float)\n",
    "\n",
    "        # NN1\n",
    "        NN1_result = {}\n",
    "        NN1_architecture = {\"module__n_feature\": X_train_tensor.shape[1],\n",
    "                            # n_feature should be the number of predictors\n",
    "                            \"module__n_hidden1\": 32,\n",
    "                            \"module__n_output\": 1}\n",
    "        NN1_param = {'module__dropout': [0.2, 0.4, 0.6, 0.8],\n",
    "                     'lr': [0.001, 0.01],\n",
    "                     'optimizer__weight_decay': [0.1, 0.01, 0.001]}\n",
    "        for param in ParameterGrid(NN1_param):\n",
    "            NN1 = NeuralNetRegressor(Net1, verbose=0, max_epochs=200,\n",
    "                                     optimizer=torch.optim.SGD,\n",
    "                                     **NN1_architecture, **param)\n",
    "            NN1.fit(X_train_tensor, y_train_tensor)\n",
    "            mse = mean_squared_error(NN1.predict(X_validation_tensor), y_validation)\n",
    "            NN1_result[str(param)] = mse\n",
    "\n",
    "        #\n",
    "        NN1_best_param = eval(min(NN1_result, key=NN1_result.get))\n",
    "        NN1_model = NeuralNetRegressor(Net1, verbose=0, max_epochs=200, optimizer=torch.optim.SGD,\n",
    "                                       **NN1_architecture, **NN1_best_param)\n",
    "        NN1_model.fit(X_train_all_tensor, y_train_all_tensor)\n",
    "        y_pred_NN1_1957.append(NN1_model.predict(torch.tensor(predictor[[t], 1:13], dtype=torch.float))[0][0])\n",
    "\n",
    "        # NN2\n",
    "        NN2_result = {}\n",
    "        NN2_architecture = {\"module__n_feature\": X_train_tensor.shape[1],\n",
    "                            \"module__n_hidden1\": 32, \"module__n_hidden2\": 16,\n",
    "                            \"module__n_output\": 1}\n",
    "        NN2_param = {'module__dropout': [0.2, 0.4, 0.6, 0.8],\n",
    "                     'lr': [0.001, 0.01],\n",
    "                     'optimizer__weight_decay': [0.1, 0.01, 0.001]}\n",
    "        for param in ParameterGrid(NN2_param):\n",
    "            NN2 = NeuralNetRegressor(Net2, verbose=0, max_epochs=200,\n",
    "                                     optimizer=torch.optim.SGD,\n",
    "                                     **NN2_architecture, **param)\n",
    "            NN2.fit(X_train_tensor, y_train_tensor)\n",
    "            mse = mean_squared_error(NN2.predict(X_validation_tensor), y_validation)\n",
    "            NN2_result[str(param)] = mse\n",
    "\n",
    "        #\n",
    "        NN2_best_param = eval(min(NN2_result, key=NN2_result.get))\n",
    "        NN2_model = NeuralNetRegressor(Net2, verbose=0, max_epochs=200, optimizer=torch.optim.SGD,\n",
    "                                       **NN2_architecture, **NN2_best_param)\n",
    "        NN2_model.fit(X_train_all_tensor, y_train_all_tensor)\n",
    "        y_pred_NN2_1957.append(NN2_model.predict(torch.tensor(predictor[[t], 1:13], dtype=torch.float))[0][0])\n",
    "        #\n",
    "\n",
    "        # NN3\n",
    "        NN3_result = {}\n",
    "        NN3_architecture = {\"module__n_feature\": X_train_tensor.shape[1],\n",
    "                            # n_feature should be the number of predictors\n",
    "                            \"module__n_hidden1\": 32, \"module__n_hidden2\": 16,\n",
    "                            \"module__n_hidden3\": 8,\n",
    "                            \"module__n_output\": 1}\n",
    "        NN3_param = {'module__dropout': [0.2, 0.4, 0.6, 0.8],\n",
    "                     'lr': [0.001, 0.01],\n",
    "                     'optimizer__weight_decay': [0.1, 0.01, 0.001]}\n",
    "        for param in ParameterGrid(NN3_param):\n",
    "            NN3 = NeuralNetRegressor(Net3, verbose=0, max_epochs=200,\n",
    "                                     optimizer=torch.optim.SGD,\n",
    "                                     **NN3_architecture, **param)\n",
    "            NN3.fit(X_train_tensor, y_train_tensor)\n",
    "            mse = mean_squared_error(NN3.predict(X_validation_tensor), y_validation)\n",
    "            NN3_result[str(param)] = mse\n",
    "\n",
    "        #\n",
    "        NN3_best_param = eval(min(NN3_result, key=NN3_result.get))\n",
    "        NN3_model = NeuralNetRegressor(Net3, verbose=0, max_epochs=200, optimizer=torch.optim.SGD,\n",
    "                                       **NN3_architecture, **NN3_best_param)\n",
    "        NN3_model.fit(X_train_all_tensor, y_train_all_tensor)\n",
    "        y_pred_NN3_1957.append(NN3_model.predict(torch.tensor(predictor[[t], 1:13], dtype=torch.float))[0][0])\n",
    "        #\n",
    "\n",
    "        # NN4\n",
    "        NN4_result = {}\n",
    "        NN4_architecture = {\"module__n_feature\": X_train_tensor.shape[1],\n",
    "                            \"module__n_hidden1\": 32, \"module__n_hidden2\": 16,\n",
    "                            \"module__n_hidden3\": 8, \"module__n_hidden4\": 4,\n",
    "                            \"module__n_output\": 1}\n",
    "        NN4_param = {'module__dropout': [0.2, 0.4, 0.6, 0.8],\n",
    "                     'lr': [0.001, 0.01],\n",
    "                     'optimizer__weight_decay': [0.1, 0.01, 0.001]}\n",
    "        for param in ParameterGrid(NN4_param):\n",
    "            NN4 = NeuralNetRegressor(Net4, verbose=0, max_epochs=200,\n",
    "                                     optimizer=torch.optim.SGD,\n",
    "                                     **NN4_architecture, **param)\n",
    "            NN4.fit(X_train_tensor, y_train_tensor)\n",
    "            mse = mean_squared_error(NN4.predict(X_validation_tensor), y_validation)\n",
    "            NN4_result[str(param)] = mse\n",
    "\n",
    "        #\n",
    "        NN4_best_param = eval(min(NN4_result, key=NN4_result.get))\n",
    "        NN4_model = NeuralNetRegressor(Net4, verbose=0, max_epochs=200, optimizer=torch.optim.SGD,\n",
    "                                       **NN4_architecture, **NN4_best_param)\n",
    "        NN4_model.fit(X_train_all_tensor, y_train_all_tensor)\n",
    "        y_pred_NN4_1957.append(NN4_model.predict(torch.tensor(predictor[[t], 1:13], dtype=torch.float))[0][0])\n",
    "        #\n",
    "\n",
    "        # NN5\n",
    "        NN5_result = {}\n",
    "        NN5_architecture = {\"module__n_feature\": X_train_tensor.shape[1],\n",
    "                            \"module__n_hidden1\": 32, \"module__n_hidden2\": 16,\n",
    "                            \"module__n_hidden3\": 8, \"module__n_hidden4\": 4,\n",
    "                            \"module__n_hidden5\": 2,\n",
    "                            \"module__n_output\": 1}\n",
    "        NN5_param = {'module__dropout': [0.2, 0.4, 0.6, 0.8],\n",
    "                     'lr': [0.001, 0.01],\n",
    "                     'optimizer__weight_decay': [0.1, 0.01, 0.001]}\n",
    "        for param in ParameterGrid(NN5_param):\n",
    "            NN5 = NeuralNetRegressor(Net5, verbose=0, max_epochs=200,\n",
    "                                     optimizer=torch.optim.SGD,\n",
    "                                     **NN5_architecture, **param)\n",
    "            NN5.fit(X_train_tensor, y_train_tensor)\n",
    "            mse = mean_squared_error(NN5.predict(X_validation_tensor), y_validation)\n",
    "            NN5_result[str(param)] = mse\n",
    "\n",
    "        #\n",
    "        NN5_best_param = eval(min(NN5_result, key=NN5_result.get))\n",
    "        NN5_model = NeuralNetRegressor(Net5, verbose=0, max_epochs=200, optimizer=torch.optim.SGD,\n",
    "                                       **NN5_architecture, **NN5_best_param)\n",
    "        NN5_model.fit(X_train_all_tensor, y_train_all_tensor)\n",
    "        y_pred_NN5_1957.append(NN5_model.predict(torch.tensor(predictor[[t], 1:13], dtype=torch.float))[0][0])\n",
    "        #\n",
    "\n",
    "        ## Other commmonly used ML methods\n",
    "        # Ridge\n",
    "        Ridge_param = {'alpha': list(10 ** np.arange(0, 20 + 0.001, 1))}\n",
    "        Ridge_result = {}\n",
    "        for param in ParameterGrid(Ridge_param):\n",
    "            RIDGE = Ridge(**param)\n",
    "            RIDGE.fit(X_train, y_train)\n",
    "            mse = mean_squared_error(RIDGE.predict(X_validation), y_validation)\n",
    "            Ridge_result[str(param)] = mse\n",
    "        #\n",
    "        Ridge_best_param = eval(min(Ridge_result, key=Ridge_result.get))\n",
    "        Ridge_model = Ridge(**Ridge_best_param)\n",
    "        Ridge_model.fit(X_train_all, y_train_all)\n",
    "        y_pred_Ridge_1957.append(Ridge_model.predict(predictor[[t], 1:13])[0])\n",
    "\n",
    "        # SVR\n",
    "        SVR_param = {'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'degree': [2, 3, 4], 'C': [0.1, 0.5, 1]}\n",
    "        SVR_result = {}\n",
    "        for param in ParameterGrid(SVR_param):\n",
    "            SVR_tmp = SVR(**param)\n",
    "            SVR_tmp.fit(X_train, y_train)\n",
    "            mse = mean_squared_error(SVR_tmp.predict(X_validation), y_validation)\n",
    "            SVR_result[str(param)] = mse\n",
    "        SVR_best_param = eval(min(SVR_result, key=SVR_result.get))\n",
    "        SVR_model = SVR(**SVR_best_param)\n",
    "        SVR_model.fit(X_train_all, y_train_all)\n",
    "        y_pred_SVR_1957.append(SVR_model.predict(predictor[[t], 1:13])[0])\n",
    "\n",
    "        # KNR\n",
    "        KNR = KNeighborsRegressor()\n",
    "        KNR_param = {'n_neighbors': [3, 4, 5, 6, 7], 'weights': ['distance', 'uniform'],\n",
    "                     'leaf_size': [20, 30, 40], 'p': [1, 2, 3]}\n",
    "        KNR_result = {}\n",
    "        for param in ParameterGrid(KNR_param):\n",
    "            KNR = KNeighborsRegressor(**param)\n",
    "            KNR.fit(X_train, y_train)\n",
    "            mse = mean_squared_error(KNR.predict(X_validation), y_validation)\n",
    "            KNR_result[str(param)] = mse\n",
    "\n",
    "        KNR_best_param = eval(min(KNR_result, key=KNR_result.get))\n",
    "        KNR_model = KNeighborsRegressor(**KNR_best_param)\n",
    "        KNR_model.fit(X_train_all, y_train_all)\n",
    "        y_pred_KNR_1957.append(KNR_model.predict(predictor[[t], 1:13])[0])\n",
    "\n",
    "        # XGBoost\n",
    "        XGBoost_param = {'max_depth': [4, 5, 6, 7, 8], 'eta': [0.01, 0.1],\n",
    "                         'lambda': [0, 0.5, 1], 'alpha': [0, 0.5, 1]}\n",
    "        XGBoost_result = {}\n",
    "        for param in ParameterGrid(XGBoost_param):\n",
    "            XGBoost = XGBRegressor(**param)\n",
    "            XGBoost.fit(X_train, y_train)\n",
    "            mse = mean_squared_error(XGBoost.predict(X_validation), y_validation)\n",
    "            XGBoost_result[str(param)] = mse\n",
    "\n",
    "        XGB_best_param = eval(min(XGBoost_result, key=XGBoost_result.get))\n",
    "        XGB_model = XGBRegressor(**XGB_best_param)\n",
    "        XGB_model.fit(X_train_all, y_train_all)\n",
    "        y_pred_XGBoost_1957.append(XGB_model.predict(predictor[[t], 1:13])[0])\n",
    "    else:\n",
    "        month_index += 1\n",
    "        y_pred_OLS_1957.append(OLS.predict(predictor[[t], 1:13])[0])\n",
    "        y_pred_PLS_1957.append(PLS_model.predict(predictor[[t], 1:13])[0][0])\n",
    "        y_pred_PCR_1957.append(PCR_forecast.predict(PCR_model.transform(predictor[[t], 1:13]))[0])\n",
    "        y_pred_LASSO_1957.append(LASSO_model.predict(predictor[[t], 1:13])[0])\n",
    "        y_pred_ENet_1957.append(ENet_model.predict(predictor[[t], 1:13])[0])\n",
    "        y_pred_GBRT_1957.append(GBRT_model.predict(predictor[[t], 1:13])[0])\n",
    "        y_pred_RF_1957.append(RF_model.predict(predictor[[t], 1:13])[0])\n",
    "        y_pred_NN1_1957.append(NN1_model.predict(torch.tensor(predictor[[t], 1:13], dtype=torch.float))[0][0])\n",
    "        y_pred_NN2_1957.append(NN2_model.predict(torch.tensor(predictor[[t], 1:13], dtype=torch.float))[0][0])\n",
    "        y_pred_NN3_1957.append(NN3_model.predict(torch.tensor(predictor[[t], 1:13], dtype=torch.float))[0][0])\n",
    "        y_pred_NN4_1957.append(NN4_model.predict(torch.tensor(predictor[[t], 1:13], dtype=torch.float))[0][0])\n",
    "        y_pred_NN5_1957.append(NN5_model.predict(torch.tensor(predictor[[t], 1:13], dtype=torch.float))[0][0])\n",
    "        # Other commonly used ML methods\n",
    "        y_pred_Ridge_1957.append(Ridge_model.predict(predictor[[t], 1:13])[0])\n",
    "        y_pred_SVR_1957.append(SVR_model.predict(predictor[[t], 1:13])[0])\n",
    "        y_pred_KNR_1957.append(KNR_model.predict(predictor[[t], 1:13])[0])\n",
    "        y_pred_XGBoost_1957.append(XGB_model.predict(predictor[[t], 1:13])[0])\n",
    "\n",
    "        \n",
    "# collect predicted value        \n",
    "y_ml_pred = pd.DataFrame(np.array([y_pred_OLS_1957, y_pred_PLS_1957, y_pred_PCR_1957, y_pred_LASSO_1957,\n",
    "                                   y_pred_ENet_1957, y_pred_GBRT_1957, y_pred_RF_1957, y_pred_NN1_1957,\n",
    "                                   y_pred_NN2_1957, y_pred_NN3_1957, y_pred_NN4_1957, y_pred_NN5_1957,\n",
    "                                   y_pred_Ridge_1957, y_pred_SVR_1957, y_pred_KNR_1957, y_pred_XGBoost_1957]),\n",
    "                         index=['OLS', 'PLS', 'PCR', 'LASSO', 'ENet', 'GBRT', 'RF', 'NN1',\n",
    "                                'NN2', 'NN3', 'NN4', 'NN5', 'Ridge', 'SVR', 'KNR', 'XGBoost'],\n",
    "                         columns=predictor_df.month[in_out_1957:N]).T\n",
    "y_ml_pred['Combined'] = y_ml_pred.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f55b8e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xingfuxu/PycharmProjects/EquityPremiumPredictionML-Jupyter/Perform_PT_test.py:38: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  stat = (p_hat - p_star) / np.sqrt(p_hat_var - p_star_var)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m_oos_r_square</th>\n",
       "      <th>m_MSFE_adjusted</th>\n",
       "      <th>m_pvalue_MSFE</th>\n",
       "      <th>m_success_ratio</th>\n",
       "      <th>m_PT_stat</th>\n",
       "      <th>m_pvalue_PT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>OLS</th>\n",
       "      <td>-10.832278</td>\n",
       "      <td>-0.163173</td>\n",
       "      <td>0.564809</td>\n",
       "      <td>52.411995</td>\n",
       "      <td>-0.072373</td>\n",
       "      <td>0.528848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PLS</th>\n",
       "      <td>-4.207930</td>\n",
       "      <td>-0.469415</td>\n",
       "      <td>0.680613</td>\n",
       "      <td>54.628422</td>\n",
       "      <td>0.024259</td>\n",
       "      <td>0.490323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCR</th>\n",
       "      <td>-0.295120</td>\n",
       "      <td>1.456394</td>\n",
       "      <td>0.072642</td>\n",
       "      <td>57.235984</td>\n",
       "      <td>1.769164</td>\n",
       "      <td>0.038433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LASSO</th>\n",
       "      <td>-2.122375</td>\n",
       "      <td>-0.098809</td>\n",
       "      <td>0.539355</td>\n",
       "      <td>57.235984</td>\n",
       "      <td>0.812908</td>\n",
       "      <td>0.208135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENet</th>\n",
       "      <td>-2.099062</td>\n",
       "      <td>0.121347</td>\n",
       "      <td>0.451708</td>\n",
       "      <td>56.192960</td>\n",
       "      <td>0.385332</td>\n",
       "      <td>0.349996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBRT</th>\n",
       "      <td>-15.540483</td>\n",
       "      <td>0.620540</td>\n",
       "      <td>0.267451</td>\n",
       "      <td>56.584094</td>\n",
       "      <td>-0.518751</td>\n",
       "      <td>0.698033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>-10.940488</td>\n",
       "      <td>-0.480153</td>\n",
       "      <td>0.684441</td>\n",
       "      <td>54.758801</td>\n",
       "      <td>-1.843827</td>\n",
       "      <td>0.967396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN1</th>\n",
       "      <td>-4.797002</td>\n",
       "      <td>1.019277</td>\n",
       "      <td>0.154036</td>\n",
       "      <td>59.061278</td>\n",
       "      <td>1.646321</td>\n",
       "      <td>0.049849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN2</th>\n",
       "      <td>-7.924200</td>\n",
       "      <td>-1.297293</td>\n",
       "      <td>0.902735</td>\n",
       "      <td>55.541069</td>\n",
       "      <td>-0.621255</td>\n",
       "      <td>0.732784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN3</th>\n",
       "      <td>-13.836601</td>\n",
       "      <td>0.281574</td>\n",
       "      <td>0.389135</td>\n",
       "      <td>59.061278</td>\n",
       "      <td>1.586979</td>\n",
       "      <td>0.056259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN4</th>\n",
       "      <td>-10.046936</td>\n",
       "      <td>1.436731</td>\n",
       "      <td>0.075397</td>\n",
       "      <td>58.670143</td>\n",
       "      <td>1.320618</td>\n",
       "      <td>0.093314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN5</th>\n",
       "      <td>-12.988817</td>\n",
       "      <td>-1.100073</td>\n",
       "      <td>0.864350</td>\n",
       "      <td>56.062581</td>\n",
       "      <td>-1.439952</td>\n",
       "      <td>0.925060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>-2.290153</td>\n",
       "      <td>-0.050386</td>\n",
       "      <td>0.520093</td>\n",
       "      <td>57.496741</td>\n",
       "      <td>0.801747</td>\n",
       "      <td>0.211350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>-24.365435</td>\n",
       "      <td>0.473852</td>\n",
       "      <td>0.317803</td>\n",
       "      <td>41.720991</td>\n",
       "      <td>-1.786963</td>\n",
       "      <td>0.963028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNR</th>\n",
       "      <td>-18.162781</td>\n",
       "      <td>-0.176308</td>\n",
       "      <td>0.569974</td>\n",
       "      <td>51.760104</td>\n",
       "      <td>-0.594499</td>\n",
       "      <td>0.723911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>-31.418401</td>\n",
       "      <td>1.243597</td>\n",
       "      <td>0.106824</td>\n",
       "      <td>54.628422</td>\n",
       "      <td>-0.247235</td>\n",
       "      <td>0.597637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Combined</th>\n",
       "      <td>-0.841788</td>\n",
       "      <td>0.583938</td>\n",
       "      <td>0.279631</td>\n",
       "      <td>58.539765</td>\n",
       "      <td>1.167757</td>\n",
       "      <td>0.121452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HA</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.973924</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          m_oos_r_square  m_MSFE_adjusted  m_pvalue_MSFE  m_success_ratio  \\\n",
       "OLS           -10.832278        -0.163173       0.564809        52.411995   \n",
       "PLS            -4.207930        -0.469415       0.680613        54.628422   \n",
       "PCR            -0.295120         1.456394       0.072642        57.235984   \n",
       "LASSO          -2.122375        -0.098809       0.539355        57.235984   \n",
       "ENet           -2.099062         0.121347       0.451708        56.192960   \n",
       "GBRT          -15.540483         0.620540       0.267451        56.584094   \n",
       "RF            -10.940488        -0.480153       0.684441        54.758801   \n",
       "NN1            -4.797002         1.019277       0.154036        59.061278   \n",
       "NN2            -7.924200        -1.297293       0.902735        55.541069   \n",
       "NN3           -13.836601         0.281574       0.389135        59.061278   \n",
       "NN4           -10.046936         1.436731       0.075397        58.670143   \n",
       "NN5           -12.988817        -1.100073       0.864350        56.062581   \n",
       "Ridge          -2.290153        -0.050386       0.520093        57.496741   \n",
       "SVR           -24.365435         0.473852       0.317803        41.720991   \n",
       "KNR           -18.162781        -0.176308       0.569974        51.760104   \n",
       "XGBoost       -31.418401         1.243597       0.106824        54.628422   \n",
       "Combined       -0.841788         0.583938       0.279631        58.539765   \n",
       "HA              0.000000              NaN            NaN        59.973924   \n",
       "\n",
       "          m_PT_stat  m_pvalue_PT  \n",
       "OLS       -0.072373     0.528848  \n",
       "PLS        0.024259     0.490323  \n",
       "PCR        1.769164     0.038433  \n",
       "LASSO      0.812908     0.208135  \n",
       "ENet       0.385332     0.349996  \n",
       "GBRT      -0.518751     0.698033  \n",
       "RF        -1.843827     0.967396  \n",
       "NN1        1.646321     0.049849  \n",
       "NN2       -0.621255     0.732784  \n",
       "NN3        1.586979     0.056259  \n",
       "NN4        1.320618     0.093314  \n",
       "NN5       -1.439952     0.925060  \n",
       "Ridge      0.801747     0.211350  \n",
       "SVR       -1.786963     0.963028  \n",
       "KNR       -0.594499     0.723911  \n",
       "XGBoost   -0.247235     0.597637  \n",
       "Combined   1.167757     0.121452  \n",
       "HA              NaN          NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_oos_r_square(actual, y_benchmark, y_pred):\n",
    "    MSFE_benchmark = mean_squared_error(y_benchmark, actual)\n",
    "    MSFE_pred = mean_squared_error(y_pred, actual)\n",
    "    return 1 - MSFE_pred / MSFE_benchmark\n",
    "\n",
    "\n",
    "ml_oos_macro_performance = []\n",
    "\n",
    "for col in y_ml_pred.columns:\n",
    "    oos_r_square = compute_oos_r_square(actual_1957, y_pred_HA_1957, y_ml_pred[[col]].to_numpy())\n",
    "    MSFE_adjusted, pvalue_MSFE = CW_test(actual_1957, y_pred_HA_1957, y_ml_pred[[col]].to_numpy())\n",
    "    success_ratio, PT_stat, pvalue_PT = PT_test(actual_1957, y_ml_pred[[col]].to_numpy())\n",
    "    ml_oos_macro_performance.append([oos_r_square * 100, MSFE_adjusted, pvalue_MSFE, success_ratio * 100, PT_stat, pvalue_PT])\n",
    "\n",
    "\n",
    "ml_oos_macro_performance_df = pd.DataFrame(np.array(ml_oos_macro_performance),\n",
    "                                     index=y_ml_pred.columns,\n",
    "                                     columns=['m_oos_r_square', 'm_MSFE_adjusted', 'm_pvalue_MSFE',\n",
    "                                              'm_success_ratio', 'm_PT_stat', 'm_pvalue_PT'])\n",
    "# success ratio of HA\n",
    "success_ratio_HA_1957, PT_HA_1957, p2_HA_1957 = PT_test(actual_1957, y_pred_HA_1957)\n",
    "ml_oos_macro_performance_df.loc['HA'] = [0, np.nan, np.nan, success_ratio_HA_1957 * 100, PT_HA_1957, p2_HA_1957]\n",
    "ml_oos_macro_performance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5d59018",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 767/767 [5:53:12<00:00, 27.63s/it]\n"
     ]
    }
   ],
   "source": [
    "## For technical indicators\n",
    "\n",
    "# Machine Learning methods used in GKX (2020)\n",
    "y_pred_OLS_1957, y_pred_PLS_1957, y_pred_PCR_1957,  y_pred_LASSO_1957 = [], [], [], []\n",
    "y_pred_ENet_1957, y_pred_GBRT_1957, y_pred_RF_1957 = [], [], []\n",
    "y_pred_NN1_1957, y_pred_NN2_1957, y_pred_NN3_1957, y_pred_NN4_1957, y_pred_NN5_1957 = [], [], [], [], []\n",
    "\n",
    "## Other commonly used machine learning method\n",
    "y_pred_Ridge_1957, y_pred_SVR_1957, y_pred_KNR_1957,  y_pred_XGBoost_1957 = [], [], [], []\n",
    "y_pred_combination_1957 = []\n",
    "\n",
    "# control the update month of models during out-of-sample period. \n",
    "month_index = 1  # We update our models annually, meaning we refresh them in months 1, 13, 25, ...\n",
    "\n",
    "for t in tqdm(range(in_out_1957, N)):\n",
    "    #\n",
    "    X_train_all = predictor[:t, 13:25]\n",
    "    y_train_all = predictor[:t, 0]\n",
    "    # set 15% of all the train data as validation set\n",
    "    X_train = X_train_all[0:int(len(X_train_all) * 0.85), :]\n",
    "    X_validation = X_train_all[int(len(X_train_all) * 0.85):t, :]\n",
    "    y_train = y_train_all[0:int(len(X_train_all) * 0.85)]\n",
    "    y_validation = y_train_all[int(len(X_train_all) * 0.85):t]\n",
    "    #\n",
    "    if month_index % 12 == 1:\n",
    "        month_index += 1\n",
    "        # OLS\n",
    "        OLS = LinearRegression()\n",
    "        OLS.fit(X_train_all, y_train_all)\n",
    "        y_pred_OLS_1957.append(OLS.predict(predictor[[t], 13:25])[0])\n",
    "\n",
    "        # PLS\n",
    "        PLS_param = {'n_components': [1, 2, 3, 4, 5, 6, 7, 8]}\n",
    "        PLS_result = {}\n",
    "        for param in ParameterGrid(PLS_param):\n",
    "            PLS = PLSRegression(**param)\n",
    "            PLS.fit(X_train, y_train)\n",
    "            mse = mean_squared_error(PLS.predict(X_validation), y_validation)\n",
    "            PLS_result[str(param)] = mse\n",
    "\n",
    "        PLS_best_param = eval(min(PLS_result, key=PLS_result.get))\n",
    "        PLS_model = PLSRegression(**PLS_best_param)\n",
    "        PLS_model.fit(X_train_all, y_train_all)\n",
    "        y_pred_PLS_1957.append(PLS_model.predict(predictor[[t], 13:25])[0][0])\n",
    "\n",
    "        # PCR\n",
    "        PCR_param = {'n_components': [1, 2, 3, 4, 5, 6, 7, 8]}\n",
    "        PCR_result = {}\n",
    "        for param in ParameterGrid(PCR_param):\n",
    "            pca = PCA(**param)\n",
    "            pca.fit(X_train)\n",
    "            comps = pca.transform(X_train)\n",
    "            forecast = LinearRegression()\n",
    "            forecast.fit(comps, y_train)\n",
    "            mse = mean_squared_error(forecast.predict(pca.transform(X_validation)), y_validation)\n",
    "            PCR_result[str(param)] = mse\n",
    "        #\n",
    "        PCR_best_param = eval(min(PCR_result, key=PCR_result.get))\n",
    "        #\n",
    "        PCR_model = PCA(**PCR_best_param)\n",
    "        PCR_model.fit(X_train_all)\n",
    "        PCR_comps = PCR_model.transform(X_train_all)\n",
    "        PCR_forecast = LinearRegression()\n",
    "        PCR_forecast.fit(PCR_comps, y_train_all)\n",
    "        y_pred_PCR_1957.append(PCR_forecast.predict(PCR_model.transform(predictor[[t], 13:25]))[0])\n",
    "\n",
    "        # LASSO\n",
    "        LASSO_param = {'alpha': list(10 ** np.arange(-4, 1 + 0.001, 0.2))}\n",
    "        LASSO_result = {}\n",
    "        for param in ParameterGrid(LASSO_param):\n",
    "            LASSO = Lasso(**param)\n",
    "            LASSO.fit(X_train, y_train)\n",
    "            mse = mean_squared_error(LASSO.predict(X_validation), y_validation)\n",
    "            LASSO_result[str(param)] = mse\n",
    "        #\n",
    "        LASSO_best_param = eval(min(LASSO_result, key=LASSO_result.get))\n",
    "        #\n",
    "        LASSO_model = Lasso(**LASSO_best_param)\n",
    "        LASSO_model.fit(X_train_all, y_train_all)\n",
    "        y_pred_LASSO_1957.append(LASSO_model.predict(predictor[[t], 13:25])[0])\n",
    "\n",
    "        # ENet\n",
    "        ENet_param = {'alpha': list(10 ** np.arange(-4, 1 + 0.001, 0.2)),\n",
    "                      'l1_ratio': list(np.arange(0.2, 1, 0.3))}\n",
    "        ENet_result = {}\n",
    "        for param in ParameterGrid(ENet_param):\n",
    "            ENet = ElasticNet(**param)\n",
    "            ENet.fit(X_train, y_train)\n",
    "            mse = mean_squared_error(ENet.predict(X_validation), y_validation)\n",
    "            ENet_result[str(param)] = mse\n",
    "\n",
    "        ENet_best_param = eval(min(ENet_result, key=ENet_result.get))\n",
    "        ENet_model = ElasticNet(**ENet_best_param)\n",
    "        ENet_model.fit(X_train_all, y_train_all)\n",
    "        y_pred_ENet_1957.append(ENet_model.predict(predictor[[t], 13:25])[0])\n",
    "\n",
    "        # GBRT\n",
    "        GBRT_param = {'n_estimators': [10, 50, 100, 150, 200],\n",
    "                      'max_depth': [2, 3, 4],\n",
    "                      'min_samples_leaf': [1, 3, 5]}\n",
    "        GBRT_result = {}\n",
    "        for param in ParameterGrid(GBRT_param):\n",
    "            GBRT = GradientBoostingRegressor(**param)\n",
    "            GBRT.fit(X_train, y_train)\n",
    "            mse = mean_squared_error(GBRT.predict(X_validation), y_validation)\n",
    "            GBRT_result[str(param)] = mse\n",
    "\n",
    "        GBRT_best_param = eval(min(GBRT_result, key=GBRT_result.get))\n",
    "        GBRT_model = GradientBoostingRegressor(**GBRT_best_param)\n",
    "        GBRT_model.fit(X_train_all, y_train_all)\n",
    "        y_pred_GBRT_1957.append(GBRT_model.predict(predictor[[t], 13:25])[0])\n",
    "\n",
    "        # RF\n",
    "        RF_param = {'n_estimators': [10, 50, 100, 150, 200],\n",
    "                    'max_depth': [2, 3, 4],\n",
    "                    'min_samples_leaf': [1, 3, 5]}\n",
    "        RF_result = {}\n",
    "        for param in ParameterGrid(RF_param):\n",
    "            RF = RandomForestRegressor(**param)\n",
    "            RF.fit(X_train, y_train)\n",
    "            mse = mean_squared_error(RF.predict(X_validation), y_validation)\n",
    "            RF_result[str(param)] = mse\n",
    "\n",
    "        RF_best_param = eval(min(RF_result, key=RF_result.get))\n",
    "        RF_model = RandomForestRegressor(**RF_best_param)\n",
    "        RF_model.fit(X_train_all, y_train_all)\n",
    "        y_pred_RF_1957.append(RF_model.predict(predictor[[t], 13:25])[0])\n",
    "\n",
    "        # Neural Network Models: NN1~NN5\n",
    "        X_train_all_tensor = torch.tensor(X_train_all, dtype=torch.float)\n",
    "        y_train_all_tensor = torch.tensor(y_train_all.reshape(-1, 1), dtype=torch.float)\n",
    "        X_train_tensor = torch.tensor(X_train, dtype=torch.float)\n",
    "        y_train_tensor = torch.tensor(y_train.reshape(-1, 1), dtype=torch.float)\n",
    "        X_validation_tensor = torch.tensor(X_validation, dtype=torch.float)\n",
    "        y_validation_tensor = torch.tensor(y_validation.reshape(-1, 1), dtype=torch.float)\n",
    "\n",
    "        # NN1\n",
    "        NN1_result = {}\n",
    "        NN1_architecture = {\"module__n_feature\": X_train_tensor.shape[1],\n",
    "                            # n_feature should be the number of predictors\n",
    "                            \"module__n_hidden1\": 32,\n",
    "                            \"module__n_output\": 1}\n",
    "        NN1_param = {'module__dropout': [0.2, 0.4, 0.6, 0.8],\n",
    "                     'lr': [0.001, 0.01],\n",
    "                     'optimizer__weight_decay': [0.1, 0.01, 0.001]}\n",
    "        for param in ParameterGrid(NN1_param):\n",
    "            NN1 = NeuralNetRegressor(Net1, verbose=0, max_epochs=200,\n",
    "                                     optimizer=torch.optim.SGD,\n",
    "                                     **NN1_architecture, **param)\n",
    "            NN1.fit(X_train_tensor, y_train_tensor)\n",
    "            mse = mean_squared_error(NN1.predict(X_validation_tensor), y_validation)\n",
    "            NN1_result[str(param)] = mse\n",
    "\n",
    "        #\n",
    "        NN1_best_param = eval(min(NN1_result, key=NN1_result.get))\n",
    "        NN1_model = NeuralNetRegressor(Net1, verbose=0, max_epochs=200, optimizer=torch.optim.SGD,\n",
    "                                       **NN1_architecture, **NN1_best_param)\n",
    "        NN1_model.fit(X_train_all_tensor, y_train_all_tensor)\n",
    "        y_pred_NN1_1957.append(NN1_model.predict(torch.tensor(predictor[[t], 13:25], dtype=torch.float))[0][0])\n",
    "\n",
    "        # NN2\n",
    "        NN2_result = {}\n",
    "        NN2_architecture = {\"module__n_feature\": X_train_tensor.shape[1],\n",
    "                            \"module__n_hidden1\": 32, \"module__n_hidden2\": 16,\n",
    "                            \"module__n_output\": 1}\n",
    "        NN2_param = {'module__dropout': [0.2, 0.4, 0.6, 0.8],\n",
    "                     'lr': [0.001, 0.01],\n",
    "                     'optimizer__weight_decay': [0.1, 0.01, 0.001]}\n",
    "        for param in ParameterGrid(NN2_param):\n",
    "            NN2 = NeuralNetRegressor(Net2, verbose=0, max_epochs=200,\n",
    "                                     optimizer=torch.optim.SGD,\n",
    "                                     **NN2_architecture, **param)\n",
    "            NN2.fit(X_train_tensor, y_train_tensor)\n",
    "            mse = mean_squared_error(NN2.predict(X_validation_tensor), y_validation)\n",
    "            NN2_result[str(param)] = mse\n",
    "\n",
    "        #\n",
    "        NN2_best_param = eval(min(NN2_result, key=NN2_result.get))\n",
    "        NN2_model = NeuralNetRegressor(Net2, verbose=0, max_epochs=200, optimizer=torch.optim.SGD,\n",
    "                                       **NN2_architecture, **NN2_best_param)\n",
    "        NN2_model.fit(X_train_all_tensor, y_train_all_tensor)\n",
    "        y_pred_NN2_1957.append(NN2_model.predict(torch.tensor(predictor[[t], 13:25], dtype=torch.float))[0][0])\n",
    "        #\n",
    "\n",
    "        # NN3\n",
    "        NN3_result = {}\n",
    "        NN3_architecture = {\"module__n_feature\": X_train_tensor.shape[1],\n",
    "                            # n_feature should be the number of predictors\n",
    "                            \"module__n_hidden1\": 32, \"module__n_hidden2\": 16,\n",
    "                            \"module__n_hidden3\": 8,\n",
    "                            \"module__n_output\": 1}\n",
    "        NN3_param = {'module__dropout': [0.2, 0.4, 0.6, 0.8],\n",
    "                     'lr': [0.001, 0.01],\n",
    "                     'optimizer__weight_decay': [0.1, 0.01, 0.001]}\n",
    "        for param in ParameterGrid(NN3_param):\n",
    "            NN3 = NeuralNetRegressor(Net3, verbose=0, max_epochs=200,\n",
    "                                     optimizer=torch.optim.SGD,\n",
    "                                     **NN3_architecture, **param)\n",
    "            NN3.fit(X_train_tensor, y_train_tensor)\n",
    "            mse = mean_squared_error(NN3.predict(X_validation_tensor), y_validation)\n",
    "            NN3_result[str(param)] = mse\n",
    "\n",
    "        #\n",
    "        NN3_best_param = eval(min(NN3_result, key=NN3_result.get))\n",
    "        NN3_model = NeuralNetRegressor(Net3, verbose=0, max_epochs=200, optimizer=torch.optim.SGD,\n",
    "                                       **NN3_architecture, **NN3_best_param)\n",
    "        NN3_model.fit(X_train_all_tensor, y_train_all_tensor)\n",
    "        y_pred_NN3_1957.append(NN3_model.predict(torch.tensor(predictor[[t], 13:25], dtype=torch.float))[0][0])\n",
    "        #\n",
    "\n",
    "        # NN4\n",
    "        NN4_result = {}\n",
    "        NN4_architecture = {\"module__n_feature\": X_train_tensor.shape[1],\n",
    "                            \"module__n_hidden1\": 32, \"module__n_hidden2\": 16,\n",
    "                            \"module__n_hidden3\": 8, \"module__n_hidden4\": 4,\n",
    "                            \"module__n_output\": 1}\n",
    "        NN4_param = {'module__dropout': [0.2, 0.4, 0.6, 0.8],\n",
    "                     'lr': [0.001, 0.01],\n",
    "                     'optimizer__weight_decay': [0.1, 0.01, 0.001]}\n",
    "        for param in ParameterGrid(NN4_param):\n",
    "            NN4 = NeuralNetRegressor(Net4, verbose=0, max_epochs=200,\n",
    "                                     optimizer=torch.optim.SGD,\n",
    "                                     **NN4_architecture, **param)\n",
    "            NN4.fit(X_train_tensor, y_train_tensor)\n",
    "            mse = mean_squared_error(NN4.predict(X_validation_tensor), y_validation)\n",
    "            NN4_result[str(param)] = mse\n",
    "\n",
    "        #\n",
    "        NN4_best_param = eval(min(NN4_result, key=NN4_result.get))\n",
    "        NN4_model = NeuralNetRegressor(Net4, verbose=0, max_epochs=200, optimizer=torch.optim.SGD,\n",
    "                                       **NN4_architecture, **NN4_best_param)\n",
    "        NN4_model.fit(X_train_all_tensor, y_train_all_tensor)\n",
    "        y_pred_NN4_1957.append(NN4_model.predict(torch.tensor(predictor[[t], 13:25], dtype=torch.float))[0][0])\n",
    "        #\n",
    "\n",
    "        # NN5\n",
    "        NN5_result = {}\n",
    "        NN5_architecture = {\"module__n_feature\": X_train_tensor.shape[1],\n",
    "                            \"module__n_hidden1\": 32, \"module__n_hidden2\": 16,\n",
    "                            \"module__n_hidden3\": 8, \"module__n_hidden4\": 4,\n",
    "                            \"module__n_hidden5\": 2,\n",
    "                            \"module__n_output\": 1}\n",
    "        NN5_param = {'module__dropout': [0.2, 0.4, 0.6, 0.8],\n",
    "                     'lr': [0.001, 0.01],\n",
    "                     'optimizer__weight_decay': [0.1, 0.01, 0.001]}\n",
    "        for param in ParameterGrid(NN5_param):\n",
    "            NN5 = NeuralNetRegressor(Net5, verbose=0, max_epochs=200,\n",
    "                                     optimizer=torch.optim.SGD,\n",
    "                                     **NN5_architecture, **param)\n",
    "            NN5.fit(X_train_tensor, y_train_tensor)\n",
    "            mse = mean_squared_error(NN5.predict(X_validation_tensor), y_validation)\n",
    "            NN5_result[str(param)] = mse\n",
    "\n",
    "        #\n",
    "        NN5_best_param = eval(min(NN5_result, key=NN5_result.get))\n",
    "        NN5_model = NeuralNetRegressor(Net5, verbose=0, max_epochs=200, optimizer=torch.optim.SGD,\n",
    "                                       **NN5_architecture, **NN5_best_param)\n",
    "        NN5_model.fit(X_train_all_tensor, y_train_all_tensor)\n",
    "        y_pred_NN5_1957.append(NN5_model.predict(torch.tensor(predictor[[t], 13:25], dtype=torch.float))[0][0])\n",
    "        #\n",
    "\n",
    "        ## Other commmonly used ML methods\n",
    "        # Ridge\n",
    "        Ridge_param = {'alpha': list(10 ** np.arange(0, 20 + 0.001, 1))}\n",
    "        Ridge_result = {}\n",
    "        for param in ParameterGrid(Ridge_param):\n",
    "            RIDGE = Ridge(**param)\n",
    "            RIDGE.fit(X_train, y_train)\n",
    "            mse = mean_squared_error(RIDGE.predict(X_validation), y_validation)\n",
    "            Ridge_result[str(param)] = mse\n",
    "        #\n",
    "        Ridge_best_param = eval(min(Ridge_result, key=Ridge_result.get))\n",
    "        Ridge_model = Ridge(**Ridge_best_param)\n",
    "        Ridge_model.fit(X_train_all, y_train_all)\n",
    "        y_pred_Ridge_1957.append(Ridge_model.predict(predictor[[t], 13:25])[0])\n",
    "\n",
    "        # SVR\n",
    "        SVR_param = {'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'degree': [2, 3, 4], 'C': [0.1, 0.5, 1]}\n",
    "        SVR_result = {}\n",
    "        for param in ParameterGrid(SVR_param):\n",
    "            SVR_tmp = SVR(**param)\n",
    "            SVR_tmp.fit(X_train, y_train)\n",
    "            mse = mean_squared_error(SVR_tmp.predict(X_validation), y_validation)\n",
    "            SVR_result[str(param)] = mse\n",
    "        SVR_best_param = eval(min(SVR_result, key=SVR_result.get))\n",
    "        SVR_model = SVR(**SVR_best_param)\n",
    "        SVR_model.fit(X_train_all, y_train_all)\n",
    "        y_pred_SVR_1957.append(SVR_model.predict(predictor[[t], 13:25])[0])\n",
    "\n",
    "        # KNR\n",
    "        KNR = KNeighborsRegressor()\n",
    "        KNR_param = {'n_neighbors': [3, 4, 5, 6, 7], 'weights': ['distance', 'uniform'],\n",
    "                     'leaf_size': [20, 30, 40], 'p': [1, 2, 3]}\n",
    "        KNR_result = {}\n",
    "        for param in ParameterGrid(KNR_param):\n",
    "            KNR = KNeighborsRegressor(**param)\n",
    "            KNR.fit(X_train, y_train)\n",
    "            mse = mean_squared_error(KNR.predict(X_validation), y_validation)\n",
    "            KNR_result[str(param)] = mse\n",
    "\n",
    "        KNR_best_param = eval(min(KNR_result, key=KNR_result.get))\n",
    "        KNR_model = KNeighborsRegressor(**KNR_best_param)\n",
    "        KNR_model.fit(X_train_all, y_train_all)\n",
    "        y_pred_KNR_1957.append(KNR_model.predict(predictor[[t], 13:25])[0])\n",
    "\n",
    "        # XGBoost\n",
    "        XGBoost_param = {'max_depth': [4, 5, 6, 7, 8], 'eta': [0.01, 0.1],\n",
    "                         'lambda': [0, 0.5, 1], 'alpha': [0, 0.5, 1]}\n",
    "        XGBoost_result = {}\n",
    "        for param in ParameterGrid(XGBoost_param):\n",
    "            XGBoost = XGBRegressor(**param)\n",
    "            XGBoost.fit(X_train, y_train)\n",
    "            mse = mean_squared_error(XGBoost.predict(X_validation), y_validation)\n",
    "            XGBoost_result[str(param)] = mse\n",
    "\n",
    "        XGB_best_param = eval(min(XGBoost_result, key=XGBoost_result.get))\n",
    "        XGB_model = XGBRegressor(**XGB_best_param)\n",
    "        XGB_model.fit(X_train_all, y_train_all)\n",
    "        y_pred_XGBoost_1957.append(XGB_model.predict(predictor[[t], 13:25])[0])\n",
    "    else:\n",
    "        month_index += 1\n",
    "        y_pred_OLS_1957.append(OLS.predict(predictor[[t], 13:25])[0])\n",
    "        y_pred_PLS_1957.append(PLS_model.predict(predictor[[t], 13:25])[0][0])\n",
    "        y_pred_PCR_1957.append(PCR_forecast.predict(PCR_model.transform(predictor[[t], 13:25]))[0])\n",
    "        y_pred_LASSO_1957.append(LASSO_model.predict(predictor[[t], 13:25])[0])\n",
    "        y_pred_ENet_1957.append(ENet_model.predict(predictor[[t], 13:25])[0])\n",
    "        y_pred_GBRT_1957.append(GBRT_model.predict(predictor[[t], 13:25])[0])\n",
    "        y_pred_RF_1957.append(RF_model.predict(predictor[[t], 13:25])[0])\n",
    "        y_pred_NN1_1957.append(NN1_model.predict(torch.tensor(predictor[[t], 13:25], dtype=torch.float))[0][0])\n",
    "        y_pred_NN2_1957.append(NN2_model.predict(torch.tensor(predictor[[t], 13:25], dtype=torch.float))[0][0])\n",
    "        y_pred_NN3_1957.append(NN3_model.predict(torch.tensor(predictor[[t], 13:25], dtype=torch.float))[0][0])\n",
    "        y_pred_NN4_1957.append(NN4_model.predict(torch.tensor(predictor[[t], 13:25], dtype=torch.float))[0][0])\n",
    "        y_pred_NN5_1957.append(NN5_model.predict(torch.tensor(predictor[[t], 13:25], dtype=torch.float))[0][0])\n",
    "        # Other commonly used ML methods\n",
    "        y_pred_Ridge_1957.append(Ridge_model.predict(predictor[[t], 13:25])[0])\n",
    "        y_pred_SVR_1957.append(SVR_model.predict(predictor[[t], 13:25])[0])\n",
    "        y_pred_KNR_1957.append(KNR_model.predict(predictor[[t], 13:25])[0])\n",
    "        y_pred_XGBoost_1957.append(XGB_model.predict(predictor[[t], 13:25])[0])\n",
    "        \n",
    "\n",
    "# collect predicted value        \n",
    "y_ml_pred = pd.DataFrame(np.array([y_pred_OLS_1957, y_pred_PLS_1957, y_pred_PCR_1957, y_pred_LASSO_1957,\n",
    "                                   y_pred_ENet_1957, y_pred_GBRT_1957, y_pred_RF_1957, y_pred_NN1_1957,\n",
    "                                   y_pred_NN2_1957, y_pred_NN3_1957, y_pred_NN4_1957, y_pred_NN5_1957,\n",
    "                                   y_pred_Ridge_1957, y_pred_SVR_1957, y_pred_KNR_1957, y_pred_XGBoost_1957]),\n",
    "                         index=['OLS', 'PLS', 'PCR', 'LASSO', 'ENet', 'GBRT', 'RF', 'NN1',\n",
    "                                'NN2', 'NN3', 'NN4', 'NN5', 'Ridge', 'SVR', 'KNR', 'XGBoost'],\n",
    "                         columns=predictor_df.month[in_out_1957:N]).T\n",
    "y_ml_pred['Combined'] = y_ml_pred.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8378dc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_oos_r_square</th>\n",
       "      <th>t_MSFE_adjusted</th>\n",
       "      <th>t_pvalue_MSFE</th>\n",
       "      <th>t_success_ratio</th>\n",
       "      <th>t_PT_stat</th>\n",
       "      <th>t_pvalue_PT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>OLS</th>\n",
       "      <td>-2.252358</td>\n",
       "      <td>1.102825</td>\n",
       "      <td>0.135052</td>\n",
       "      <td>58.800522</td>\n",
       "      <td>2.066333</td>\n",
       "      <td>0.019399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PLS</th>\n",
       "      <td>-1.328090</td>\n",
       "      <td>0.890150</td>\n",
       "      <td>0.186693</td>\n",
       "      <td>59.191656</td>\n",
       "      <td>2.145730</td>\n",
       "      <td>0.015947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCR</th>\n",
       "      <td>-1.447030</td>\n",
       "      <td>0.482516</td>\n",
       "      <td>0.314720</td>\n",
       "      <td>59.843546</td>\n",
       "      <td>2.723879</td>\n",
       "      <td>0.003226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LASSO</th>\n",
       "      <td>-0.807651</td>\n",
       "      <td>0.415393</td>\n",
       "      <td>0.338927</td>\n",
       "      <td>59.322034</td>\n",
       "      <td>0.936688</td>\n",
       "      <td>0.174460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENet</th>\n",
       "      <td>-0.449636</td>\n",
       "      <td>1.131260</td>\n",
       "      <td>0.128973</td>\n",
       "      <td>59.713168</td>\n",
       "      <td>1.742299</td>\n",
       "      <td>0.040728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBRT</th>\n",
       "      <td>-4.788859</td>\n",
       "      <td>-0.262271</td>\n",
       "      <td>0.603444</td>\n",
       "      <td>57.757497</td>\n",
       "      <td>-0.052616</td>\n",
       "      <td>0.520981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>-2.763316</td>\n",
       "      <td>0.466681</td>\n",
       "      <td>0.320364</td>\n",
       "      <td>57.757497</td>\n",
       "      <td>1.278115</td>\n",
       "      <td>0.100604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN1</th>\n",
       "      <td>-1.953500</td>\n",
       "      <td>0.531686</td>\n",
       "      <td>0.297472</td>\n",
       "      <td>58.279009</td>\n",
       "      <td>0.506332</td>\n",
       "      <td>0.306312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN2</th>\n",
       "      <td>-6.050815</td>\n",
       "      <td>1.783169</td>\n",
       "      <td>0.037279</td>\n",
       "      <td>57.105606</td>\n",
       "      <td>0.669100</td>\n",
       "      <td>0.251716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN3</th>\n",
       "      <td>-9.938478</td>\n",
       "      <td>0.412314</td>\n",
       "      <td>0.340055</td>\n",
       "      <td>56.975228</td>\n",
       "      <td>0.115003</td>\n",
       "      <td>0.454221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN4</th>\n",
       "      <td>-21.888305</td>\n",
       "      <td>-0.499246</td>\n",
       "      <td>0.691197</td>\n",
       "      <td>55.671447</td>\n",
       "      <td>-1.572585</td>\n",
       "      <td>0.942092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN5</th>\n",
       "      <td>-26.109554</td>\n",
       "      <td>0.787604</td>\n",
       "      <td>0.215464</td>\n",
       "      <td>57.366362</td>\n",
       "      <td>0.163644</td>\n",
       "      <td>0.435006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>-0.802149</td>\n",
       "      <td>0.845750</td>\n",
       "      <td>0.198846</td>\n",
       "      <td>58.148631</td>\n",
       "      <td>0.325430</td>\n",
       "      <td>0.372428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>-19.627307</td>\n",
       "      <td>0.733042</td>\n",
       "      <td>0.231766</td>\n",
       "      <td>46.153846</td>\n",
       "      <td>0.946048</td>\n",
       "      <td>0.172062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNR</th>\n",
       "      <td>-15.641535</td>\n",
       "      <td>1.765765</td>\n",
       "      <td>0.038718</td>\n",
       "      <td>55.280313</td>\n",
       "      <td>1.032629</td>\n",
       "      <td>0.150889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>-5.087559</td>\n",
       "      <td>-0.518313</td>\n",
       "      <td>0.697880</td>\n",
       "      <td>57.627119</td>\n",
       "      <td>-0.146859</td>\n",
       "      <td>0.558378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Combined</th>\n",
       "      <td>-0.016858</td>\n",
       "      <td>1.422554</td>\n",
       "      <td>0.077433</td>\n",
       "      <td>58.670143</td>\n",
       "      <td>1.414614</td>\n",
       "      <td>0.078591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HA</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.973924</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          t_oos_r_square  t_MSFE_adjusted  t_pvalue_MSFE  t_success_ratio  \\\n",
       "OLS            -2.252358         1.102825       0.135052        58.800522   \n",
       "PLS            -1.328090         0.890150       0.186693        59.191656   \n",
       "PCR            -1.447030         0.482516       0.314720        59.843546   \n",
       "LASSO          -0.807651         0.415393       0.338927        59.322034   \n",
       "ENet           -0.449636         1.131260       0.128973        59.713168   \n",
       "GBRT           -4.788859        -0.262271       0.603444        57.757497   \n",
       "RF             -2.763316         0.466681       0.320364        57.757497   \n",
       "NN1            -1.953500         0.531686       0.297472        58.279009   \n",
       "NN2            -6.050815         1.783169       0.037279        57.105606   \n",
       "NN3            -9.938478         0.412314       0.340055        56.975228   \n",
       "NN4           -21.888305        -0.499246       0.691197        55.671447   \n",
       "NN5           -26.109554         0.787604       0.215464        57.366362   \n",
       "Ridge          -0.802149         0.845750       0.198846        58.148631   \n",
       "SVR           -19.627307         0.733042       0.231766        46.153846   \n",
       "KNR           -15.641535         1.765765       0.038718        55.280313   \n",
       "XGBoost        -5.087559        -0.518313       0.697880        57.627119   \n",
       "Combined       -0.016858         1.422554       0.077433        58.670143   \n",
       "HA              0.000000              NaN            NaN        59.973924   \n",
       "\n",
       "          t_PT_stat  t_pvalue_PT  \n",
       "OLS        2.066333     0.019399  \n",
       "PLS        2.145730     0.015947  \n",
       "PCR        2.723879     0.003226  \n",
       "LASSO      0.936688     0.174460  \n",
       "ENet       1.742299     0.040728  \n",
       "GBRT      -0.052616     0.520981  \n",
       "RF         1.278115     0.100604  \n",
       "NN1        0.506332     0.306312  \n",
       "NN2        0.669100     0.251716  \n",
       "NN3        0.115003     0.454221  \n",
       "NN4       -1.572585     0.942092  \n",
       "NN5        0.163644     0.435006  \n",
       "Ridge      0.325430     0.372428  \n",
       "SVR        0.946048     0.172062  \n",
       "KNR        1.032629     0.150889  \n",
       "XGBoost   -0.146859     0.558378  \n",
       "Combined   1.414614     0.078591  \n",
       "HA              NaN          NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_oos_tech_performance = []\n",
    "\n",
    "for col in y_ml_pred.columns:\n",
    "    oos_r_square = compute_oos_r_square(actual_1957, y_pred_HA_1957, y_ml_pred[[col]].to_numpy())\n",
    "    MSFE_adjusted, pvalue_MSFE = CW_test(actual_1957, y_pred_HA_1957, y_ml_pred[[col]].to_numpy())\n",
    "    success_ratio, PT_stat, pvalue_PT = PT_test(actual_1957, y_ml_pred[[col]].to_numpy())\n",
    "    ml_oos_tech_performance.append([oos_r_square * 100, MSFE_adjusted, pvalue_MSFE, success_ratio * 100, PT_stat, pvalue_PT])\n",
    "\n",
    "\n",
    "ml_oos_tech_performance_df = pd.DataFrame(np.array(ml_oos_tech_performance),\n",
    "                                     index=y_ml_pred.columns,\n",
    "                                     columns=['t_oos_r_square', 't_MSFE_adjusted', 't_pvalue_MSFE',\n",
    "                                              't_success_ratio', 't_PT_stat', 't_pvalue_PT'])\n",
    "# success ratio of HA\n",
    "ml_oos_tech_performance_df.loc['HA'] = [0, np.nan, np.nan, success_ratio_HA_1957 * 100, PT_HA_1957, p2_HA_1957]\n",
    "ml_oos_tech_performance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3e6458f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m_oos_r_square</th>\n",
       "      <th>m_MSFE_adjusted</th>\n",
       "      <th>m_pvalue_MSFE</th>\n",
       "      <th>m_success_ratio</th>\n",
       "      <th>m_PT_stat</th>\n",
       "      <th>m_pvalue_PT</th>\n",
       "      <th>t_oos_r_square</th>\n",
       "      <th>t_MSFE_adjusted</th>\n",
       "      <th>t_pvalue_MSFE</th>\n",
       "      <th>t_success_ratio</th>\n",
       "      <th>t_PT_stat</th>\n",
       "      <th>t_pvalue_PT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>OLS</th>\n",
       "      <td>-10.832278</td>\n",
       "      <td>-0.163173</td>\n",
       "      <td>0.564809</td>\n",
       "      <td>52.411995</td>\n",
       "      <td>-0.072373</td>\n",
       "      <td>0.528848</td>\n",
       "      <td>-2.252358</td>\n",
       "      <td>1.102825</td>\n",
       "      <td>0.135052</td>\n",
       "      <td>58.800522</td>\n",
       "      <td>2.066333</td>\n",
       "      <td>0.019399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PLS</th>\n",
       "      <td>-4.207930</td>\n",
       "      <td>-0.469415</td>\n",
       "      <td>0.680613</td>\n",
       "      <td>54.628422</td>\n",
       "      <td>0.024259</td>\n",
       "      <td>0.490323</td>\n",
       "      <td>-1.328090</td>\n",
       "      <td>0.890150</td>\n",
       "      <td>0.186693</td>\n",
       "      <td>59.191656</td>\n",
       "      <td>2.145730</td>\n",
       "      <td>0.015947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCR</th>\n",
       "      <td>-0.295120</td>\n",
       "      <td>1.456394</td>\n",
       "      <td>0.072642</td>\n",
       "      <td>57.235984</td>\n",
       "      <td>1.769164</td>\n",
       "      <td>0.038433</td>\n",
       "      <td>-1.447030</td>\n",
       "      <td>0.482516</td>\n",
       "      <td>0.314720</td>\n",
       "      <td>59.843546</td>\n",
       "      <td>2.723879</td>\n",
       "      <td>0.003226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LASSO</th>\n",
       "      <td>-2.122375</td>\n",
       "      <td>-0.098809</td>\n",
       "      <td>0.539355</td>\n",
       "      <td>57.235984</td>\n",
       "      <td>0.812908</td>\n",
       "      <td>0.208135</td>\n",
       "      <td>-0.807651</td>\n",
       "      <td>0.415393</td>\n",
       "      <td>0.338927</td>\n",
       "      <td>59.322034</td>\n",
       "      <td>0.936688</td>\n",
       "      <td>0.174460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENet</th>\n",
       "      <td>-2.099062</td>\n",
       "      <td>0.121347</td>\n",
       "      <td>0.451708</td>\n",
       "      <td>56.192960</td>\n",
       "      <td>0.385332</td>\n",
       "      <td>0.349996</td>\n",
       "      <td>-0.449636</td>\n",
       "      <td>1.131260</td>\n",
       "      <td>0.128973</td>\n",
       "      <td>59.713168</td>\n",
       "      <td>1.742299</td>\n",
       "      <td>0.040728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBRT</th>\n",
       "      <td>-15.540483</td>\n",
       "      <td>0.620540</td>\n",
       "      <td>0.267451</td>\n",
       "      <td>56.584094</td>\n",
       "      <td>-0.518751</td>\n",
       "      <td>0.698033</td>\n",
       "      <td>-4.788859</td>\n",
       "      <td>-0.262271</td>\n",
       "      <td>0.603444</td>\n",
       "      <td>57.757497</td>\n",
       "      <td>-0.052616</td>\n",
       "      <td>0.520981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>-10.940488</td>\n",
       "      <td>-0.480153</td>\n",
       "      <td>0.684441</td>\n",
       "      <td>54.758801</td>\n",
       "      <td>-1.843827</td>\n",
       "      <td>0.967396</td>\n",
       "      <td>-2.763316</td>\n",
       "      <td>0.466681</td>\n",
       "      <td>0.320364</td>\n",
       "      <td>57.757497</td>\n",
       "      <td>1.278115</td>\n",
       "      <td>0.100604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN1</th>\n",
       "      <td>-4.797002</td>\n",
       "      <td>1.019277</td>\n",
       "      <td>0.154036</td>\n",
       "      <td>59.061278</td>\n",
       "      <td>1.646321</td>\n",
       "      <td>0.049849</td>\n",
       "      <td>-1.953500</td>\n",
       "      <td>0.531686</td>\n",
       "      <td>0.297472</td>\n",
       "      <td>58.279009</td>\n",
       "      <td>0.506332</td>\n",
       "      <td>0.306312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN2</th>\n",
       "      <td>-7.924200</td>\n",
       "      <td>-1.297293</td>\n",
       "      <td>0.902735</td>\n",
       "      <td>55.541069</td>\n",
       "      <td>-0.621255</td>\n",
       "      <td>0.732784</td>\n",
       "      <td>-6.050815</td>\n",
       "      <td>1.783169</td>\n",
       "      <td>0.037279</td>\n",
       "      <td>57.105606</td>\n",
       "      <td>0.669100</td>\n",
       "      <td>0.251716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN3</th>\n",
       "      <td>-13.836601</td>\n",
       "      <td>0.281574</td>\n",
       "      <td>0.389135</td>\n",
       "      <td>59.061278</td>\n",
       "      <td>1.586979</td>\n",
       "      <td>0.056259</td>\n",
       "      <td>-9.938478</td>\n",
       "      <td>0.412314</td>\n",
       "      <td>0.340055</td>\n",
       "      <td>56.975228</td>\n",
       "      <td>0.115003</td>\n",
       "      <td>0.454221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN4</th>\n",
       "      <td>-10.046936</td>\n",
       "      <td>1.436731</td>\n",
       "      <td>0.075397</td>\n",
       "      <td>58.670143</td>\n",
       "      <td>1.320618</td>\n",
       "      <td>0.093314</td>\n",
       "      <td>-21.888305</td>\n",
       "      <td>-0.499246</td>\n",
       "      <td>0.691197</td>\n",
       "      <td>55.671447</td>\n",
       "      <td>-1.572585</td>\n",
       "      <td>0.942092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN5</th>\n",
       "      <td>-12.988817</td>\n",
       "      <td>-1.100073</td>\n",
       "      <td>0.864350</td>\n",
       "      <td>56.062581</td>\n",
       "      <td>-1.439952</td>\n",
       "      <td>0.925060</td>\n",
       "      <td>-26.109554</td>\n",
       "      <td>0.787604</td>\n",
       "      <td>0.215464</td>\n",
       "      <td>57.366362</td>\n",
       "      <td>0.163644</td>\n",
       "      <td>0.435006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>-2.290153</td>\n",
       "      <td>-0.050386</td>\n",
       "      <td>0.520093</td>\n",
       "      <td>57.496741</td>\n",
       "      <td>0.801747</td>\n",
       "      <td>0.211350</td>\n",
       "      <td>-0.802149</td>\n",
       "      <td>0.845750</td>\n",
       "      <td>0.198846</td>\n",
       "      <td>58.148631</td>\n",
       "      <td>0.325430</td>\n",
       "      <td>0.372428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>-24.365435</td>\n",
       "      <td>0.473852</td>\n",
       "      <td>0.317803</td>\n",
       "      <td>41.720991</td>\n",
       "      <td>-1.786963</td>\n",
       "      <td>0.963028</td>\n",
       "      <td>-19.627307</td>\n",
       "      <td>0.733042</td>\n",
       "      <td>0.231766</td>\n",
       "      <td>46.153846</td>\n",
       "      <td>0.946048</td>\n",
       "      <td>0.172062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNR</th>\n",
       "      <td>-18.162781</td>\n",
       "      <td>-0.176308</td>\n",
       "      <td>0.569974</td>\n",
       "      <td>51.760104</td>\n",
       "      <td>-0.594499</td>\n",
       "      <td>0.723911</td>\n",
       "      <td>-15.641535</td>\n",
       "      <td>1.765765</td>\n",
       "      <td>0.038718</td>\n",
       "      <td>55.280313</td>\n",
       "      <td>1.032629</td>\n",
       "      <td>0.150889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>-31.418401</td>\n",
       "      <td>1.243597</td>\n",
       "      <td>0.106824</td>\n",
       "      <td>54.628422</td>\n",
       "      <td>-0.247235</td>\n",
       "      <td>0.597637</td>\n",
       "      <td>-5.087559</td>\n",
       "      <td>-0.518313</td>\n",
       "      <td>0.697880</td>\n",
       "      <td>57.627119</td>\n",
       "      <td>-0.146859</td>\n",
       "      <td>0.558378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Combined</th>\n",
       "      <td>-0.841788</td>\n",
       "      <td>0.583938</td>\n",
       "      <td>0.279631</td>\n",
       "      <td>58.539765</td>\n",
       "      <td>1.167757</td>\n",
       "      <td>0.121452</td>\n",
       "      <td>-0.016858</td>\n",
       "      <td>1.422554</td>\n",
       "      <td>0.077433</td>\n",
       "      <td>58.670143</td>\n",
       "      <td>1.414614</td>\n",
       "      <td>0.078591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HA</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.973924</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.973924</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          m_oos_r_square  m_MSFE_adjusted  m_pvalue_MSFE  m_success_ratio  \\\n",
       "OLS           -10.832278        -0.163173       0.564809        52.411995   \n",
       "PLS            -4.207930        -0.469415       0.680613        54.628422   \n",
       "PCR            -0.295120         1.456394       0.072642        57.235984   \n",
       "LASSO          -2.122375        -0.098809       0.539355        57.235984   \n",
       "ENet           -2.099062         0.121347       0.451708        56.192960   \n",
       "GBRT          -15.540483         0.620540       0.267451        56.584094   \n",
       "RF            -10.940488        -0.480153       0.684441        54.758801   \n",
       "NN1            -4.797002         1.019277       0.154036        59.061278   \n",
       "NN2            -7.924200        -1.297293       0.902735        55.541069   \n",
       "NN3           -13.836601         0.281574       0.389135        59.061278   \n",
       "NN4           -10.046936         1.436731       0.075397        58.670143   \n",
       "NN5           -12.988817        -1.100073       0.864350        56.062581   \n",
       "Ridge          -2.290153        -0.050386       0.520093        57.496741   \n",
       "SVR           -24.365435         0.473852       0.317803        41.720991   \n",
       "KNR           -18.162781        -0.176308       0.569974        51.760104   \n",
       "XGBoost       -31.418401         1.243597       0.106824        54.628422   \n",
       "Combined       -0.841788         0.583938       0.279631        58.539765   \n",
       "HA              0.000000              NaN            NaN        59.973924   \n",
       "\n",
       "          m_PT_stat  m_pvalue_PT  t_oos_r_square  t_MSFE_adjusted  \\\n",
       "OLS       -0.072373     0.528848       -2.252358         1.102825   \n",
       "PLS        0.024259     0.490323       -1.328090         0.890150   \n",
       "PCR        1.769164     0.038433       -1.447030         0.482516   \n",
       "LASSO      0.812908     0.208135       -0.807651         0.415393   \n",
       "ENet       0.385332     0.349996       -0.449636         1.131260   \n",
       "GBRT      -0.518751     0.698033       -4.788859        -0.262271   \n",
       "RF        -1.843827     0.967396       -2.763316         0.466681   \n",
       "NN1        1.646321     0.049849       -1.953500         0.531686   \n",
       "NN2       -0.621255     0.732784       -6.050815         1.783169   \n",
       "NN3        1.586979     0.056259       -9.938478         0.412314   \n",
       "NN4        1.320618     0.093314      -21.888305        -0.499246   \n",
       "NN5       -1.439952     0.925060      -26.109554         0.787604   \n",
       "Ridge      0.801747     0.211350       -0.802149         0.845750   \n",
       "SVR       -1.786963     0.963028      -19.627307         0.733042   \n",
       "KNR       -0.594499     0.723911      -15.641535         1.765765   \n",
       "XGBoost   -0.247235     0.597637       -5.087559        -0.518313   \n",
       "Combined   1.167757     0.121452       -0.016858         1.422554   \n",
       "HA              NaN          NaN        0.000000              NaN   \n",
       "\n",
       "          t_pvalue_MSFE  t_success_ratio  t_PT_stat  t_pvalue_PT  \n",
       "OLS            0.135052        58.800522   2.066333     0.019399  \n",
       "PLS            0.186693        59.191656   2.145730     0.015947  \n",
       "PCR            0.314720        59.843546   2.723879     0.003226  \n",
       "LASSO          0.338927        59.322034   0.936688     0.174460  \n",
       "ENet           0.128973        59.713168   1.742299     0.040728  \n",
       "GBRT           0.603444        57.757497  -0.052616     0.520981  \n",
       "RF             0.320364        57.757497   1.278115     0.100604  \n",
       "NN1            0.297472        58.279009   0.506332     0.306312  \n",
       "NN2            0.037279        57.105606   0.669100     0.251716  \n",
       "NN3            0.340055        56.975228   0.115003     0.454221  \n",
       "NN4            0.691197        55.671447  -1.572585     0.942092  \n",
       "NN5            0.215464        57.366362   0.163644     0.435006  \n",
       "Ridge          0.198846        58.148631   0.325430     0.372428  \n",
       "SVR            0.231766        46.153846   0.946048     0.172062  \n",
       "KNR            0.038718        55.280313   1.032629     0.150889  \n",
       "XGBoost        0.697880        57.627119  -0.146859     0.558378  \n",
       "Combined       0.077433        58.670143   1.414614     0.078591  \n",
       "HA                  NaN        59.973924        NaN          NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_oos_performance_df = pd.concat([ml_oos_macro_performance_df, ml_oos_tech_performance_df], axis=1)\n",
    "import openpyxl\n",
    "with pd.ExcelWriter(\"ml_equity_premium_results.xlsx\", engine='openpyxl', mode='a') as writer:\n",
    "    ml_oos_performance_df.to_excel(writer, sheet_name='using_econ_tech_separately')\n",
    "ml_oos_performance_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
